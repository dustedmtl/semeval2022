{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa290f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4dfb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important; }</style>\"))\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeeb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import util, embeds, fitter, masker, features, sentiment, translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d6ddd8",
   "metadata": {},
   "source": [
    "Uncomment these two lines to download the required data for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec89c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git\n",
    "# !git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e44fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20834c78",
   "metadata": {},
   "source": [
    "Load all the CSV files in dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21478ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = util.load_csv_dataframes(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = frames['train_zero_shot.csv']\n",
    "odf = frames['train_one_shot.csv']\n",
    "ddf = frames['dev.csv']\n",
    "ddf_gold = frames['dev_gold.csv']\n",
    "edf = frames['eval.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_emb = embeds.get_embeddings(zdf)\n",
    "z_emb_i = embeds.get_embeddings(zdf, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75640d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_model = 'distiluse-base-multilingual-cased-v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3a72d",
   "metadata": {},
   "source": [
    "### Sentence transformers embeddings\n",
    "\n",
    "Get sentence-transformers embeddings with the best method (appending MWE to the text, ignoring context).\n",
    "\n",
    "The \"best\" method isn't actually completely true, as the original paper uses the \"idiomatic principle\" to encode the MWE, that is, using it as a single token when tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_emb_multi = embeds.get_embeddings(zdf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a18832",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_emb_multi = embeds.get_embeddings(ddf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4c057",
   "metadata": {},
   "source": [
    "Do a fitting for the embeddings with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c15e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score, z_probs, z_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], d_emb_multi, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres = fitter.add_results(ddf, z_results, ddf_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943676d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7130a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_counts = util.get_counts(dres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58981d8a",
   "metadata": {},
   "source": [
    "Show the MWEs that the model gets wrong more than half of the time. Are there any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_counts[dres_counts['Pct correct'] < 0.5].sort_values(by=['Language','MWE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6c182",
   "metadata": {},
   "source": [
    "### Mask filling (lexical substitution)\n",
    "\n",
    "Get several features based on mask-filling pipeline.\n",
    "\n",
    "Rationale: It should be more difficult to get mask filling to work when the MWE is idiomatic.\n",
    "\n",
    "There are three ways to do mask filling for the MWE:\n",
    "- replace the whole expression: banana republic -\\> \\<mask\\>\n",
    "- replace the first term: \\<mask\\> republic\n",
    "- replace the second term: banana \\<mask\\>\n",
    "\n",
    "The mask filling generates several features:\n",
    "- Hassub: whether a top-5 term is found in the MWE (exactly)\n",
    "- Top score: the confidence score of the top term\n",
    "- Short/FS/SS: Amount of \"Short\" terms (less than three characters) in whole mask vs first term replacement vs second term replacement, respectively\n",
    "\n",
    "Additionally, the top terms are recorded into Top score columns.\n",
    "\n",
    "The Top score is only recorded for an \"acceptable\" term (at least three characters and no non-word characters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb432d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked = masker.get_masked_features(zdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a110ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked.groupby(['Language','Label','Hassub'])['DataID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked = masker.get_masked_features(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d73804",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked[ddf_masked['Hassub'] == False][535:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc545304",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked.groupby(['Language','Hassub'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16cf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_prob = 'Além de ter sido um fracasso de bilheteria e crítica, o filme acabou marcado pelos seus efeitos especiais, principalmente ao antropomorfizar os gatos, que, bem, ficam um pouco bisonhos.'\n",
    "str_prob_2 = 'Professor livre docente da Unesp, Fortaleza é presidente da Sociedade Paulista de Infectologia e membro do Comitê de Contingência da COVID-19, do Governo do Estado de São Paulo.'\n",
    "str_prob_3 = 'Com a segurança da imunização em massa e os números traduzindo sua eficácia, fica mais fácil para o americano médio sentir-se confiante em marcar sua próxima viagem, gerando um circulo virtuoso para o setor nos próximos meses.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9565b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replacer2(str_prob_3, 'círculo virtuoso', '<mask>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b18dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replacer2(str_prob, 'efeito especial', 'efeito <mask>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04662b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replace_mask_token(str_prob_2, 'livre-docente', 'livre-<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replace_mask_token(str_prob, 'efeito especial', 'efeito <mask>', '<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replace_mask_token(str_prob, 'efeito especial', '<mask>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73a5c8",
   "metadata": {},
   "source": [
    "### Boolean features\n",
    "\n",
    "Get features: Caps and Quotes.\n",
    "\n",
    "Rationale:\n",
    "- MWEs in Caps (Banana Republic vs banana republic) are more likely to be a proper noun (PN)\n",
    "- Quoted MWEs are more likely to be idiomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats = features.get_features(zdf_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6063c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats.groupby(['Language','Label','Caps'])['DataID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efeb5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked_feats = features.get_features(ddf_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58abfaa8",
   "metadata": {},
   "source": [
    "### Sentiment classifier\n",
    "\n",
    "Rationale: idiomatic expressions are more likely to be affective (positive or negative).\n",
    "\n",
    "Neutral sentiment probability is used as a proxy for literality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544684b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier, sentiment_tokenizer, sentiment_config = sentiment.get_classifier_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.get_sentiment(ddf_masked_feats['Target'].values[0], sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked_feats_sent = sentiment.get_df_sentiments(ddf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f7535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats_sent = sentiment.get_df_sentiments(zdf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb8a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats_sent[zdf_masked_feats_sent['Label'] == '0'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67832ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats_sent[zdf_masked_feats_sent['Label'] == '1'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db319c16",
   "metadata": {},
   "source": [
    "### Backtranslation\n",
    "\n",
    "Translate text from English to Portuguese and back (and vice versa if the source language is Portuguese).\n",
    "\n",
    "Rationale: the expression is more likely to be idiomatic if it is not found from the backtranslation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "btmodel1, btmodel2, bttoken1, bttoken2 = translate.get_marian_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt = translate.backtranslate(zdf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707cc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt = translate.backtranslate(ddf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdf_bt.sort_values(by=\"BT\", key=lambda x: x.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt2 = translate.record_trans(zdf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt2 = translate.record_trans(ddf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54030c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt2.groupby(['Language','Label','Trans'])['DataID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b47c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt2.groupby(['Language','Trans'])['ID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab27493",
   "metadata": {},
   "source": [
    "### Previous/next difference\n",
    "\n",
    "Compare the embeddings of the Target to those of Previous/Next sentence.\n",
    "\n",
    "Rationale: Idioms are semantic outliers, thus they are more likely to be dissimilar to the context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3 = embeds.get_prev_next_diff(zdf_bt2, modelname=multilingual_model)\n",
    "ddf_bt3 = embeds.get_prev_next_diff(ddf_bt2, modelname=multilingual_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da217a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdf_bt3[zdf_bt3['Label'] == '0'].mean()\n",
    "# zdf_bt3[zdf_bt3['Label'] == '1'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0950764",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Combine the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_t = fitter.get_trainable(zdf_bt3)\n",
    "ddf_t = fitter.get_trainable(ddf_bt3)\n",
    "\n",
    "ddf_feat_score, ddf_feat_probs, ddf_feat_results = fitter.get_fit_results(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'])\n",
    "ddf_feat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf2_feat_score, ddf2_feat_probs, ddf2_feat_results = fitter.get_fit_results(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'], method='rf')\n",
    "# ddf2_feat_score\n",
    "\n",
    "# ff = fitter.check_feats(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'])\n",
    "# ff.sort_values(by=['Score'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf_feat_results, ddf_feat_probs, ['Caps', 'Hassub'])\n",
    "co = len(mu[mu['Prediction'] == mu['Label']])\n",
    "print(co/len(mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366504bf",
   "metadata": {},
   "source": [
    "### Store data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3.to_json('data/zdf_bt3.json', orient=\"records\", lines=True)\n",
    "zdf_bt3.to_csv('data/zdf_bt3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc944d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt3.to_json('data/ddf_bt3.json', orient=\"records\", lines=True)\n",
    "ddf_bt3.to_csv('data/ddf_bt3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a11707",
   "metadata": {},
   "outputs": [],
   "source": [
    "mux = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf_feat_results, ddf_feat_probs, ['Caps', 'Hassub'],['!Trans'])\n",
    "cox = len(mux[mux['Prediction'] == mux['Label']])\n",
    "print(cox/len(mux))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e8929",
   "metadata": {},
   "source": [
    "### One-shot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o_emb_multi = embeds.get_embeddings(odf, modelname=multilingual_model, append=['MWE'])\n",
    "# ozdf = pd.concat([zdf,odf])\n",
    "# oz_emb_multi = np.concatenate([z_emb_multi, o_emb_multi])\n",
    "\n",
    "# oz_score, oz_probs, oz_results = fitter.get_fit_results(oz_emb_multi, ozdf['Label'], d_emb_multi, ddf_gold['Label'])\n",
    "# oz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# odf_masked = masker.get_masked_features(odf)\n",
    "# odf_masked_feats = features.get_features(odf_masked)\n",
    "# odf_masked_feats_sent = sentiment.get_df_sentiments(odf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)\n",
    "# odf_bt = translate.backtranslate(odf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)\n",
    "# odf_bt2 = translate.record_trans(odf_bt)\n",
    "# ozdf_bt2 = pd.concat([zdf_bt2,odf_bt2])\n",
    "# ozdf_t = fitter.get_trainable(ozdf_bt2)\n",
    "\n",
    "# oddf_feat_score, oddf_feat_probs, oddf_feat_results = fitter.get_fit_results2(ozdf_t, ozdf['Label'], ddf_t, ddf_gold['Label'])\n",
    "# oddf_feat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# omu = fitter.multi_results(ddf_bt2, ddf_gold, oz_results, oz_probs, oddf_feat_results, oddf_feat_probs, ['Caps', 'Hassub'])\n",
    "# co = len(omu[omu['Prediction'] == omu['Label']])\n",
    "# print(co/len(omu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d613e",
   "metadata": {},
   "source": [
    "### Get the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9284db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff2 = fitter.check_feats(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'], minfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fitter.get_best_features(ff2, topn=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead67c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestres, bestest = fitter.get_bestest_features(best, zdf_bt3, ddf_bt3, ddf_gold, z_results, z_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e467f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestest.sort_values(by=['Score'], ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8481e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestres2, bestest2 = fitter.get_bestest_features(best, zdf_bt3, ddf_bt3, ddf_gold, z_results, z_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865dccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropcols = ['Top score', 'FS', 'SS', 'Quotes', 'MWEdiff']\n",
    "dropcols = ['Hassub', 'FS', 'Nextdiff']\n",
    "#dropcols = ['Top score', 'FS', 'Nextdiff', 'MWEdiff']\n",
    "zdf_t4 = fitter.get_trainable(zdf_bt3).drop(dropcols, axis=1)\n",
    "ddf_t4 = fitter.get_trainable(ddf_bt3).drop(dropcols, axis=1)\n",
    "ddf5_feat_score, ddf5_feat_probs, ddf5_feat_results = fitter.get_fit_results(zdf_t4, zdf['Label'], ddf_t4, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99298216",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf5_feat_results, ddf5_feat_probs, ['Caps', 'Hassub'],['Quotes', '!Trans'])\n",
    "co = len(mup[mup['Prediction'] == mup['Label']])\n",
    "print(co/len(mup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a978c3",
   "metadata": {},
   "source": [
    "### Evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_emb_multi = embeds.get_embeddings(edf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ez_score, ez_probs, ez_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], e_emb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_masked = masker.get_masked_features(edf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_masked_feats = features.get_features(edf_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47709ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_masked_feats_sent = sentiment.get_df_sentiments(edf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt = translate.backtranslate(edf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfe71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt2 = translate.record_trans(edf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt3 = embeds.get_prev_next_diff(edf_bt2, modelname=multilingual_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f617c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt3.to_json('data/edf_bt3.json', orient=\"records\", lines=True)\n",
    "edf_bt3.to_csv('data/edf_bt3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62662d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt3.to_pickle('data/edf_bt3_20211217_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_sub = frames['eval_submission_format.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673df406",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_t1 = fitter.get_trainable(edf_bt3).drop(dropcols, axis=1)\n",
    "\n",
    "edf_feat_score1, edf_feat_probs1, edf_feat_results1 = fitter.get_fit_results(zdf_t4, zdf['Label'], edf_t1)\n",
    "edf_comb1 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results1, edf_feat_probs1, ['Caps','Hassub'])\n",
    "edf_comb1.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res1 = edf_sub.copy()\n",
    "edf_res1.loc[edf_res1['Setting'] == 'zero_shot', 'Label'] = edf_comb1['Prediction']\n",
    "edf_res1.to_csv('data/eval_sub_20211210_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols2 = ['Top score', 'FS', 'SS', 'Quotes', 'MWEdiff', 'Hassub', 'Caps', 'Top score 1', 'Top score 2']\n",
    "\n",
    "zdf_et2 = fitter.get_trainable(zdf_bt3).drop(dropcols2, axis=1)\n",
    "edf_et2 = fitter.get_trainable(edf_bt3).drop(dropcols2, axis=1)\n",
    "\n",
    "edf_feat_score2, edf_feat_probs2, edf_feat_results2 = fitter.get_fit_results(zdf_et2, zdf['Label'], edf_et2)\n",
    "edf_comb2 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results2, edf_feat_probs2, ['Caps','Hassub'],['Quotes'])\n",
    "edf_comb2.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973b5221",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res2 = edf_sub.copy()\n",
    "edf_res2.loc[edf_res2['Setting'] == 'zero_shot', 'Label'] = edf_comb2['Prediction']\n",
    "edf_res2.to_csv('data/eval_sub_20211210_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e7b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols3 = ['Top score', 'Hassub', 'Short', 'Nextdiff', 'MWEdiff']\n",
    "zdf_et3 = fitter.get_trainable(zdf_bt3).drop(dropcols3, axis=1)\n",
    "edf_et3 = fitter.get_trainable(edf_bt3).drop(dropcols3, axis=1)\n",
    "\n",
    "edf_feat_score3, edf_feat_probs3, edf_feat_results3 = fitter.get_fit_results(zdf_et3, zdf['Label'], edf_et3)\n",
    "edf_comb3 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes'])\n",
    "edf_comb3.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2456d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res3 = edf_sub.copy()\n",
    "edf_res3.loc[edf_res3['Setting'] == 'zero_shot', 'Label'] = edf_comb3['Prediction']\n",
    "edf_res3.to_csv('data/eval_sub_20211210_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe274f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_z = edf_sub.copy()\n",
    "edf_res_z.loc[edf_res_z['Setting'] == 'zero_shot', 'Label'] = ez_results\n",
    "edf_res_z[edf_res_z['Setting'] == 'zero_shot'].groupby(['Language','Label'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_z.to_csv('data/eval_sub_20211210_e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a025608",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = fitter.check_diffs([edf_res1, edf_res2, edf_res3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_best = fitter.get_diff_df(diffs, [edf_res1, edf_res2, edf_res3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767461bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_best.to_csv('data/eval_sub_20211210_b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db2ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
