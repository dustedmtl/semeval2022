{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664ff2b7",
   "metadata": {},
   "source": [
    "## Feature building\n",
    "\n",
    "This notebook builds the feature models using various pipelines and models from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa290f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4dfb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important; }</style>\"))\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeeb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import util, embeds, fitter, masker, features, sentiment, translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d6ddd8",
   "metadata": {},
   "source": [
    "Uncomment these two lines to download the required data for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec89c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git\n",
    "# !git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e44fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath = 'SemEval_2022_Task2-idiomaticity/SubTaskA/TestData'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20834c78",
   "metadata": {},
   "source": [
    "Load all the CSV files in dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21478ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = util.load_csv_dataframes(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = frames['train_zero_shot.csv']\n",
    "odf = frames['train_one_shot.csv']\n",
    "ddf = frames['dev.csv']\n",
    "ddf_gold = frames['dev_gold.csv']\n",
    "edf = frames['eval.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f7705",
   "metadata": {},
   "source": [
    "Load trial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "tframes = util.load_csv_dataframes(testpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = tframes['test.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a0ac3c",
   "metadata": {},
   "source": [
    "Test basic embeddings with sentence-transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_emb = embeds.get_embeddings(zdf)\n",
    "z_emb_i = embeds.get_embeddings(zdf, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75640d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_model = 'distiluse-base-multilingual-cased-v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3a72d",
   "metadata": {},
   "source": [
    "### Sentence transformers embeddings\n",
    "\n",
    "Get sentence-transformers embeddings with the best method (appending MWE to the text, ignoring context).\n",
    "\n",
    "The \"best\" method isn't actually completely true, as the original paper uses the \"idiomatic principle\" to encode the MWE, that is, using it as a single token when tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_emb_multi = embeds.get_embeddings(zdf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a18832",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_emb_multi = embeds.get_embeddings(ddf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4c057",
   "metadata": {},
   "source": [
    "Do a fitting for the embeddings with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c15e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score, z_probs, z_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], d_emb_multi, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres = fitter.add_results(ddf, z_results, ddf_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943676d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7130a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_counts = util.get_counts(dres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58981d8a",
   "metadata": {},
   "source": [
    "Show the MWEs that the model gets wrong more than half of the time. Are there any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_counts[dres_counts['Pct correct'] < 0.5].sort_values(by=['Language','MWE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918f447",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "\n",
    "If you have already generated the features, skip all cells until the \"Reload data from disk\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6c182",
   "metadata": {},
   "source": [
    "### Mask filling (lexical substitution)\n",
    "\n",
    "Get several features based on mask-filling pipeline.\n",
    "\n",
    "Rationale: It should be more difficult to get mask filling to work when the MWE is idiomatic.\n",
    "\n",
    "There are three ways to do mask filling for the MWE:\n",
    "- replace the whole expression: banana republic -\\> \\<mask\\>\n",
    "- replace the first term: \\<mask\\> republic\n",
    "- replace the second term: banana \\<mask\\>\n",
    "\n",
    "The mask filling generates several features:\n",
    "- Hassub: whether a top-5 term is found in the MWE (exactly)\n",
    "  - FoundIndex: records the index of found term\n",
    "  - FoundScore: records the score of found term\n",
    "- Top score: the confidence score of the top term\n",
    "- Short/FS/SS: Amount of \"Short\" terms (less than three characters) in whole mask vs first term replacement vs second term replacement, respectively\n",
    "\n",
    "Additionally, the top terms are recorded into Top terms and Top score columns (for the whole expression and first and second term)\n",
    "- The top score is only recorded for an \"acceptable\" term (at least three characters and no non-word characters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb432d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked = masker.get_masked_features(zdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a110ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked.groupby(['Language','Label','Hassub'])['DataID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked = masker.get_masked_features(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d73804",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked[ddf_masked['Hassub'] == False][535:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc545304",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked.groupby(['Language','Hassub'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16cf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_prob = 'Além de ter sido um fracasso de bilheteria e crítica, o filme acabou marcado pelos seus efeitos especiais, principalmente ao antropomorfizar os gatos, que, bem, ficam um pouco bisonhos.'\n",
    "str_prob_2 = 'Professor livre docente da Unesp, Fortaleza é presidente da Sociedade Paulista de Infectologia e membro do Comitê de Contingência da COVID-19, do Governo do Estado de São Paulo.'\n",
    "str_prob_3 = 'Com a segurança da imunização em massa e os números traduzindo sua eficácia, fica mais fácil para o americano médio sentir-se confiante em marcar sua próxima viagem, gerando um circulo virtuoso para o setor nos próximos meses.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9565b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replacer2(str_prob_3, 'círculo virtuoso', '<mask>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b18dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replacer2(str_prob, 'efeito especial', 'efeito <mask>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04662b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replace_mask_token(str_prob_2, 'livre-docente', 'livre-<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replace_mask_token(str_prob, 'efeito especial', 'efeito <mask>', '<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replace_mask_token(str_prob, 'efeito especial', '<mask>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73a5c8",
   "metadata": {},
   "source": [
    "### Boolean features\n",
    "\n",
    "Get features: Caps and Quotes.\n",
    "\n",
    "Rationale:\n",
    "- MWEs in Caps (Banana Republic vs banana republic) are more likely to be a proper noun (PN)\n",
    "- Quoted MWEs are more likely to be idiomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats = features.get_features(zdf_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6063c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats.groupby(['Language','Label','Caps'])['DataID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efeb5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked_feats = features.get_features(ddf_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58abfaa8",
   "metadata": {},
   "source": [
    "### Sentiment classifier\n",
    "\n",
    "Rationale: idiomatic expressions are more likely to be affective (positive or negative).\n",
    "\n",
    "Neutral sentiment probability is used as a proxy for literality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544684b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier, sentiment_tokenizer, sentiment_config = sentiment.get_classifier_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.get_sentiment(ddf_masked_feats['Target'].values[0], sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked_feats_sent = sentiment.get_df_sentiments(ddf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f7535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats_sent = sentiment.get_df_sentiments(zdf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb8a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats_sent[zdf_masked_feats_sent['Label'] == '0'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db319c16",
   "metadata": {},
   "source": [
    "### Backtranslation\n",
    "\n",
    "Translate text from English to Portuguese and back (and vice versa if the source language is Portuguese).\n",
    "\n",
    "Rationale: the expression is more likely to be idiomatic if it is not found from the backtranslation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "btmodel1, btmodel2, bttoken1, bttoken2 = translate.get_marian_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt = translate.backtranslate(zdf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707cc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt = translate.backtranslate(ddf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdf_bt.sort_values(by=\"BT\", key=lambda x: x.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt2 = translate.record_trans(zdf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt2 = translate.record_trans(ddf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54030c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt2.groupby(['Language','Label','Trans'])['DataID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b47c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt2.groupby(['Language','Trans'])['ID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab27493",
   "metadata": {},
   "source": [
    "### Previous/next difference\n",
    "\n",
    "Compare the embeddings of the Target to those of Previous/Next sentence.\n",
    "\n",
    "Rationale: Idioms are semantic outliers, thus they are more likely to be dissimilar to the context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3 = embeds.get_prev_next_diff(zdf_bt2, modelname=multilingual_model)\n",
    "ddf_bt3 = embeds.get_prev_next_diff(ddf_bt2, modelname=multilingual_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da217a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdf_bt3[zdf_bt3['Label'] == '0'].mean()\n",
    "# zdf_bt3[zdf_bt3['Label'] == '1'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f98676",
   "metadata": {},
   "source": [
    "### Save data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.save_pickle(zdf_bt3, 'data/zdf_bt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8bdb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.save_pickle(ddf_bt3, 'data/ddf_bt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfb2d5",
   "metadata": {},
   "source": [
    "### Reload data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eacbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3 = pd.read_pickle('data/zdf_bt3_20220104_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08629b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt3 = pd.read_pickle('data/ddf_bt3_20220104_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0950764",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Combine the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_t = fitter.get_trainable(zdf_bt3)\n",
    "ddf_t = fitter.get_trainable(ddf_bt3)\n",
    "\n",
    "ddf_feat_score, ddf_feat_probs, ddf_feat_results = fitter.get_fit_results(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'])\n",
    "ddf_feat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf_feat_results, ddf_feat_probs, ['Caps', 'Hassub'], ['Quotes'])\n",
    "co = len(mu[mu['Prediction'] == mu['Label']])\n",
    "print(co/len(mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(mu['Prediction'], mu['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f820411",
   "metadata": {},
   "outputs": [],
   "source": [
    "mux = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf_feat_results, ddf_feat_probs, ['Caps', 'Hassub'],['!Trans','Quotes'])\n",
    "cox = len(mux[mux['Prediction'] == mux['Label']])\n",
    "print(cox/len(mux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(mux['Prediction'], mux['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e8929",
   "metadata": {},
   "source": [
    "### One-shot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o_emb_multi = embeds.get_embeddings(odf, modelname=multilingual_model, append=['MWE'])\n",
    "# ozdf = pd.concat([zdf,odf])\n",
    "# oz_emb_multi = np.concatenate([z_emb_multi, o_emb_multi])\n",
    "\n",
    "# oz_score, oz_probs, oz_results = fitter.get_fit_results(oz_emb_multi, ozdf['Label'], d_emb_multi, ddf_gold['Label'])\n",
    "# oz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# odf_masked = masker.get_masked_features(odf)\n",
    "# odf_masked_feats = features.get_features(odf_masked)\n",
    "# odf_masked_feats_sent = sentiment.get_df_sentiments(odf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)\n",
    "# odf_bt = translate.backtranslate(odf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)\n",
    "# odf_bt2 = translate.record_trans(odf_bt)\n",
    "# ozdf_bt2 = pd.concat([zdf_bt2,odf_bt2])\n",
    "# ozdf_t = fitter.get_trainable(ozdf_bt2)\n",
    "\n",
    "# oddf_feat_score, oddf_feat_probs, oddf_feat_results = fitter.get_fit_results2(ozdf_t, ozdf['Label'], ddf_t, ddf_gold['Label'])\n",
    "# oddf_feat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# omu = fitter.multi_results(ddf_bt2, ddf_gold, oz_results, oz_probs, oddf_feat_results, oddf_feat_probs, ['Caps', 'Hassub'])\n",
    "# co = len(omu[omu['Prediction'] == omu['Label']])\n",
    "# print(co/len(omu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d613e",
   "metadata": {},
   "source": [
    "### Get the best features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0858cd",
   "metadata": {},
   "source": [
    "Lets check some statistics first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3[zdf_bt3['Label'] == '0'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3[zdf_bt3['Label'] == '1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09509a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3[zdf_bt3['Label'] == '1'].mean() - zdf_bt3[zdf_bt3['Label'] == '0'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5cc0c1",
   "metadata": {},
   "source": [
    "Check best and worst features, maximum three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff2 = fitter.check_feats(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'], minfeats=1, maxfeats=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ff2.columns[3:]:\n",
    "    if col != 'Score':\n",
    "        print(col, ff2[ff2[col]]['Score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff2.sort_values(by=['Score'], ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc5a62f",
   "metadata": {},
   "source": [
    "Prune the worst-performing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = ['Top score 1', 'Top score 2', 'SS', 'FS', 'MWEdiff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_t2 = fitter.get_trainable(zdf_bt3).drop(dropcols, axis=1)\n",
    "ddf_t2 = fitter.get_trainable(ddf_bt3).drop(dropcols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b425ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff3 = fitter.check_feats(zdf_t2, zdf['Label'], ddf_t2, ddf_gold['Label'], minfeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9284db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff3.sort_values(by=['Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fitter.get_best_features(ff3, topn=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead67c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestres, bestest = fitter.get_bestest_features(best, zdf_bt3, ddf_bt3, ddf_gold, z_results, z_probs, autodrop=dropcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e467f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestest.sort_values(by=['Score'], ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865dccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropcols = ['Top score', 'FS', 'SS', 'Quotes', 'MWEdiff']\n",
    "# dropcols = ['Top score', 'Top score 1', 'Top score 2', 'Hassub', 'FS', 'Nextdiff']\n",
    "# dropcols = ['FoundIdx', 'MWEdiff', 'FS', 'Hassub']\n",
    "dropcols2 = ['MWEdiff', 'FS']\n",
    "zdf_t4 = fitter.get_trainable(zdf_bt3).drop(dropcols2, axis=1)\n",
    "ddf_t4 = fitter.get_trainable(ddf_bt3).drop(dropcols2, axis=1)\n",
    "ddf5_feat_score, ddf5_feat_probs, ddf5_feat_results = fitter.get_fit_results(zdf_t4, zdf['Label'], ddf_t4, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99298216",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf5_feat_results, ddf5_feat_probs, ['Caps', 'Hassub'],['Quotes'])\n",
    "co = len(mup[mup['Prediction'] == mup['Label']])\n",
    "print(co/len(mup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf53bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(mup['Prediction'], mup['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a978c3",
   "metadata": {},
   "source": [
    "### Evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_emb_multi = embeds.get_embeddings(edf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ez_score, ez_probs, ez_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], e_emb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_masked = masker.get_masked_features(edf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_masked_feats = features.get_features(edf_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47709ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_masked_feats_sent = sentiment.get_df_sentiments(edf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt = translate.backtranslate(edf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfe71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt2 = translate.record_trans(edf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt3 = embeds.get_prev_next_diff(edf_bt2, modelname=multilingual_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae155cc1",
   "metadata": {},
   "source": [
    "Save evaluation data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.save_pickle(edf_bt3, 'data/edf_bt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c478229",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt3 = pd.read_pickle('data/edf_bt3_20220105_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def15622",
   "metadata": {},
   "source": [
    "#### Runs with test data\n",
    "\n",
    "Test data was releaesd on January 10, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_emb_multi = embeds.get_embeddings(tdf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84461d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_score, tz_probs, tz_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], t_emb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_masked = masker.get_masked_features(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad8157",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_masked_feats = features.get_features(tdf_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6149b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_masked_feats_sent = sentiment.get_df_sentiments(tdf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe0446e",
   "metadata": {},
   "source": [
    "Check how Galician sentences are translated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_gl = tdf_masked_feats_sent[tdf_masked_feats_sent['Language'] == 'GL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb20e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_gl_bt = translate.backtranslate(tdf_gl, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910486c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_gl_bt2 = translate.record_trans(tdf_gl_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5354a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_gl_bt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4695e4",
   "metadata": {},
   "source": [
    "Run backtranslation for the whole data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bt = translate.backtranslate(tdf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc304f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bt2 = translate.record_trans(tdf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae87fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bt3 = embeds.get_prev_next_diff(tdf_bt2, modelname=multilingual_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccb295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.save_pickle(tdf_bt3, 'data/tdf_bt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf_bt3 = pd.read_pickle('data/tdf_bt3_20220111_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e84ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
