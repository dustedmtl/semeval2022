{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d181d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important; }</style>\"))\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c02a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import util, embeds, fitter, masker, features, sentiment, translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed22dcc",
   "metadata": {},
   "source": [
    "Uncomment these two lines to download the required data for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850913f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git\n",
    "# !git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cf541",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab999b",
   "metadata": {},
   "source": [
    "Load all the CSV files in dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = util.load_csv_dataframes(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b629162",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = frames['train_zero_shot.csv']\n",
    "odf = frames['train_one_shot.csv']\n",
    "ddf = frames['dev.csv']\n",
    "ddf_gold = frames['dev_gold.csv']\n",
    "edf = frames['eval.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58db4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_emb = embeds.get_embeddings(zdf)\n",
    "z_emb_i = embeds.get_embeddings(zdf, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ede796",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_model = 'distiluse-base-multilingual-cased-v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1875b488",
   "metadata": {},
   "source": [
    "### Sentence transformers embeddings\n",
    "\n",
    "Get sentence-transformers embeddings with the best method (appending MWE to the text, ignoring context).\n",
    "\n",
    "The \"best\" method isn't actually completely true, as the original paper uses the \"idiomatic principle\" to encode the MWE, that is, using it as a single token when tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e65bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_emb_multi = embeds.get_embeddings(zdf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_emb_multi = embeds.get_embeddings(ddf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2fcae",
   "metadata": {},
   "source": [
    "Do a fitting for the embeddings with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae460cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score, z_probs, z_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], d_emb_multi, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres = fitter.add_results(ddf, z_results, ddf_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95faf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_counts = util.get_counts(dres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d8b24",
   "metadata": {},
   "source": [
    "Show the MWEs that the model gets wrong more than half of the time. Are there any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_counts[dres_counts['Pct correct'] < 0.5].sort_values(by=['Language','MWE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650560a",
   "metadata": {},
   "source": [
    "### Mask filling (lexical substitution)\n",
    "\n",
    "Get several features based on mask-filling pipeline.\n",
    "\n",
    "Rationale: It should be more difficult to get mask filling to work when the MWE is idiomatic.\n",
    "\n",
    "There are three ways to do mask filling for the MWE:\n",
    "- replace the whole expression: banana republic -\\> \\<mask\\>\n",
    "- replace the first term: \\<mask\\> republic\n",
    "- replace the second term: banana \\<mask\\>\n",
    "\n",
    "The mask filling generates several features:\n",
    "- Hassub: whether a top-5 term is found in the MWE (exactly)\n",
    "- Top score: the confidence score of the top term\n",
    "- Short/FS/SS: Amount of \"Short\" terms (less than three characters) in whole mask vs first term replacement vs second term replacement, respectively\n",
    "\n",
    "Additionally, the top terms are recorded into Top score columns.\n",
    "\n",
    "The Top score is only recorded for an \"acceptable\" term (at least three characters and no non-word characters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c984e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked = masker.get_masked_features(zdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493087f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked.groupby(['Language','Label','Hassub'])['DataID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b60272",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked = masker.get_masked_features(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked[ddf_masked['Hassub'] == False][535:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36157904",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked.groupby(['Language','Hassub'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d39dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_prob = 'Além de ter sido um fracasso de bilheteria e crítica, o filme acabou marcado pelos seus efeitos especiais, principalmente ao antropomorfizar os gatos, que, bem, ficam um pouco bisonhos.'\n",
    "str_prob_2 = 'Professor livre docente da Unesp, Fortaleza é presidente da Sociedade Paulista de Infectologia e membro do Comitê de Contingência da COVID-19, do Governo do Estado de São Paulo.'\n",
    "str_prob_3 = 'Com a segurança da imunização em massa e os números traduzindo sua eficácia, fica mais fácil para o americano médio sentir-se confiante em marcar sua próxima viagem, gerando um circulo virtuoso para o setor nos próximos meses.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545962a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replacer2(str_prob_3, 'círculo virtuoso', '<mask>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62929275",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replacer2(str_prob, 'efeito especial', 'efeito <mask>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replace_mask_token(str_prob_2, 'livre-docente', 'livre-<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f051cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replace_mask_token(str_prob, 'efeito especial', 'efeito <mask>', '<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.replace_mask_token(str_prob, 'efeito especial', '<mask>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0db274",
   "metadata": {},
   "source": [
    "### Boolean features\n",
    "\n",
    "Get features: Caps and Quotes.\n",
    "\n",
    "Rationale:\n",
    "- MWEs in Caps (Banana Republic vs banana republic) are more likely to be a proper noun (PN)\n",
    "- Quoted MWEs are more likely to be idiomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba65c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats = features.get_features(zdf_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats.groupby(['Language','Label','Caps'])['DataID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1484e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked_feats = features.get_features(ddf_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b1246",
   "metadata": {},
   "source": [
    "### Sentiment classifier\n",
    "\n",
    "Rationale: idiomatic expressions are more likely to be affective (positive or negative).\n",
    "\n",
    "Neutral sentiment probability is used as a proxy for literality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier, sentiment_tokenizer, sentiment_config = sentiment.get_classifier_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.get_sentiment(ddf_masked_feats['Target'].values[0], sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f89cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_masked_feats_sent = sentiment.get_df_sentiments(ddf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f374021",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats_sent = sentiment.get_df_sentiments(zdf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadcc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats_sent[zdf_masked_feats_sent['Label'] == '0'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_masked_feats_sent[zdf_masked_feats_sent['Label'] == '1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "btmodel1, btmodel2, bttoken1, bttoken2 = translate.get_marian_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d830a",
   "metadata": {},
   "source": [
    "### Backtranslation\n",
    "\n",
    "Translate text from English to Portuguese and back (and vice versa if the source language is Portuguese).\n",
    "\n",
    "Rationale: the expression is more likely to be idiomatic if it is not found from the backtranslation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b532652",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt = translate.backtranslate(zdf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00347629",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt = translate.backtranslate(ddf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdf_bt.sort_values(by=\"BT\", key=lambda x: x.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt2 = translate.record_trans(zdf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405dfe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt2 = translate.record_trans(ddf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86dfd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt2.groupby(['Language','Label','Trans'])['DataID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt2.groupby(['Language','Trans'])['ID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d415db",
   "metadata": {},
   "source": [
    "### Previous/next difference\n",
    "\n",
    "Compare the embeddings of the Target to those of Previous/Next sentence.\n",
    "\n",
    "Rationale: Idioms are semantic outliers, thus they are more likely to be dissimilar to the context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47613812",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3 = embeds.get_prev_next_diff(zdf_bt2, modelname=multilingual_model)\n",
    "ddf_bt3 = embeds.get_prev_next_diff(ddf_bt2, modelname=multilingual_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d608b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdf_bt3[zdf_bt3['Label'] == '0'].mean()\n",
    "# zdf_bt3[zdf_bt3['Label'] == '1'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ebb45",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Combine the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_t = fitter.get_trainable(zdf_bt3)\n",
    "ddf_t = fitter.get_trainable(ddf_bt3)\n",
    "\n",
    "ddf_feat_score, ddf_feat_probs, ddf_feat_results = fitter.get_fit_results(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'])\n",
    "ddf_feat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a88510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf2_feat_score, ddf2_feat_probs, ddf2_feat_results = fitter.get_fit_results(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'], method='rf')\n",
    "# ddf2_feat_score\n",
    "\n",
    "# ff = fitter.check_feats(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'])\n",
    "# ff.sort_values(by=['Score'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf_feat_results, ddf_feat_probs, ['Caps', 'Hassub'])\n",
    "co = len(mu[mu['Prediction'] == mu['Label']])\n",
    "print(co/len(mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3.to_json('data/zdf_bt3.json', orient=\"records\", lines=True)\n",
    "zdf_bt3.to_csv('data/zdf_bt3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37abcf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt3.to_json('data/ddf_bt3.json', orient=\"records\", lines=True)\n",
    "ddf_bt3.to_csv('data/ddf_bt3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abe5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mux = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf_feat_results, ddf_feat_probs, ['Caps', 'Hassub'],['!Trans'])\n",
    "cox = len(mux[mux['Prediction'] == mux['Label']])\n",
    "print(cox/len(mux))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3903b99",
   "metadata": {},
   "source": [
    "### One-shot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o_emb_multi = embeds.get_embeddings(odf, modelname=multilingual_model, append=['MWE'])\n",
    "# ozdf = pd.concat([zdf,odf])\n",
    "# oz_emb_multi = np.concatenate([z_emb_multi, o_emb_multi])\n",
    "\n",
    "# oz_score, oz_probs, oz_results = fitter.get_fit_results(oz_emb_multi, ozdf['Label'], d_emb_multi, ddf_gold['Label'])\n",
    "# oz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507cab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# odf_masked = masker.get_masked_features(odf)\n",
    "# odf_masked_feats = features.get_features(odf_masked)\n",
    "# odf_masked_feats_sent = sentiment.get_df_sentiments(odf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)\n",
    "# odf_bt = translate.backtranslate(odf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)\n",
    "# odf_bt2 = translate.record_trans(odf_bt)\n",
    "# ozdf_bt2 = pd.concat([zdf_bt2,odf_bt2])\n",
    "# ozdf_t = fitter.get_trainable(ozdf_bt2)\n",
    "\n",
    "# oddf_feat_score, oddf_feat_probs, oddf_feat_results = fitter.get_fit_results2(ozdf_t, ozdf['Label'], ddf_t, ddf_gold['Label'])\n",
    "# oddf_feat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f33354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# omu = fitter.multi_results(ddf_bt2, ddf_gold, oz_results, oz_probs, oddf_feat_results, oddf_feat_probs, ['Caps', 'Hassub'])\n",
    "# co = len(omu[omu['Prediction'] == omu['Label']])\n",
    "# print(co/len(omu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced2e65",
   "metadata": {},
   "source": [
    "### Get the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff2 = fitter.check_feats(zdf_t, zdf['Label'], ddf_t, ddf_gold['Label'], minfeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0225e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fitter.get_best_features(ff2, topn=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0185ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestres, bestest = fitter.get_bestest_features(best, zdf_bt3, ddf_bt3, ddf_gold, z_results, z_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestres2, bestest2 = fitter.get_bestest_features(best, zdf_bt3, ddf_bt3, ddf_gold, z_results, z_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb46361",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestest.sort_values(by=['Score'], ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b430c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropcols = ['Top score', 'FS', 'SS', 'Quotes', 'MWEdiff']\n",
    "dropcols = ['Hassub', 'FS', 'Nextdiff']\n",
    "#dropcols = ['Top score', 'FS', 'Nextdiff', 'MWEdiff']\n",
    "zdf_t4 = fitter.get_trainable(zdf_bt3).drop(dropcols, axis=1)\n",
    "ddf_t4 = fitter.get_trainable(ddf_bt3).drop(dropcols, axis=1)\n",
    "ddf5_feat_score, ddf5_feat_probs, ddf5_feat_results = fitter.get_fit_results(zdf_t4, zdf['Label'], ddf_t4, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf5_feat_results, ddf5_feat_probs, ['Caps', 'Hassub'],['!Trans'])\n",
    "co = len(mup[mup['Prediction'] == mup['Label']])\n",
    "print(co/len(mup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb18abe",
   "metadata": {},
   "source": [
    "### Evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a440c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_emb_multi = embeds.get_embeddings(edf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ez_score, ez_probs, ez_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], e_emb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_masked = masker.get_masked_features(edf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_masked_feats = features.get_features(edf_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_masked_feats_sent = sentiment.get_df_sentiments(edf_masked_feats, sentiment_classifier, sentiment_tokenizer, sentiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec3269",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt = translate.backtranslate(edf_masked_feats_sent, btmodel1, btmodel2, bttoken1, bttoken2, batch_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt2 = translate.record_trans(edf_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt3 = embeds.get_prev_next_diff(edf_bt2, modelname=multilingual_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ceb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bt3.to_json('data/edf_bt3.json', orient=\"records\", lines=True)\n",
    "edf_bt3.to_csv('data/edf_bt3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a7c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_sub = frames['eval_submission_format.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_t1 = fitter.get_trainable(edf_bt3).drop(dropcols, axis=1)\n",
    "\n",
    "edf_feat_score1, edf_feat_probs1, edf_feat_results1 = fitter.get_fit_results(zdf_t4, zdf['Label'], edf_t1)\n",
    "edf_comb1 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results1, edf_feat_probs1, ['Caps','Hassub'])\n",
    "edf_comb1.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2911a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols2 = ['Top score', 'FS', 'SS', 'Quotes', 'MWEdiff', 'Hassub', 'Caps', 'Top score 1', 'Top score 2']\n",
    "\n",
    "zdf_et3 = fitter.get_trainable(zdf_bt3).drop(dropcols2, axis=1)\n",
    "edf_et3 = fitter.get_trainable(edf_bt3).drop(dropcols2, axis=1)\n",
    "\n",
    "edf_feat_score3, edf_feat_probs3, edf_feat_results3 = fitter.get_fit_results(zdf_et3, zdf['Label'], edf_et3)\n",
    "edf_comb3 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes'])\n",
    "edf_comb3.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863dd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb3[edf_comb3['Prediction'] != edf_comb1['Prediction']][['ID','MWE','Target','Hassub','Trans','Pred1','Pred2','Score1','Score2','Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a95566",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols3 = ['Top score', 'Hassub', 'Short', 'Nextdiff', 'MWEdiff']\n",
    "zdf_et4 = fitter.get_trainable(zdf_bt3).drop(dropcols3, axis=1)\n",
    "edf_et4 = fitter.get_trainable(edf_bt3).drop(dropcols3, axis=1)\n",
    "\n",
    "edf_feat_score4, edf_feat_probs4, edf_feat_results4 = fitter.get_fit_results(zdf_et4, zdf['Label'], edf_et4)\n",
    "edf_comb4 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results4, edf_feat_probs4, ['Caps','Hassub'],['Quotes'])\n",
    "edf_comb4.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4523550",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb4[edf_comb4['Prediction'] != edf_comb3['Prediction']][['ID','MWE','Target','Hassub','Trans','Pred1','Pred2','Score1','Score2','Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95765f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res2 = edf_sub.copy()\n",
    "edf_res2.loc[edf_res2['Setting'] == 'zero_shot', 'Label'] = edf_comb2['Prediction']\n",
    "edf_res2.to_csv('data/eval_sub_20211208_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res4 = edf_sub.copy()\n",
    "edf_res4.loc[edf_res4['Setting'] == 'zero_shot', 'Label'] = ez_results\n",
    "edf_res4[edf_res4['Setting'] == 'zero_shot'].groupby(['Language','Label'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d08043",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res4.to_csv('data/eval_sub_20211208_6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
