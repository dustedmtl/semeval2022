{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a944a89",
   "metadata": {},
   "source": [
    "## Feature analysis\n",
    "\n",
    "This notebook operates the data that has been generated on the SubTaskA-zeroshot and SubTaskA-zeroshot-bert notebooks:\n",
    "- The stored features are loaded from the data directory for training, development, evaluation and test sets.\n",
    "- The BERT model data is loaded from models directory.\n",
    "\n",
    "The models are combined in various ways. Baselines for various features are also calculated.\n",
    "\n",
    "The external outputs of this notebook include:\n",
    "- CSV files for submission to codalab\n",
    "- Latex tables for results and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beccb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important; }</style>\"))\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af70584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da023b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import util, embeds, fitter, masker, features, sentiment, translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data'\n",
    "testpath = 'SemEval_2022_Task2-idiomaticity/SubTaskA/TestData'\n",
    "multilingual_model = 'distiluse-base-multilingual-cased-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = util.load_csv_dataframes(datapath)\n",
    "tframes = util.load_csv_dataframes(testpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740314e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = frames['train_zero_shot.csv']\n",
    "odf = frames['train_one_shot.csv']\n",
    "ddf = frames['dev.csv']\n",
    "ddf_gold = frames['dev_gold.csv']\n",
    "edf = frames['eval.csv']\n",
    "tdf = tframes['test.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_emb_multi = embeds.get_embeddings(zdf, modelname=multilingual_model, append=['MWE'])\n",
    "d_emb_multi = embeds.get_embeddings(ddf, modelname=multilingual_model, append=['MWE'])\n",
    "e_emb_multi = embeds.get_embeddings(edf, modelname=multilingual_model, append=['MWE'])\n",
    "t_emb_multi = embeds.get_embeddings(tdf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b2d9c",
   "metadata": {},
   "source": [
    "#### Sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddde188",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score, z_probs, z_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], d_emb_multi, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17bb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(z_results, ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb8ca7",
   "metadata": {},
   "source": [
    "Using only sentence-transformers embeddings results in 61.4% score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7367a0a",
   "metadata": {},
   "source": [
    "Create a result dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1920af",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev = pd.DataFrame(columns=['Name', 'Score', 'ScoreEN', 'ScorePT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c518b",
   "metadata": {},
   "source": [
    "### Reload stored data\n",
    "\n",
    "There are the stored features for the feature model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf699f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3 = pd.read_pickle('data/zdf_bt3_20220104_1.pkl')\n",
    "ddf_bt3 = pd.read_pickle('data/ddf_bt3_20220104_1.pkl')\n",
    "edf_bt3 = pd.read_pickle('data/edf_bt3_20220105_1.pkl')\n",
    "tdf_bt3 = pd.read_pickle('data/tdf_bt3_20220111_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615827e7",
   "metadata": {},
   "source": [
    "#### Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd3ea0",
   "metadata": {},
   "source": [
    "##### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(zdf_bt3['Hassub'].map({True: '1', False: '0'}), zdf_bt3['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(zdf_bt3['Trans'].map({True: '1', False: '0'}), zdf_bt3['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sentiment_mean_en = zdf_bt3[zdf_bt3['Language'] == 'EN']['Sentiment'].mean()\n",
    "z_sentiment_mean_pt = zdf_bt3[zdf_bt3['Language'] == 'PT']['Sentiment'].mean()\n",
    "(z_sentiment_mean_en, z_sentiment_mean_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_s = zdf_bt3.copy()\n",
    "zdf_s.loc[(zdf_s['Language'] == 'EN') & (zdf_s['Sentiment'] > z_sentiment_mean_en), 'SentM'] = '1'\n",
    "zdf_s.loc[(zdf_s['Language'] == 'EN') & (zdf_s['Sentiment'] <= z_sentiment_mean_en), 'SentM'] = '0'\n",
    "zdf_s.loc[(zdf_s['Language'] == 'PT') & (zdf_s['Sentiment'] > z_sentiment_mean_pt), 'SentM'] = '1'\n",
    "zdf_s.loc[(zdf_s['Language'] == 'PT') & (zdf_s['Sentiment'] <= z_sentiment_mean_pt), 'SentM'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90627b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(zdf_s['SentM'], zdf_s['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74844c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "zbase_majority = np.max([np.sum(zdf['Label'].astype('int')), len(zdf) - np.sum(zdf['Label'].astype('int'))])/len(zdf)\n",
    "zbase_majority"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f3c78",
   "metadata": {},
   "source": [
    "##### Development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang(df: pd.DataFrame, lang) -> pd.DataFrame:\n",
    "    return df[df['Language'] == lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hassub = f1_score(ddf_bt3['Hassub'].map({True: '1', False: '0'}), ddf_gold['Label'], average='macro')\n",
    "base_trans = f1_score(ddf_bt3['Trans'].map({True: '1', False: '0'}), ddf_gold['Label'], average='macro')\n",
    "sentiment_mean_en = ddf_bt3[ddf_bt3['Language'] == 'EN']['Sentiment'].mean()\n",
    "sentiment_mean_pt = ddf_bt3[ddf_bt3['Language'] == 'PT']['Sentiment'].mean()\n",
    "(sentiment_mean_en, sentiment_mean_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fdbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hassub_en = f1_score(get_lang(ddf_bt3, 'EN')['Hassub'].map({True: '1', False: '0'}), get_lang(ddf_gold, 'EN')['Label'], average='macro')\n",
    "base_hassub_pt = f1_score(get_lang(ddf_bt3, 'PT')['Hassub'].map({True: '1', False: '0'}), get_lang(ddf_gold, 'PT')['Label'], average='macro')\n",
    "base_trans_en = f1_score(get_lang(ddf_bt3, 'EN')['Trans'].map({True: '1', False: '0'}), get_lang(ddf_gold, 'EN')['Label'], average='macro')\n",
    "base_trans_pt = f1_score(get_lang(ddf_bt3, 'PT')['Trans'].map({True: '1', False: '0'}), get_lang(ddf_gold, 'PT')['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a803e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_s = ddf_bt3.copy()\n",
    "ddf_s.loc[(ddf_s['Language'] == 'EN') & (ddf_s['Sentiment'] > sentiment_mean_en), 'SentM'] = '1'\n",
    "ddf_s.loc[(ddf_s['Language'] == 'EN') & (ddf_s['Sentiment'] <= sentiment_mean_en), 'SentM'] = '0'\n",
    "ddf_s.loc[(ddf_s['Language'] == 'PT') & (ddf_s['Sentiment'] > sentiment_mean_pt), 'SentM'] = '1'\n",
    "ddf_s.loc[(ddf_s['Language'] == 'PT') & (ddf_s['Sentiment'] <= sentiment_mean_pt), 'SentM'] = '0'\n",
    "ddf_s.loc[ddf_s['Sentiment'] > ddf_bt3['Sentiment'].mean(), 'SentM2'] = '1'\n",
    "ddf_s.loc[ddf_s['Sentiment'] <= ddf_bt3['Sentiment'].mean(), 'SentM2'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a495e3",
   "metadata": {},
   "source": [
    "Since the sentiment distribution is quite different for English and Portuguese, we want to use different mean values for each language. A score above the mean is taken as literal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sentiment mean\n",
    "f1_score(ddf_s['SentM2'], ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bad1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different mean values for English and Portuguese\n",
    "base_sentiment = f1_score(ddf_s['SentM'], ddf_gold['Label'], average='macro')\n",
    "base_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c465cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sentiment_en = f1_score(get_lang(ddf_s, 'EN')['SentM'], get_lang(ddf_gold, 'EN')['Label'], average='macro')\n",
    "base_sentiment_pt = f1_score(get_lang(ddf_s, 'PT')['SentM'], get_lang(ddf_gold, 'PT')['Label'], average='macro')\n",
    "base_sentiment_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_majority = np.max([np.sum(ddf_gold['Label'].astype('int')), len(ddf_gold) - np.sum(ddf_gold['Label'].astype('int'))])/len(ddf_gold)\n",
    "base_majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd63ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_majority_en = np.max([np.sum(get_lang(ddf_gold, 'EN')['Label'].astype('int')), len(get_lang(ddf_gold, 'EN')) - np.sum(get_lang(ddf_gold, 'EN')['Label'].astype('int'))])/len(get_lang(ddf_gold, 'EN'))\n",
    "base_majority_pt = np.max([np.sum(get_lang(ddf_gold, 'PT')['Label'].astype('int')), len(get_lang(ddf_gold, 'PT')) - np.sum(get_lang(ddf_gold, 'PT')['Label'].astype('int'))])/len(get_lang(ddf_gold, 'PT'))\n",
    "base_majority_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['base_hassub'] = ['Baseline: hassub', base_hassub, base_hassub_en, base_hassub_pt]\n",
    "resdf_dev.loc['base_trans'] = ['Baseline: trans', base_trans, base_trans_en, base_trans_pt]\n",
    "resdf_dev.loc['base_sentiment'] = ['Baseline: sentiment', base_sentiment, base_sentiment_en, base_sentiment_pt]\n",
    "resdf_dev.loc['base_majority'] = ['Baseline: majority', base_majority, base_majority_en, base_majority_pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_idx = ddf_gold['Language'] == 'EN'\n",
    "pt_idx = ddf_gold['Language'] == 'PT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(z_results[en_idx], get_lang(ddf_gold, 'EN')['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d03950",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(z_results[pt_idx], get_lang(ddf_gold, 'PT')['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['sbert'] = ['Sentence transformers',\n",
    "                          f1_score(z_results, ddf_gold['Label'], average='macro'),\n",
    "                          f1_score(z_results[en_idx], get_lang(ddf_gold, 'EN')['Label'], average='macro'),\n",
    "                          f1_score(z_results[pt_idx], get_lang(ddf_gold, 'PT')['Label'], average='macro')\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152dd013",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958b6eb",
   "metadata": {},
   "source": [
    "#### Sentence transformers + feature model\n",
    "\n",
    "Classification with the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropcols = ['Top score', 'FS', 'SS', 'Quotes', 'MWEdiff']\n",
    "# dropcols = ['Hassub', 'FS', 'Nextdiff']\n",
    "# dropcols = ['MWEdiff', 'FS']\n",
    "# dropcols = ['Top score 1', 'Top score 2', 'SS', 'FS', 'MWEdiff']\n",
    "dropcols = ['Top score 1', 'FS', 'MWEdiff']\n",
    "zdf_t4 = fitter.get_trainable(zdf_bt3).drop(dropcols, axis=1)\n",
    "ddf_t4 = fitter.get_trainable(ddf_bt3).drop(dropcols, axis=1)\n",
    "ddf5_feat_score, ddf5_feat_probs, ddf5_feat_results = fitter.get_fit_results(zdf_t4, zdf['Label'], ddf_t4, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080df3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf5_feat_results, ddf5_feat_probs, ['Caps', 'Hassub'],['Quotes'])\n",
    "f1_score(mup ['Prediction'], mup['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup_x = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf5_feat_results, ddf5_feat_probs, ['Caps'],['Quotes'])\n",
    "f1_score(mup_x['Prediction'], mup_x['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4beeeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['sbert_feat'] = ['Sentence transformers + feature',\n",
    "                               f1_score(mup['Prediction'], mup['Label'], average='macro'),\n",
    "                               f1_score(get_lang(mup, 'EN')['Prediction'], get_lang(mup, 'EN')['Label'], average='macro'),\n",
    "                               f1_score(get_lang(mup, 'PT')['Prediction'], get_lang(mup, 'PT')['Label'], average='macro')\n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d42bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_sub = frames['dev_submission_format.csv']\n",
    "ddf_res = ddf_sub.copy()\n",
    "ddf_res.loc[ddf_res['Setting'] == 'zero_shot', 'Label'] = mup['Prediction']\n",
    "# ddf_res.to_csv('data/ddf_sub_20220121_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11630b",
   "metadata": {},
   "source": [
    "#### Normalization of sentiment scores\n",
    "\n",
    "Since the sentiment distribution is different for each language, let's see if normalizing sentiment helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ca5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zdf_bt3[zdf_bt3['Language'] == 'EN']['Sentiment'].mean())\n",
    "print(zdf_bt3[zdf_bt3['Language'] == 'PT']['Sentiment'].mean())\n",
    "sentdiff = zdf_bt3[zdf_bt3['Language'] == 'PT']['Sentiment'].mean() - zdf_bt3[zdf_bt3['Language'] == 'EN']['Sentiment'].mean()\n",
    "print(sentdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt4 = zdf_bt3.copy()\n",
    "zdf_bt4['SentNorm'] = zdf_bt4['Sentiment']\n",
    "zdf_bt4.loc[zdf_bt4['Language'] == 'PT', 'SentNorm'] -= sentdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cdc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ddf_bt3[ddf_bt3['Language'] == 'EN']['Sentiment'].mean())\n",
    "print(ddf_bt3[ddf_bt3['Language'] == 'PT']['Sentiment'].mean())\n",
    "sentdiff_d = ddf_bt3[ddf_bt3['Language'] == 'PT']['Sentiment'].mean() - ddf_bt3[ddf_bt3['Language'] == 'EN']['Sentiment'].mean()\n",
    "print(sentdiff_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc6166",
   "metadata": {},
   "source": [
    "There's a ~0.08-0.09 difference in sentiment means. Let's use that for normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e4b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt4 = ddf_bt3.copy()\n",
    "ddf_bt4['SentNorm'] = ddf_bt4['Sentiment']\n",
    "ddf_bt4.loc[ddf_bt4['Language'] == 'PT', 'SentNorm'] -= sentdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols_s = ['Top score 1', 'FS', 'MWEdiff', 'Sentiment']\n",
    "zdf_t6 = fitter.get_trainable(zdf_bt4).drop(dropcols_s, axis=1)\n",
    "ddf_t6 = fitter.get_trainable(ddf_bt4).drop(dropcols_s, axis=1)\n",
    "ddf7_feat_score, ddf7_feat_probs, ddf7_feat_results = fitter.get_fit_results(zdf_t6, zdf['Label'], ddf_t6, ddf_gold['Label'])\n",
    "mup_s = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf7_feat_results, ddf7_feat_probs, ['Caps', 'Hassub'],['Quotes'])\n",
    "f1_score(mup_s['Prediction'], mup_s['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83c764",
   "metadata": {},
   "source": [
    "Normalization of the Sentiment scores doesn't seem to help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6568de",
   "metadata": {},
   "source": [
    "#### One-hot language variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt5 = pd.get_dummies(zdf_bt3, columns=['Language'])\n",
    "ddf_bt5 = pd.get_dummies(ddf_bt3, columns=['Language'])\n",
    "ddf_bt5 = ddf_bt3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols_m = ['Top score 1', 'FS', 'MWEdiff', 'Top score', 'Top score 2']\n",
    "zdf_t7 = fitter.get_trainable(zdf_bt5).drop(dropcols_m, axis=1)\n",
    "ddf_t7 = fitter.get_trainable(ddf_bt5).drop(dropcols_m, axis=1)\n",
    "ddf8_feat_score, ddf8_feat_probs, ddf8_feat_results = fitter.get_fit_results(zdf_t7, zdf['Label'], ddf_t7, ddf_gold['Label'])\n",
    "mup_m = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf8_feat_results, ddf8_feat_probs, ['Caps', 'Hassub'],['Quotes'])\n",
    "f1_score(mup_m['Prediction'], mup_m['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cc93e",
   "metadata": {},
   "source": [
    "Encoding the languages as One Hot variables doesn't change things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0af21",
   "metadata": {},
   "source": [
    "### Results from BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13420718",
   "metadata": {},
   "source": [
    "##### Multilingual model for both EN,PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddda831",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bert0 = pd.read_csv('models/ZeroShot/0/eval-dev/test_results_None.txt', sep='\\t')\n",
    "ddf_bert0_probs = pd.read_csv('models/ZeroShot/0/eval-dev/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64276134",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(ddf_bert0['prediction'].astype('str'), ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['BERT'] = ['BERT', \n",
    "                         f1_score(ddf_bert0['prediction'].astype('str'), ddf_gold['Label'], average='macro'),\n",
    "                         f1_score(ddf_bert0['prediction'][en_idx].astype('str'), get_lang(ddf_gold, 'EN')['Label'], average='macro'),\n",
    "                         f1_score(ddf_bert0['prediction'][pt_idx].astype('str'), get_lang(ddf_gold, 'PT')['Label'], average='macro')\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c98a9",
   "metadata": {},
   "source": [
    "##### English model for English, multilingual (full) model for PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bert1 = pd.read_csv('models/ZeroShot/1/eval-dev/test_results_None.txt', sep='\\t')\n",
    "ddf_bert1_probs = pd.read_csv('models/ZeroShot/1/eval-dev/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2868f0",
   "metadata": {},
   "source": [
    "bert0 is the multilingual model, copy the results from the English model (bert1) over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bert_comb = ddf_bert0.copy()\n",
    "ddf_bert_comb_probs = ddf_bert0_probs.copy()\n",
    "for idx,row in ddf_bert1.iterrows():\n",
    "    _idx,_pred = row\n",
    "    ddf_bert_comb.loc[_idx,'prediction'] = _pred\n",
    "for idx,row in ddf_bert1_probs.iterrows():\n",
    "    _idx,_pred = row\n",
    "    ddf_bert_comb_probs.loc[_idx,'prediction'] = _pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465449cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(ddf_bert_comb['prediction'].astype('str'), ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(ddf_bert_comb['prediction'][en_idx].astype('str'), ddf_gold['Label'][en_idx], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(ddf_bert_comb['prediction'][pt_idx].astype('str'), ddf_gold['Label'][pt_idx], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f698f49f",
   "metadata": {},
   "source": [
    "##### English model for English, multilingual (PT-only) model for PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ba8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_1 = util.load_df('models/ZeroShot/1/eval-dev/test_results_None.txt', delimiter=\"\\t\")\n",
    "dres_2 = util.load_df('models/ZeroShot/2/eval-dev/test_results_None.txt', delimiter=\"\\t\")\n",
    "dres_1['index'] = dres_1['index'].astype(int)\n",
    "dres_2['index'] = dres_2['index'].astype(int)\n",
    "dres_2['index'] += len(dres_1)\n",
    "dres_3 = pd.concat([dres_1, dres_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_1_p = util.load_df('models/ZeroShot/1/eval-dev/test_results_None.txt.probs', delimiter=\"\\t\")\n",
    "dres_2_p = util.load_df('models/ZeroShot/2/eval-dev/test_results_None.txt.probs', delimiter=\"\\t\")\n",
    "dres_1_p['index'] = dres_1_p['index'].astype(float)\n",
    "dres_2_p['index'] = dres_2_p['index'].astype(float)\n",
    "dres_2_p['index'] += len(dres_1_p)\n",
    "dres_3_p = pd.concat([dres_1_p, dres_2_p], ignore_index=True)\n",
    "dres_3_p['probs'] = dres_3_p['probs'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dce5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(dres_3['prediction'].astype('str'), ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(dres_3['prediction'][pt_idx].astype('str'), ddf_gold['Label'][pt_idx], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14074a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['BERT_multi1'] = ['BERT multilingual, separate, PT results from full model', \n",
    "                                f1_score(ddf_bert_comb['prediction'].astype('str'), ddf_gold['Label'], average='macro'),\n",
    "                                f1_score(ddf_bert_comb['prediction'][en_idx].astype('str'), ddf_gold['Label'][en_idx], average='macro'),\n",
    "                                f1_score(ddf_bert_comb['prediction'][pt_idx].astype('str'), ddf_gold['Label'][pt_idx], average='macro')\n",
    "                               ]\n",
    "resdf_dev.loc['BERT_multi2'] = ['BERT multilingual, separate',\n",
    "                                f1_score(dres_3['prediction'].astype('str'), ddf_gold['Label'], average='macro'),\n",
    "                                f1_score(dres_3['prediction'][en_idx].astype('str'), ddf_gold['Label'][en_idx], average='macro'),\n",
    "                                f1_score(dres_3['prediction'][pt_idx].astype('str'), ddf_gold['Label'][pt_idx], average='macro')\n",
    "                               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10ba0e",
   "metadata": {},
   "source": [
    "#### Combine BERT with feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup0 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert0['prediction'].astype('str'), ddf_bert0_probs['probs'],\n",
    "                            ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes'], agreeonly=True)\n",
    "f1_score(mup0['Prediction'], mup0['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5cabfb",
   "metadata": {},
   "source": [
    "Using Sentiment as a forced feature doesn't help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup0s = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert0['prediction'].astype('str'), ddf_bert0_probs['probs'],\n",
    "                             ddf5_feat_results, ddf5_feat_probs,\n",
    "                             ['Caps', 'Hassub', 'Sentiment'],\n",
    "                             ['Quotes'], agreeonly=True)\n",
    "f1_score(mup0s['Prediction'], mup0s['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3c250",
   "metadata": {},
   "source": [
    "##### Combine BERT (en+pt) with feature model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c01c04",
   "metadata": {},
   "source": [
    "Using different BERT models for English and Portuguese.\n",
    "\n",
    "A couple of different options used here:\n",
    " - Using !Trans as a boolean feature (i.e. not having a good translation is considered idiomatic)\n",
    " - agreeonly: only consider boolean features if both models agree\n",
    "\n",
    "The first results are without using agreeonly feature. First for the case where PT model is trained with all data, the second when it is only trained with PT data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e905717",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup1 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                            ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes'])\n",
    "f1_score(mup1['Prediction'], mup1['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a984887",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_res2 = ddf_sub.copy()\n",
    "ddf_res2.loc[ddf_res2['Setting'] == 'zero_shot', 'Label'] = mup1['Prediction']\n",
    "# ddf_res2.to_csv('data/ddf_sub_20220121_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup1p = fitter.multi_results(ddf_bt3, ddf_gold, dres_3['prediction'].astype('str'),\n",
    "                             dres_3_p['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                             ['Caps', 'Hassub'],\n",
    "                             ['Quotes'])\n",
    "f1_score(mup1p['Prediction'], mup1p['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904363de",
   "metadata": {},
   "source": [
    "Add the agreeonly feature to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup2 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                            ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes'], agreeonly=True)\n",
    "f1_score(mup2['Prediction'], mup2['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce06976",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup2p = fitter.multi_results(ddf_bt3, ddf_gold, dres_3['prediction'].astype('str'),\n",
    "                            dres_3_p['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes'], agreeonly=True)\n",
    "f1_score(mup2p['Prediction'], mup2p['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f1d9f",
   "metadata": {},
   "source": [
    "The same with !Trans, with or without agreeonly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafaef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup3 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                            ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes', '!Trans'])\n",
    "f1_score(mup3['Prediction'], mup3['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup3p = fitter.multi_results(ddf_bt3, ddf_gold, dres_3['prediction'].astype('str'),\n",
    "                            dres_3_p['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes', '!Trans'])\n",
    "f1_score(mup3p['Prediction'], mup3p['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb260dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup4 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                            ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes', '!Trans'], agreeonly=True)\n",
    "f1_score(mup4['Prediction'], mup4['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed619633",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup4p = fitter.multi_results(ddf_bt3, ddf_gold, dres_3['prediction'].astype('str'),\n",
    "                             dres_3_p['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                             ['Caps', 'Hassub'],\n",
    "                             ['Quotes', '!Trans'], agreeonly=True)\n",
    "f1_score(mup4p['Prediction'], mup4p['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d47b74",
   "metadata": {},
   "source": [
    "In the end, using multilingual model only for Portuguese may or may not improve things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup4s = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                             ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                             ['Caps', 'Hassub', 'Sentiment'],\n",
    "                             ['Quotes', '!Trans'], agreeonly=True)\n",
    "f1_score(mup4s['Prediction'], mup4s['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133851d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['BERT_feat'] = ['BERT + feature',\n",
    "                              f1_score(mup0['Prediction'], mup0['Label'], average='macro'),\n",
    "                              f1_score(mup0['Prediction'][en_idx], mup0['Label'][en_idx], average='macro'),\n",
    "                              f1_score(mup0['Prediction'][pt_idx], mup0['Label'][pt_idx], average='macro')\n",
    "                             ]\n",
    "resdf_dev.loc['BERT_multi_feat'] = ['BERT (multi) + feature',\n",
    "                                    f1_score(mup1['Prediction'], mup1['Label'], average='macro'),\n",
    "                                    f1_score(mup1['Prediction'][en_idx], mup1['Label'][en_idx], average='macro'),\n",
    "                                    f1_score(mup1['Prediction'][pt_idx], mup1['Label'][pt_idx], average='macro')\n",
    "                                   ]\n",
    "resdf_dev.loc['BERT_multi_feat_agree'] = ['BERT (multi) + feature (agreeonly)',\n",
    "                                          f1_score(mup2['Prediction'], mup2['Label'], average='macro'),\n",
    "                                          f1_score(mup2['Prediction'][en_idx], mup2['Label'][en_idx], average='macro'),\n",
    "                                          f1_score(mup2['Prediction'][pt_idx], mup2['Label'][pt_idx], average='macro')\n",
    "                                         ]\n",
    "resdf_dev.loc['BERT_multi_feat_trans'] = ['BERT (multi) + feature + trans',\n",
    "                                          f1_score(mup3['Prediction'], mup3['Label'], average='macro'),\n",
    "                                          f1_score(mup3['Prediction'][en_idx], mup3['Label'][en_idx], average='macro'),\n",
    "                                          f1_score(mup3['Prediction'][pt_idx], mup3['Label'][pt_idx], average='macro')\n",
    "                                         ]\n",
    "resdf_dev.loc['BERT_multi_feat_trans_agree'] = ['BERT (multi) + feature + trans (agreeonly)',\n",
    "                                                f1_score(mup4['Prediction'], mup4['Label'], average='macro'),\n",
    "                                                f1_score(mup4['Prediction'][en_idx], mup4['Label'][en_idx], average='macro'),\n",
    "                                                f1_score(mup4['Prediction'][pt_idx], mup4['Label'][pt_idx], average='macro')\n",
    "                                               ]\n",
    "resdf_dev.loc['BERT_multi2_feat_trans_agree'] = ['BERT (multi2) + feature + trans (agreeonly)',\n",
    "                                                 f1_score(mup4p['Prediction'], mup4p['Label'], average='macro'),\n",
    "                                                 f1_score(mup4p['Prediction'][en_idx], mup4p['Label'][en_idx], average='macro'),\n",
    "                                                 f1_score(mup4p['Prediction'][pt_idx], mup4p['Label'][pt_idx], average='macro')\n",
    "                                                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faed8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b3446",
   "metadata": {},
   "source": [
    "#### Majority voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88af4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup_m1 = fitter.majority_results(ddf_bt3, ddf_gold,\n",
    "                                 ddf_bert_comb['prediction'].astype('str'),\n",
    "                                 ddf_bert_comb_probs['probs'],\n",
    "                                 ddf5_feat_results, ddf5_feat_probs,\n",
    "                                 z_results, z_probs,\n",
    "                                 ['Caps', 'Hassub'],\n",
    "                                 ['Quotes', '!Trans'])\n",
    "f1_score(mup_m1['Prediction'], mup_m1['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa39af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup_m2 = fitter.majority_results(ddf_bt3, ddf_gold,\n",
    "                                 ddf_bert_comb['prediction'].astype('str'),\n",
    "                                 ddf_bert_comb_probs['probs'],\n",
    "                                 ddf5_feat_results, ddf5_feat_probs,\n",
    "                                 z_results, z_probs,\n",
    "                                 ['Caps', 'Hassub'],\n",
    "                                 ['Quotes', '!Trans'], agreeonly=True)\n",
    "f1_score(mup_m2['Prediction'], mup_m2['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fde114",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['majority_voting_trans'] = ['Majority voting + trans',\n",
    "                                          f1_score(mup_m1['Prediction'], mup_m1['Label'], average='macro'),\n",
    "                                          f1_score(mup_m1[en_idx]['Prediction'], mup_m1[en_idx]['Label'], average='macro'),\n",
    "                                          f1_score(mup_m1[pt_idx]['Prediction'], mup_m1[pt_idx]['Label'], average='macro')\n",
    "                                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['majority_voting_trans_agree'] = ['Majority voting + trans (agreeonly)',\n",
    "                                                f1_score(mup_m2['Prediction'], mup_m2['Label'], average='macro'),\n",
    "                                                f1_score(mup_m2[en_idx]['Prediction'], mup_m2[en_idx]['Label'], average='macro'),\n",
    "                                                f1_score(mup_m2[pt_idx]['Prediction'], mup_m2[pt_idx]['Label'], average='macro')\n",
    "                                               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d74be",
   "metadata": {},
   "source": [
    "### Eval results\n",
    "\n",
    "For the evaluation results, scores are copied from the codalab website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af88f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_sub = frames['eval_submission_format.csv']\n",
    "tdf_sub = tframes['test_submission_format.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bert0 = pd.read_csv('models/ZeroShot/0/eval-eval/test_results_None.txt', sep='\\t')\n",
    "edf_bert0_probs = pd.read_csv('models/ZeroShot/0/eval-eval/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ez_score, ez_probs, ez_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], e_emb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols3 = ['Top score 1', 'FS', 'MWEdiff']\n",
    "zdf_et3 = fitter.get_trainable(zdf_bt3).drop(dropcols3, axis=1)\n",
    "edf_et3 = fitter.get_trainable(edf_bt3).drop(dropcols3, axis=1)\n",
    "\n",
    "edf_feat_score3, edf_feat_probs3, edf_feat_results3 = fitter.get_fit_results(zdf_et3, zdf['Label'], edf_et3)\n",
    "edf_comb3 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes','!Trans'])\n",
    "edf_comb3.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res1 = edf_sub.copy()\n",
    "edf_res1.loc[edf_res1['Setting'] == 'zero_shot', 'Label'] = edf_comb3['Prediction']\n",
    "edf_res1.to_csv('data/eval_sub_20220113_sft.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c73aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb4 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes'])\n",
    "edf_res2 = edf_sub.copy()\n",
    "edf_res2.loc[edf_res1['Setting'] == 'zero_shot', 'Label'] = edf_comb4['Prediction']\n",
    "# edf_res2.to_csv('data/eval_sub_20220113_sf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert1 = fitter.multi_results(edf_bt3, None, edf_bert0['prediction'].astype('str'), edf_bert0_probs['probs'],\n",
    "                                      edf_feat_results3, edf_feat_probs3,\n",
    "                                      ['Caps','Hassub'],['Quotes','!Trans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert1 = edf_sub.copy()\n",
    "edf_res_bert1.loc[edf_res_bert1['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert1['Prediction']\n",
    "# edf_res_bert1.to_csv('data/eval_sub_20220113_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4216f0e",
   "metadata": {},
   "source": [
    "This one gets a result of 0.6711207561."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert1p = fitter.multi_results(edf_bt3, None, edf_bert0['prediction'].astype('str'), edf_bert0_probs['probs'],\n",
    "                                       edf_feat_results3, edf_feat_probs3,\n",
    "                                       ['Caps','Hassub'],['Quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df971870",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert1p = edf_sub.copy()\n",
    "edf_res_bert1p.loc[edf_res_bert1p['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert1p['Prediction']\n",
    "# edf_res_bert1p.to_csv('data/eval_sub_20220113_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b8e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert2 = fitter.multi_results(edf_bt3, None, edf_bert0['prediction'].astype('str'),\n",
    "                                      edf_bert0_probs['probs'], edf_feat_results3, edf_feat_probs3,\n",
    "                                      ['Caps','Hassub'],['Quotes'], agreeonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddfc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert2 = edf_sub.copy()\n",
    "edf_res_bert2.loc[edf_res_bert1['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert2['Prediction']\n",
    "# edf_res_bert2.to_csv('data/eval_sub_20220113_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632028e",
   "metadata": {},
   "source": [
    "This model finally gets a better result than baseline (72.3% vs 70.2%). This essentially means:\n",
    " - use the prediction if models agree\n",
    " - if they disagree\n",
    "   - use the BERT base model (because of confidence) except when boolean features Quotes, Caps or Hassub say otherwise.\n",
    "   - Trans feature (idiomatic interpretation if Trans==False) didn't turn out to be useful.\n",
    "   \n",
    "However, using the base BERT model (English for English and multilingual for Portuguese) is a just a tiny bit higher (72.3%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f45ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bert1 = pd.read_csv('models/ZeroShot/1/eval-eval/test_results_None.txt', sep='\\t')\n",
    "edf_bert1_probs = pd.read_csv('models/ZeroShot/1/eval-eval/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26672b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bert_comb = edf_bert0.copy()\n",
    "edf_bert_comb_probs = edf_bert0_probs.copy()\n",
    "for idx,row in edf_bert1.iterrows():\n",
    "    _idx,_pred = row\n",
    "    edf_bert_comb.loc[_idx,'prediction'] = _pred\n",
    "for idx,row in edf_bert1_probs.iterrows():\n",
    "    _idx,_pred = row\n",
    "    edf_bert_comb_probs.loc[_idx,'prediction'] = _pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert3 = fitter.multi_results(edf_bt3, None, \n",
    "                                      edf_bert_comb['prediction'].astype('str'), edf_bert_comb_probs['probs'], \n",
    "                                      edf_feat_results3, edf_feat_probs3,\n",
    "                                      ['Caps','Hassub'],['Quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ac68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert4 = fitter.multi_results(edf_bt3, None, \n",
    "                                      edf_bert_comb['prediction'].astype('str'), edf_bert_comb_probs['probs'], \n",
    "                                      edf_feat_results3, edf_feat_probs3,\n",
    "                                      ['Caps','Hassub'],['Quotes'], agreeonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878be7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert3 = edf_sub.copy()\n",
    "edf_res_bert3.loc[edf_res_bert3['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert3['Prediction']\n",
    "# edf_res_bert3.to_csv('data/eval_sub_20220113_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert4 = edf_sub.copy()\n",
    "edf_res_bert4.loc[edf_res_bert4['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert4['Prediction']\n",
    "# edf_res_bert4.to_csv('data/eval_sub_20220113_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e6bd7",
   "metadata": {},
   "source": [
    "Using the English BERT for English improves the result a little bit at 72.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_eval = pd.DataFrame(columns=['Name', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_eval.loc['sbert'] = ['Sentence transformers', 0.5580687255]\n",
    "resdf_eval.loc['sbert_feat'] = ['Sentence transformers + feature', 0.6459566501]\n",
    "resdf_eval.loc['BERT'] = ['BERT', 0.7024610232]\n",
    "resdf_eval.loc['BERT_multi'] = ['BERT (multi)', 0.7229592232]\n",
    "resdf_eval.loc['BERT_feat'] = ['BERT + feature', 0.7144442603]\n",
    "resdf_eval.loc['BERT_feat_trans'] = ['BERT + feature + trans', 0.6711207561]\n",
    "resdf_eval.loc['BERT_feat_agree'] = ['BERT + feature (agree)', 0.7229308218]\n",
    "resdf_eval.loc['BERT_multi_feat'] = ['BERT (multi) + feature', 0.7202048507]\n",
    "resdf_eval.loc['BERT_multi_feat_agree'] = ['BERT (multi) + feature (agree)', 0.7252418204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e640c2",
   "metadata": {},
   "source": [
    "### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee416ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bert0 = pd.read_csv('models/ZeroShot/0/eval-test/test_results_None.txt', sep='\\t')\n",
    "tdf_bert0_probs = pd.read_csv('models/ZeroShot/0/eval-test/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d98ef",
   "metadata": {},
   "source": [
    "#### Sentence transformers + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_score, tz_probs, tz_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], t_emb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols4 = ['Top score 1', 'FS', 'MWEdiff']\n",
    "zdf_tt1 = fitter.get_trainable(zdf_bt3).drop(dropcols3, axis=1)\n",
    "tdf_tt1 = fitter.get_trainable(tdf_bt3).drop(dropcols3, axis=1)\n",
    "\n",
    "tdf_feat_score, tdf_feat_probs, tdf_feat_results = fitter.get_fit_results(zdf_tt1, zdf['Label'], tdf_tt1)\n",
    "tdf_comb = fitter.multi_results(tdf_bt3, None, tz_results, tz_probs, tdf_feat_results, tdf_feat_probs, ['Caps','Hassub'],['Quotes'])\n",
    "tdf_comb.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc5853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res1 = tdf_sub.copy()\n",
    "tdf_res1.loc[tdf_res1['Setting'] == 'zero_shot', 'Label'] = tdf_comb['Prediction']\n",
    "# tdf_res1.to_csv('data/test_sub_20220114_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f4db89",
   "metadata": {},
   "source": [
    "#### Baseline BERT + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert = fitter.multi_results(tdf_bt3, None, tdf_bert0['prediction'].astype('str'), tdf_bert0_probs['probs'],\n",
    "                                     tdf_feat_results, tdf_feat_probs,\n",
    "                                     ['Caps','Hassub'],['Quotes'])\n",
    "tdf_comb_bert.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41270352",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res2 = tdf_sub.copy()\n",
    "tdf_res2.loc[tdf_res2['Setting'] == 'zero_shot', 'Label'] = tdf_comb_bert['Prediction']\n",
    "# tdf_res2.to_csv('data/test_sub_20220114_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e698307",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert2 = fitter.multi_results(tdf_bt3, None, tdf_bert0['prediction'].astype('str'), tdf_bert0_probs['probs'],\n",
    "                                      tdf_feat_results, tdf_feat_probs,\n",
    "                                      ['Caps','Hassub'],['Quotes'], agreeonly=True)\n",
    "tdf_comb_bert2.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9daa1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res3 = tdf_sub.copy()\n",
    "tdf_res3.loc[tdf_res3['Setting'] == 'zero_shot', 'Label'] = tdf_comb_bert2['Prediction']\n",
    "# tdf_res3.to_csv('data/test_sub_20220114_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1664ad3",
   "metadata": {},
   "source": [
    "#### Baseline BERT (multi) + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bert1 = pd.read_csv('models/ZeroShot/1/eval-test/test_results_None.txt', sep='\\t')\n",
    "tdf_bert1_probs = pd.read_csv('models/ZeroShot/1/eval-test/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bert_comb = tdf_bert0.copy()\n",
    "tdf_bert_comb_probs = tdf_bert0_probs.copy()\n",
    "for idx,row in tdf_bert1.iterrows():\n",
    "    _idx,_pred = row\n",
    "    tdf_bert_comb.loc[_idx,'prediction'] = _pred\n",
    "for idx,row in tdf_bert1_probs.iterrows():\n",
    "    _idx,_pred = row\n",
    "    tdf_bert_comb_probs.loc[_idx,'prediction'] = _pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert3 = fitter.multi_results(tdf_bt3, None, \n",
    "                                      tdf_bert_comb['prediction'].astype('str'), tdf_bert_comb_probs['probs'], \n",
    "                                      tdf_feat_results, tdf_feat_probs,\n",
    "                                      ['Caps','Hassub'],['Quotes'])\n",
    "tdf_comb_bert3.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res4 = tdf_sub.copy()\n",
    "tdf_res4.loc[tdf_res4['Setting'] == 'zero_shot', 'Label'] = tdf_comb_bert3['Prediction']\n",
    "# tdf_res4.to_csv('data/test_sub_20220114_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0dff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert4 = fitter.multi_results(tdf_bt3, None, \n",
    "                                      tdf_bert_comb['prediction'].astype('str'), tdf_bert_comb_probs['probs'], \n",
    "                                      tdf_feat_results, tdf_feat_probs,\n",
    "                                      ['Caps','Hassub'],['Quotes'], agreeonly=True)\n",
    "tdf_comb_bert4.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3581625",
   "metadata": {},
   "source": [
    "This is the final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1206be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res5 = tdf_sub.copy()\n",
    "tdf_res5.loc[tdf_res4['Setting'] == 'zero_shot', 'Label'] = tdf_comb_bert4['Prediction']\n",
    "# tdf_res5.to_csv('data/test_sub_20220114_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5dfd43",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Code for outputting the results to latex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev2 = resdf_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev2['Configuration'] = [\n",
    "    'Hassub', 'Trans', 'Sentiment', 'Majority class',\n",
    "    'Sentence transformers', '+ feature',\n",
    "    'BERT baseline',\n",
    "    '+ multilingual 1: PT from full model',\n",
    "    '+ multilingual 2: PT from separate model',\n",
    "    '+ feature',\n",
    "    '+ multilingual 1 + feature',\n",
    "    '+ multilingual 1 + feature, agree',\n",
    "    '+ multilingual 1 + feature + trans',\n",
    "    '+ multilingual 1 + feature + trans, agree',\n",
    "    '+ multilingual 2 + feature + trans, agree',\n",
    "    'Majority voting + trans',\n",
    "    'Majority voting + trans, agree'\n",
    "]\n",
    "resdf_dev2['F1'] = resdf_dev2['Score']\n",
    "resdf_dev2['EN'] = resdf_dev2['ScoreEN']\n",
    "resdf_dev2['PT'] = resdf_dev2['ScorePT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34328efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev2.drop(['Name', 'Score', 'ScoreEN', 'ScorePT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94198ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.save_table(resdf_dev2.drop(['Name', 'Score', 'ScoreEN', 'ScorePT'], axis=1), 'dev_results', index=False, hlines=[6, 8, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c97b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_eval2 = resdf_eval.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_eval2['Configuration'] = [\n",
    "    'Sentence transformers', '+ feature',\n",
    "    'BERT baseline',\n",
    "    '+ multilingual 1',\n",
    "    '+ feature',\n",
    "    '+ feature + trans',\n",
    "    '+ feature, agree',\n",
    "    '+ multilingual 1 + feature',\n",
    "    '+ multilingual 1 + feature, agree',\n",
    "]\n",
    "resdf_eval2['F1'] = resdf_eval2['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.save_table(resdf_eval2.drop(['Name', 'Score'], axis=1), 'eval_results', index=False, hlines=[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d30fba",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hassub_drops = ['Quotes', 'Caps', 'Sentiment', 'BT', 'Trans',\n",
    "                'Prevdiff', 'Nextdiff', 'MWEdiff', 'Previous', 'Next',\n",
    "                'Top terms 1', 'Top terms 2', 'Top score 1', 'Top score 2', 'FS', 'SS',\n",
    "                'Language', 'Setting', 'MWE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb112176",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3 = zdf_bt3.astype({'Hassub': bool, 'Quotes': bool, 'Caps': bool, 'Trans': bool})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be255e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_hassub = zdf_bt3.drop(hassub_drops, axis=1).astype({'Short': int, 'FoundIdx': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_quotes = zdf_bt3.drop(['Previous', 'Next', 'Language', 'Setting'], axis=1)\n",
    "zdf_trans = zdf_quotes.copy()\n",
    "for col in zdf_quotes.columns[4:]:\n",
    "    if col not in ['Caps', 'Quotes']:\n",
    "        zdf_quotes.drop(col, axis=1, inplace=True)\n",
    "    if col not in ['BT','Trans']:\n",
    "        zdf_trans.drop(col, axis=1, inplace=True)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_hassub.iloc[[0, 1, 3509, 3512, 3520]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "hascolformat = {'Target': 'p{5cm}', 'Top terms': 'p{2.2cm}', \n",
    "                'Top score': 'p{1cm}',\n",
    "                'FoundIdx': 'p{1cm}', 'FoundScore': 'p{1cm}',\n",
    "               }\n",
    "# util.save_table(zdf_hassub.iloc[[0, 1, 3509, 3512, 3520]], 'zdf_hassub2', index=False, colformat=hascolformat, hlines=[2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_quotes.iloc[[1, 2, 7, 12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88773743",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotecolformat = {'Target': 'p{10cm}'}\n",
    "# util.save_table(zdf_quotes.iloc[[1, 2, 7, 12]], 'zdf_quotes', index=False, colformat=quotecolformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c966575",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_trans.iloc[[6,7,4085,4088,4474]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcolformat = {'Target': 'p{5cm}', 'BT': 'p{5cm}'}\n",
    "# util.save_table(zdf_trans.iloc[[6,7,4085,4088,4474]], 'zdf_trans', index=False, colformat=transcolformat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759731ec",
   "metadata": {},
   "source": [
    "#### Get literal/idiomatic percentages for good MWE examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_counts = util.get_counts(zdf_bt3, 'DataID').drop(columns='Pct correct', axis=1)\n",
    "z_counts[(z_counts['Pct literal'] > 0.4) & (z_counts['Pct literal'] < 0.6)].sort_values(by=['Language','MWE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f474d",
   "metadata": {},
   "source": [
    "#### Analyze Hassub results for Galician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46337965",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert4[(tdf_comb_bert4['Language'] == 'GL') & (tdf_comb_bert4['Hassub'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6d1fb",
   "metadata": {},
   "source": [
    "# Extra sets for post-competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e3b52",
   "metadata": {},
   "source": [
    "#### Extra sets for post-competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_featonly = fitter.multi_results(tdf_bt3, None, \n",
    "                                    tdf_feat_results, tdf_feat_probs,\n",
    "                                    tdf_feat_results, tdf_feat_probs,\n",
    "                                    ['Caps','Hassub'],['Quotes'])\n",
    "tdf_featonly.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res_new1 = tdf_sub.copy()\n",
    "tdf_res_new1.loc[tdf_res_new1['Setting'] == 'zero_shot', 'Label'] = tdf_featonly['Prediction']\n",
    "# tdf_res_new1.to_csv('data/test_sub_20220205_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c40db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_featonly2 = fitter.multi_results(tdf_bt3, None, \n",
    "                                     tdf_feat_results, tdf_feat_probs,\n",
    "                                     tdf_feat_results, tdf_feat_probs,\n",
    "                                     ['Caps'],['Quotes'])\n",
    "tdf_featonly2.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197793f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_featonly2[tdf_featonly['Prediction'] != tdf_featonly2['Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345351d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res_new1p = tdf_sub.copy()\n",
    "tdf_res_new1p.loc[tdf_res_new1p['Setting'] == 'zero_shot', 'Label'] = tdf_featonly2['Prediction']\n",
    "# tdf_res_new1p.to_csv('data/test_sub_20220205_1p.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ae158",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert4[tdf_featonly['Prediction'] != tdf_comb_bert4['Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert4.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed81478",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bert_new1 = fitter.multi_results(tdf_bt3, None, \n",
    "                                     tdf_bert_comb['prediction'].astype('str'), tdf_bert_comb_probs['probs'], \n",
    "                                     tdf_feat_results, tdf_feat_probs,\n",
    "                                     ['Caps','Hassub'],['Quotes'])\n",
    "tdf_bert_new1.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4089c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res_new2 = tdf_sub.copy()\n",
    "tdf_res_new2.loc[tdf_res_new2['Setting'] == 'zero_shot', 'Label'] = tdf_bert_new1['Prediction']\n",
    "# tdf_res_new2.to_csv('data/test_sub_20220205_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37adc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bert_new1[tdf_bert_new1['Prediction'] != tdf_comb_bert4['Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6fdd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bert_new2 = fitter.multi_results(tdf_bt3, None, \n",
    "                                     tdf_bert_comb['prediction'].astype('str'), tdf_bert_comb_probs['probs'], \n",
    "                                     tdf_feat_results, tdf_feat_probs,\n",
    "                                     ['Caps'],['Quotes'], agreeonly=True)\n",
    "tdf_bert_new2.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea859889",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res_new3 = tdf_sub.copy()\n",
    "tdf_res_new3.loc[tdf_res_new3['Setting'] == 'zero_shot', 'Label'] = tdf_bert_new2['Prediction']\n",
    "# tdf_res_new3.to_csv('data/test_sub_20220205_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e396938",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res_new4 = tdf_sub.copy()\n",
    "tdf_res_new4.loc[(tdf_res_new4['Setting'] == 'zero_shot') & \n",
    "                 (tdf_res_new4['Language'] == 'EN'), 'Label'] = tdf_bert_new2.loc[tdf_bert_new2['Language'] == 'EN', 'Prediction']\n",
    "tdf_res_new4.loc[(tdf_res_new4['Setting'] == 'zero_shot') & \n",
    "                 (tdf_res_new4['Language'] != 'EN'), 'Label'] = tdf_featonly2.loc[tdf_featonly2['Language'] != 'EN', 'Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa94f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res_new4[tdf_res_new4['Label'] != tdf_res_new3['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res_new4[tdf_res_new4['Label'] != tdf_res_new1p['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf_res_new4.to_csv('data/test_sub_20220214_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda32d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
