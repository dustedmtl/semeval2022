{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beccb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important; }</style>\"))\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af70584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da023b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import util, embeds, fitter, masker, features, sentiment, translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data'\n",
    "multilingual_model = 'distiluse-base-multilingual-cased-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = util.load_csv_dataframes(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740314e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = frames['train_zero_shot.csv']\n",
    "odf = frames['train_one_shot.csv']\n",
    "ddf = frames['dev.csv']\n",
    "ddf_gold = frames['dev_gold.csv']\n",
    "edf = frames['eval.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_emb_multi = embeds.get_embeddings(zdf, modelname=multilingual_model, append=['MWE'])\n",
    "d_emb_multi = embeds.get_embeddings(ddf, modelname=multilingual_model, append=['MWE'])\n",
    "e_emb_multi = embeds.get_embeddings(edf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddde188",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score, z_probs, z_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], d_emb_multi, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5fa6a",
   "metadata": {},
   "source": [
    "### Reload stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cc68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3 = pd.read_pickle('data/zdf_bt3_20220104_1.pkl')\n",
    "ddf_bt3 = pd.read_pickle('data/ddf_bt3_20220104_1.pkl')\n",
    "edf_bt3 = pd.read_pickle('data/edf_bt3_20220105_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ead71",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_sub = frames['eval_submission_format.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropcols = ['Top score', 'FS', 'SS', 'Quotes', 'MWEdiff']\n",
    "# dropcols = ['Hassub', 'FS', 'Nextdiff']\n",
    "dropcols = ['MWEdiff', 'FS']\n",
    "# dropcols = ['Top score 1', 'FS', 'MWEdiff']\n",
    "zdf_t4 = fitter.get_trainable(zdf_bt3).drop(dropcols, axis=1)\n",
    "ddf_t4 = fitter.get_trainable(ddf_bt3).drop(dropcols, axis=1)\n",
    "ddf5_feat_score, ddf5_feat_probs, ddf5_feat_results = fitter.get_fit_results(zdf_t4, zdf['Label'], ddf_t4, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080df3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf5_feat_results, ddf5_feat_probs, ['Caps', 'Hassub'],['Quotes'])\n",
    "f1_score(mup['Prediction'], mup['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0af21",
   "metadata": {},
   "source": [
    "### Results from BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13420718",
   "metadata": {},
   "source": [
    "##### Multilingual model for both EN,PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddda831",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bert0 = pd.read_csv('models/ZeroShot/0/eval-dev/test_results_None.txt', sep='\\t')\n",
    "ddf_bert0_probs = pd.read_csv('models/ZeroShot/0/eval-dev/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64276134",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(ddf_bert0['prediction'].astype('str'), ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c98a9",
   "metadata": {},
   "source": [
    "##### English model for English, multilingual model for PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bert1 = pd.read_csv('models/ZeroShot/1/eval-dev/test_results_None.txt', sep='\\t')\n",
    "ddf_bert1_probs = pd.read_csv('models/ZeroShot/1/eval-dev/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bert_comb = ddf_bert0.copy()\n",
    "ddf_bert_comb_probs = ddf_bert0_probs.copy()\n",
    "for idx,row in ddf_bert1.iterrows():\n",
    "    _idx,_pred = row\n",
    "    ddf_bert_comb.loc[_idx,'prediction'] = _pred\n",
    "for idx,row in ddf_bert1_probs.iterrows():\n",
    "    _idx,_pred = row\n",
    "    ddf_bert_comb_probs.loc[_idx,'prediction'] = _pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10ba0e",
   "metadata": {},
   "source": [
    "#### Combine BERT with feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup0 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert0['prediction'].astype('str'), ddf_bert0_probs['probs'],\n",
    "                            ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes'], agreeonly=True)\n",
    "f1_score(mup0['Prediction'], mup0['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3c250",
   "metadata": {},
   "source": [
    "##### Combine BERT (en+pt) with feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e905717",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup1 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                            ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes'], agreeonly=True)\n",
    "f1_score(mup1['Prediction'], mup1['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d74be",
   "metadata": {},
   "source": [
    "#### Eval results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bert0 = pd.read_csv('models/ZeroShot/0/eval-eval/test_results_None.txt', sep='\\t')\n",
    "edf_bert0_probs = pd.read_csv('models/ZeroShot/0/eval-eval/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ez_score, ez_probs, ez_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], e_emb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols3 = ['Top score', 'Hassub', 'Short', 'Nextdiff', 'MWEdiff']\n",
    "zdf_et3 = fitter.get_trainable(zdf_bt3).drop(dropcols3, axis=1)\n",
    "edf_et3 = fitter.get_trainable(edf_bt3).drop(dropcols3, axis=1)\n",
    "\n",
    "edf_feat_score3, edf_feat_probs3, edf_feat_results3 = fitter.get_fit_results(zdf_et3, zdf['Label'], edf_et3)\n",
    "edf_comb3 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes','!Trans'])\n",
    "edf_comb3.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert1 = fitter.multi_results(edf_bt3, None, edf_bert0['prediction'].astype('str'), edf_bert0_probs['probs'], edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes','!Trans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert1 = edf_sub.copy()\n",
    "edf_res_bert1.loc[edf_res_bert1['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert1['Prediction']\n",
    "edf_res_bert1.to_csv('data/eval_sub_20220103_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0112e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert1[edf_comb_bert1['Pred1'] != edf_comb_bert1['Pred2']][['ID', 'MWE', 'Target', 'Trans', 'Caps', 'Hassub', 'Pred1', 'Pred2',\n",
    "                                                                    'Prediction', 'PredictionTrans', 'PredictionQuotes', 'PredictionCaps', 'PredictionHassub']][50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b8e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert2 = fitter.multi_results(edf_bt3, None, edf_bert0['prediction'].astype('str'), edf_bert0_probs['probs'], edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddfc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert2 = edf_sub.copy()\n",
    "edf_res_bert2.loc[edf_res_bert1['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert2['Prediction']\n",
    "edf_res_bert2.to_csv('data/eval_sub_20220103_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81174d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert2[edf_comb_bert2['Pred1'] != edf_comb_bert2['Pred2']][['ID', 'MWE', 'Target', 'Trans', 'Caps', 'Hassub', 'Pred1', 'Pred2',\n",
    "                                                                    'Prediction', 'PredictionQuotes', 'PredictionCaps', 'PredictionHassub']][50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632028e",
   "metadata": {},
   "source": [
    "This model finally gets a better result than baseline (71.6% vs 70.2%). This essentially means:\n",
    " - use the prediction if models agree\n",
    " - if they disagree\n",
    "   - use the BERT base model (because of confidence) except when boolean features Quotes, Caps or Hassub say otherwise.\n",
    "   - Trans feature (idiomatic interpretation if Trans==False) didn't turn out to be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f45ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bert1 = pd.read_csv('models/ZeroShot/1/eval-eval/test_results_None.txt', sep='\\t')\n",
    "edf_bert1_probs = pd.read_csv('models/ZeroShot/1/eval-eval/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26672b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bert_comb = edf_bert0.copy()\n",
    "edf_bert_comb_probs = edf_bert0_probs.copy()\n",
    "for idx,row in edf_bert1.iterrows():\n",
    "    _idx,_pred = row\n",
    "    edf_bert_comb.loc[_idx,'prediction'] = _pred\n",
    "for idx,row in edf_bert1_probs.iterrows():\n",
    "    _idx,_pred = row\n",
    "    edf_bert_comb_probs.loc[_idx,'prediction'] = _pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert3 = fitter.multi_results(edf_bt3, None, edf_bert_comb['prediction'].astype('str'), edf_bert_comb_probs['probs'], edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878be7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert3 = edf_sub.copy()\n",
    "edf_res_bert3.loc[edf_res_bert3['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert3['Prediction']\n",
    "edf_res_bert3.to_csv('data/eval_sub_20220103_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert3[edf_comb_bert3['Prediction'] != edf_comb_bert2['Prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e6bd7",
   "metadata": {},
   "source": [
    "Surprisingly, using the English BERT for English only improves the result a tiny bit (71.66 > 71.62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c6672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
