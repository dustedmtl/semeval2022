{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beccb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important; }</style>\"))\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af70584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da023b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import util, embeds, fitter, masker, features, sentiment, translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data'\n",
    "testpath = 'SemEval_2022_Task2-idiomaticity/SubTaskA/TestData'\n",
    "multilingual_model = 'distiluse-base-multilingual-cased-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = util.load_csv_dataframes(datapath)\n",
    "tframes = util.load_csv_dataframes(testpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740314e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = frames['train_zero_shot.csv']\n",
    "odf = frames['train_one_shot.csv']\n",
    "ddf = frames['dev.csv']\n",
    "ddf_gold = frames['dev_gold.csv']\n",
    "edf = frames['eval.csv']\n",
    "tdf = tframes['test.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_emb_multi = embeds.get_embeddings(zdf, modelname=multilingual_model, append=['MWE'])\n",
    "d_emb_multi = embeds.get_embeddings(ddf, modelname=multilingual_model, append=['MWE'])\n",
    "e_emb_multi = embeds.get_embeddings(edf, modelname=multilingual_model, append=['MWE'])\n",
    "t_emb_multi = embeds.get_embeddings(tdf, modelname=multilingual_model, append=['MWE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddde188",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score, z_probs, z_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], d_emb_multi, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17bb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(z_results, ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb8ca7",
   "metadata": {},
   "source": [
    "Using only sentence-transformers embeddings results in 61.4% score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2deca",
   "metadata": {},
   "source": [
    "Create a dataframe for the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev = pd.DataFrame(columns=['Name', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e54916",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['sbert'] = ['Sentence transformers', f1_score(z_results, ddf_gold['Label'], average='macro')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5fa6a",
   "metadata": {},
   "source": [
    "### Reload stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cc68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt3 = pd.read_pickle('data/zdf_bt3_20220104_1.pkl')\n",
    "ddf_bt3 = pd.read_pickle('data/ddf_bt3_20220104_1.pkl')\n",
    "edf_bt3 = pd.read_pickle('data/edf_bt3_20220105_1.pkl')\n",
    "tdf_bt3 = pd.read_pickle('data/tdf_bt3_20220111_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ead71",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_sub = frames['eval_submission_format.csv']\n",
    "tdf_sub = tframes['test_submission_format.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropcols = ['Top score', 'FS', 'SS', 'Quotes', 'MWEdiff']\n",
    "# dropcols = ['Hassub', 'FS', 'Nextdiff']\n",
    "# dropcols = ['MWEdiff', 'FS']\n",
    "# dropcols = ['Top score 1', 'Top score 2', 'SS', 'FS', 'MWEdiff']\n",
    "dropcols = ['Top score 1', 'FS', 'MWEdiff']\n",
    "zdf_t4 = fitter.get_trainable(zdf_bt3).drop(dropcols, axis=1)\n",
    "ddf_t4 = fitter.get_trainable(ddf_bt3).drop(dropcols, axis=1)\n",
    "ddf5_feat_score, ddf5_feat_probs, ddf5_feat_results = fitter.get_fit_results(zdf_t4, zdf['Label'], ddf_t4, ddf_gold['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080df3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf5_feat_results, ddf5_feat_probs, ['Caps', 'Hassub'],['Quotes'])\n",
    "f1_score(mup['Prediction'], mup['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4beeeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['sbert_feat'] = ['Sentence transformers + feature', f1_score(mup['Prediction'], mup['Label'], average='macro')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d42bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_sub = frames['dev_submission_format.csv']\n",
    "ddf_res = ddf_sub.copy()\n",
    "ddf_res.loc[ddf_res['Setting'] == 'zero_shot', 'Label'] = mup['Prediction']\n",
    "ddf_res.to_csv('data/ddf_sub_20220121_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11630b",
   "metadata": {},
   "source": [
    "#### Normalization of sentiment scores\n",
    "\n",
    "Trying to see if normalizing sentiment helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ca5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zdf_bt3[zdf_bt3['Language'] == 'EN']['Sentiment'].mean())\n",
    "print(zdf_bt3[zdf_bt3['Language'] == 'PT']['Sentiment'].mean())\n",
    "sentdiff = zdf_bt3[zdf_bt3['Language'] == 'PT']['Sentiment'].mean() - zdf_bt3[zdf_bt3['Language'] == 'EN']['Sentiment'].mean()\n",
    "print(sentdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt4 = zdf_bt3.copy()\n",
    "zdf_bt4['SentNorm'] = zdf_bt4['Sentiment']\n",
    "zdf_bt4.loc[zdf_bt4['Language'] == 'PT', 'SentNorm'] -= sentdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cdc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ddf_bt3[ddf_bt3['Language'] == 'EN']['Sentiment'].mean())\n",
    "print(ddf_bt3[ddf_bt3['Language'] == 'PT']['Sentiment'].mean())\n",
    "sentdiff_d = ddf_bt3[ddf_bt3['Language'] == 'PT']['Sentiment'].mean() - ddf_bt3[ddf_bt3['Language'] == 'EN']['Sentiment'].mean()\n",
    "print(sentdiff_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e4b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bt4 = ddf_bt3.copy()\n",
    "ddf_bt4['SentNorm'] = ddf_bt4['Sentiment']\n",
    "ddf_bt4.loc[ddf_bt4['Language'] == 'PT', 'SentNorm'] -= sentdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols_s = ['Top score 1', 'FS', 'MWEdiff', 'Sentiment']\n",
    "zdf_t6 = fitter.get_trainable(zdf_bt4).drop(dropcols_s, axis=1)\n",
    "ddf_t6 = fitter.get_trainable(ddf_bt4).drop(dropcols_s, axis=1)\n",
    "ddf7_feat_score, ddf7_feat_probs, ddf7_feat_results = fitter.get_fit_results(zdf_t6, zdf['Label'], ddf_t6, ddf_gold['Label'])\n",
    "mup_s = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf7_feat_results, ddf7_feat_probs, ['Caps', 'Hassub'],['Quotes'])\n",
    "f1_score(mup_s['Prediction'], mup_s['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83c764",
   "metadata": {},
   "source": [
    "Normalization of the Sentiment scores doesn't seem to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_bt5 = pd.get_dummies(zdf_bt3, columns=['Language'])\n",
    "#zdf_bt5['OneHotEN'] = zdf_bt5['OneHotPT'] = zdf_bt5['OneHotGL'] = 0\n",
    "#zdf_bt5.loc[zdf_bt5['Language'] == 'EN', 'OneHotEN'] = 1\n",
    "#zdf_bt5.loc[zdf_bt5['Language'] == 'PT', 'OneHotPT'] = 1\n",
    "#zdf_bt5.loc[zdf_bt5['Language'] == 'GL', 'OneHotGL'] = 1\n",
    "ddf_bt5 = pd.get_dummies(ddf_bt3, columns=['Language'])\n",
    "ddf_bt5 = ddf_bt3.copy()\n",
    "#ddf_bt5['OneHotEN'] = ddf_bt5['OneHotPT'] = ddf_bt5['OneHotGL'] = 0\n",
    "#ddf_bt5.loc[ddf_bt5['Language'] == 'EN', 'OneHotEN'] = 1\n",
    "#ddf_bt5.loc[ddf_bt5['Language'] == 'PT', 'OneHotPT'] = 1\n",
    "#ddf_bt5.loc[ddf_bt5['Language'] == 'GL', 'OneHotGL'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols_m = ['Top score 1', 'FS', 'MWEdiff', 'Top score', 'Top score 2']\n",
    "zdf_t7 = fitter.get_trainable(zdf_bt5).drop(dropcols_m, axis=1)\n",
    "ddf_t7 = fitter.get_trainable(ddf_bt5).drop(dropcols_m, axis=1)\n",
    "ddf8_feat_score, ddf8_feat_probs, ddf8_feat_results = fitter.get_fit_results(zdf_t7, zdf['Label'], ddf_t7, ddf_gold['Label'])\n",
    "mup_m = fitter.multi_results(ddf_bt3, ddf_gold, z_results, z_probs, ddf8_feat_results, ddf8_feat_probs, ['Caps', 'Hassub'],['Quotes'])\n",
    "f1_score(mup_m['Prediction'], mup_m['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cc93e",
   "metadata": {},
   "source": [
    "Encoding the languages as One Hot variables doesn't change things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0af21",
   "metadata": {},
   "source": [
    "### Results from BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13420718",
   "metadata": {},
   "source": [
    "##### Multilingual model for both EN,PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddda831",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bert0 = pd.read_csv('models/ZeroShot/0/eval-dev/test_results_None.txt', sep='\\t')\n",
    "ddf_bert0_probs = pd.read_csv('models/ZeroShot/0/eval-dev/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64276134",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(ddf_bert0['prediction'].astype('str'), ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['BERT'] = ['BERT', f1_score(ddf_bert0['prediction'].astype('str'), ddf_gold['Label'], average='macro')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c98a9",
   "metadata": {},
   "source": [
    "##### English model for English, multilingual (full) model for PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bert1 = pd.read_csv('models/ZeroShot/1/eval-dev/test_results_None.txt', sep='\\t')\n",
    "ddf_bert1_probs = pd.read_csv('models/ZeroShot/1/eval-dev/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2868f0",
   "metadata": {},
   "source": [
    "bert0 is the multilingual model, copy the results from the Enligsh model (bert1) over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_bert_comb = ddf_bert0.copy()\n",
    "ddf_bert_comb_probs = ddf_bert0_probs.copy()\n",
    "for idx,row in ddf_bert1.iterrows():\n",
    "    _idx,_pred = row\n",
    "    ddf_bert_comb.loc[_idx,'prediction'] = _pred\n",
    "for idx,row in ddf_bert1_probs.iterrows():\n",
    "    _idx,_pred = row\n",
    "    ddf_bert_comb_probs.loc[_idx,'prediction'] = _pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465449cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(ddf_bert_comb['prediction'].astype('str'), ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f698f49f",
   "metadata": {},
   "source": [
    "##### English model for English, multilingual (PT-only) model for PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ba8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_1 = util.load_df('models/ZeroShot/1/eval-dev/test_results_None.txt', delimiter=\"\\t\")\n",
    "dres_2 = util.load_df('models/ZeroShot/2/eval-dev/test_results_None.txt', delimiter=\"\\t\")\n",
    "dres_1['index'] = dres_1['index'].astype(int)\n",
    "dres_2['index'] = dres_2['index'].astype(int)\n",
    "dres_2['index'] += len(dres_1)\n",
    "dres_3 = pd.concat([dres_1, dres_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_1_p = util.load_df('models/ZeroShot/1/eval-dev/test_results_None.txt.probs', delimiter=\"\\t\")\n",
    "dres_2_p = util.load_df('models/ZeroShot/2/eval-dev/test_results_None.txt.probs', delimiter=\"\\t\")\n",
    "dres_1_p['index'] = dres_1_p['index'].astype(float)\n",
    "dres_2_p['index'] = dres_2_p['index'].astype(float)\n",
    "dres_2_p['index'] += len(dres_1_p)\n",
    "dres_3_p = pd.concat([dres_1_p, dres_2_p], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(dres_3['prediction'].astype('str'), ddf_gold['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14074a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['BERT_multi1'] = ['BERT multilingual, separate, PT results from full model', f1_score(ddf_bert_comb['prediction'].astype('str'), ddf_gold['Label'], average='macro')]\n",
    "resdf_dev.loc['BERT_multi2'] = ['BERT multilingual, separate', f1_score(dres_3['prediction'].astype('str'), ddf_gold['Label'], average='macro')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10ba0e",
   "metadata": {},
   "source": [
    "#### Combine BERT with feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup0 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert0['prediction'].astype('str'), ddf_bert0_probs['probs'],\n",
    "                            ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes'], agreeonly=True)\n",
    "f1_score(mup0['Prediction'], mup0['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3c250",
   "metadata": {},
   "source": [
    "##### Combine BERT (en+pt) with feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e905717",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup1 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                            ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes'])\n",
    "f1_score(mup1['Prediction'], mup1['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a984887",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_res2 = ddf_sub.copy()\n",
    "ddf_res2.loc[ddf_res2['Setting'] == 'zero_shot', 'Label'] = mup1['Prediction']\n",
    "ddf_res2.to_csv('data/ddf_sub_20220121_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce06976",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup2 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                            ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes'], agreeonly=True)\n",
    "f1_score(mup2['Prediction'], mup2['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafaef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup3 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                            ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes', '!Trans'])\n",
    "f1_score(mup3['Prediction'], mup3['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb260dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup4 = fitter.multi_results(ddf_bt3, ddf_gold, ddf_bert_comb['prediction'].astype('str'),\n",
    "                            ddf_bert_comb_probs['probs'], ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes', '!Trans'], agreeonly=True)\n",
    "f1_score(mup4['Prediction'], mup4['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064de730",
   "metadata": {},
   "outputs": [],
   "source": [
    "mup5 = fitter.multi_results(ddf_bt3, ddf_gold, dres_3['prediction'].astype('str'),\n",
    "                            dres_3_p['probs'].astype('float'), ddf5_feat_results, ddf5_feat_probs,\n",
    "                            ['Caps', 'Hassub'],\n",
    "                            ['Quotes', '!Trans'], agreeonly=True)\n",
    "f1_score(mup5['Prediction'], mup5['Label'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d47b74",
   "metadata": {},
   "source": [
    "In the end, using multilingual model only for Portuguese does not improve things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133851d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev.loc['BERT_feat'] = ['BERT + feature', f1_score(mup0['Prediction'], mup0['Label'], average='macro')]\n",
    "resdf_dev.loc['BERT_multi_feat'] = ['BERT (multi) + feature', f1_score(mup1['Prediction'], mup1['Label'], average='macro')]\n",
    "resdf_dev.loc['BERT_multi_feat_agree'] = ['BERT (multi) + feature (agreeonly)', f1_score(mup2['Prediction'], mup2['Label'], average='macro')]\n",
    "resdf_dev.loc['BERT_multi_feat_trans'] = ['BERT (multi) + feature + trans', f1_score(mup3['Prediction'], mup3['Label'], average='macro')]\n",
    "resdf_dev.loc['BERT_multi_feat_trans_agree'] = ['BERT (multi) + feature + trans (agreeonly)', f1_score(mup4['Prediction'], mup4['Label'], average='macro')]\n",
    "resdf_dev.loc['BERT_multi2_feat_trans_agree'] = ['BERT (multi2) + feature + trans (agreeonly)', f1_score(mup5['Prediction'], mup4['Label'], average='macro')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d74be",
   "metadata": {},
   "source": [
    "### Eval results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bert0 = pd.read_csv('models/ZeroShot/0/eval-eval/test_results_None.txt', sep='\\t')\n",
    "edf_bert0_probs = pd.read_csv('models/ZeroShot/0/eval-eval/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ez_score, ez_probs, ez_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], e_emb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols3 = ['Top score 1', 'FS', 'MWEdiff']\n",
    "zdf_et3 = fitter.get_trainable(zdf_bt3).drop(dropcols3, axis=1)\n",
    "edf_et3 = fitter.get_trainable(edf_bt3).drop(dropcols3, axis=1)\n",
    "\n",
    "edf_feat_score3, edf_feat_probs3, edf_feat_results3 = fitter.get_fit_results(zdf_et3, zdf['Label'], edf_et3)\n",
    "edf_comb3 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes','!Trans'])\n",
    "edf_comb3.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res1 = edf_sub.copy()\n",
    "edf_res1.loc[edf_res1['Setting'] == 'zero_shot', 'Label'] = edf_comb3['Prediction']\n",
    "edf_res1.to_csv('data/eval_sub_20220113_sft.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c73aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb4 = fitter.multi_results(edf_bt3, None, ez_results, ez_probs, edf_feat_results3, edf_feat_probs3, ['Caps','Hassub'],['Quotes'])\n",
    "edf_res2 = edf_sub.copy()\n",
    "edf_res2.loc[edf_res1['Setting'] == 'zero_shot', 'Label'] = edf_comb4['Prediction']\n",
    "# edf_res2.to_csv('data/eval_sub_20220113_sf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert1 = fitter.multi_results(edf_bt3, None, edf_bert0['prediction'].astype('str'), edf_bert0_probs['probs'],\n",
    "                                      edf_feat_results3, edf_feat_probs3,\n",
    "                                      ['Caps','Hassub'],['Quotes','!Trans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert1 = edf_sub.copy()\n",
    "edf_res_bert1.loc[edf_res_bert1['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert1['Prediction']\n",
    "# edf_res_bert1.to_csv('data/eval_sub_20220113_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4216f0e",
   "metadata": {},
   "source": [
    "This one gets a result of 0.6711207561."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert1p = fitter.multi_results(edf_bt3, None, edf_bert0['prediction'].astype('str'), edf_bert0_probs['probs'],\n",
    "                                       edf_feat_results3, edf_feat_probs3,\n",
    "                                       ['Caps','Hassub'],['Quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df971870",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert1p = edf_sub.copy()\n",
    "edf_res_bert1p.loc[edf_res_bert1p['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert1p['Prediction']\n",
    "# edf_res_bert1p.to_csv('data/eval_sub_20220113_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b8e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert2 = fitter.multi_results(edf_bt3, None, edf_bert0['prediction'].astype('str'),\n",
    "                                      edf_bert0_probs['probs'], edf_feat_results3, edf_feat_probs3,\n",
    "                                      ['Caps','Hassub'],['Quotes'], agreeonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddfc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert2 = edf_sub.copy()\n",
    "edf_res_bert2.loc[edf_res_bert1['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert2['Prediction']\n",
    "# edf_res_bert2.to_csv('data/eval_sub_20220113_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632028e",
   "metadata": {},
   "source": [
    "This model finally gets a better result than baseline (72.3% vs 70.2%). This essentially means:\n",
    " - use the prediction if models agree\n",
    " - if they disagree\n",
    "   - use the BERT base model (because of confidence) except when boolean features Quotes, Caps or Hassub say otherwise.\n",
    "   - Trans feature (idiomatic interpretation if Trans==False) didn't turn out to be useful.\n",
    "   \n",
    "However, using the base BERT model (English for English and multilingual for Portuguese) is a just a tiny bit higher (72.3%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f45ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bert1 = pd.read_csv('models/ZeroShot/1/eval-eval/test_results_None.txt', sep='\\t')\n",
    "edf_bert1_probs = pd.read_csv('models/ZeroShot/1/eval-eval/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26672b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_bert_comb = edf_bert0.copy()\n",
    "edf_bert_comb_probs = edf_bert0_probs.copy()\n",
    "for idx,row in edf_bert1.iterrows():\n",
    "    _idx,_pred = row\n",
    "    edf_bert_comb.loc[_idx,'prediction'] = _pred\n",
    "for idx,row in edf_bert1_probs.iterrows():\n",
    "    _idx,_pred = row\n",
    "    edf_bert_comb_probs.loc[_idx,'prediction'] = _pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert3 = fitter.multi_results(edf_bt3, None, \n",
    "                                      edf_bert_comb['prediction'].astype('str'), edf_bert_comb_probs['probs'], \n",
    "                                      edf_feat_results3, edf_feat_probs3,\n",
    "                                      ['Caps','Hassub'],['Quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ac68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_comb_bert4 = fitter.multi_results(edf_bt3, None, \n",
    "                                      edf_bert_comb['prediction'].astype('str'), edf_bert_comb_probs['probs'], \n",
    "                                      edf_feat_results3, edf_feat_probs3,\n",
    "                                      ['Caps','Hassub'],['Quotes'], agreeonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878be7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert3 = edf_sub.copy()\n",
    "edf_res_bert3.loc[edf_res_bert3['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert3['Prediction']\n",
    "# edf_res_bert3.to_csv('data/eval_sub_20220113_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_res_bert4 = edf_sub.copy()\n",
    "edf_res_bert4.loc[edf_res_bert4['Setting'] == 'zero_shot', 'Label'] = edf_comb_bert4['Prediction']\n",
    "# edf_res_bert4.to_csv('data/eval_sub_20220113_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e6bd7",
   "metadata": {},
   "source": [
    "Using the English BERT for English improves the result a little bit at 72.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_eval = pd.DataFrame(columns=['Name', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_eval.loc['sbert'] = ['Sentence transformers', 0.5580687255]\n",
    "resdf_eval.loc['sbert_feat'] = ['Sentence transformers + feature', 0.6459566501]\n",
    "resdf_eval.loc['BERT'] = ['BERT', 0.7024610232]\n",
    "resdf_eval.loc['BERT_multi'] = ['BERT (multi)', 0.7229592232]\n",
    "resdf_eval.loc['BERT_feat_trans'] = ['BERT + feature + trans', 0.6711207561]\n",
    "resdf_eval.loc['BERT_feat'] = ['BERT + feature', 0.7144442603]\n",
    "resdf_eval.loc['BERT_feat_agree'] = ['BERT + feature (agree)', 0.7229308218]\n",
    "resdf_eval.loc['BERT_multi_feat'] = ['BERT (multi) + feature', 0.7202048507]\n",
    "resdf_eval.loc['BERT_multi_feat_agree'] = ['BERT (multi) + feature (agree)', 0.7252418204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e640c2",
   "metadata": {},
   "source": [
    "### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee416ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bert0 = pd.read_csv('models/ZeroShot/0/eval-test/test_results_None.txt', sep='\\t')\n",
    "tdf_bert0_probs = pd.read_csv('models/ZeroShot/0/eval-test/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d98ef",
   "metadata": {},
   "source": [
    "#### Sentence transformers + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_score, tz_probs, tz_results = fitter.get_fit_results(z_emb_multi, zdf['Label'], t_emb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols4 = ['Top score 1', 'FS', 'MWEdiff']\n",
    "zdf_tt1 = fitter.get_trainable(zdf_bt3).drop(dropcols3, axis=1)\n",
    "tdf_tt1 = fitter.get_trainable(tdf_bt3).drop(dropcols3, axis=1)\n",
    "\n",
    "tdf_feat_score, tdf_feat_probs, tdf_feat_results = fitter.get_fit_results(zdf_tt1, zdf['Label'], tdf_tt1)\n",
    "tdf_comb = fitter.multi_results(tdf_bt3, None, tz_results, tz_probs, tdf_feat_results, tdf_feat_probs, ['Caps','Hassub'],['Quotes'])\n",
    "tdf_comb.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc5853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res1 = tdf_sub.copy()\n",
    "tdf_res1.loc[tdf_res1['Setting'] == 'zero_shot', 'Label'] = tdf_comb['Prediction']\n",
    "# tdf_res1.to_csv('data/test_sub_20220114_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f4db89",
   "metadata": {},
   "source": [
    "#### Baseline BERT + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert = fitter.multi_results(tdf_bt3, None, tdf_bert0['prediction'].astype('str'), tdf_bert0_probs['probs'],\n",
    "                                     tdf_feat_results, tdf_feat_probs,\n",
    "                                     ['Caps','Hassub'],['Quotes'])\n",
    "tdf_comb_bert.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41270352",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res2 = tdf_sub.copy()\n",
    "tdf_res2.loc[tdf_res2['Setting'] == 'zero_shot', 'Label'] = tdf_comb_bert['Prediction']\n",
    "# tdf_res2.to_csv('data/test_sub_20220114_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e698307",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert2 = fitter.multi_results(tdf_bt3, None, tdf_bert0['prediction'].astype('str'), tdf_bert0_probs['probs'],\n",
    "                                      tdf_feat_results, tdf_feat_probs,\n",
    "                                      ['Caps','Hassub'],['Quotes'], agreeonly=True)\n",
    "tdf_comb_bert2.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9daa1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res3 = tdf_sub.copy()\n",
    "tdf_res3.loc[tdf_res3['Setting'] == 'zero_shot', 'Label'] = tdf_comb_bert2['Prediction']\n",
    "# tdf_res3.to_csv('data/test_sub_20220114_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1664ad3",
   "metadata": {},
   "source": [
    "#### Baseline BERT (multi) + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bert1 = pd.read_csv('models/ZeroShot/1/eval-test/test_results_None.txt', sep='\\t')\n",
    "tdf_bert1_probs = pd.read_csv('models/ZeroShot/1/eval-test/test_results_None.txt.probs', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_bert_comb = tdf_bert0.copy()\n",
    "tdf_bert_comb_probs = tdf_bert0_probs.copy()\n",
    "for idx,row in tdf_bert1.iterrows():\n",
    "    _idx,_pred = row\n",
    "    tdf_bert_comb.loc[_idx,'prediction'] = _pred\n",
    "for idx,row in tdf_bert1_probs.iterrows():\n",
    "    _idx,_pred = row\n",
    "    tdf_bert_comb_probs.loc[_idx,'prediction'] = _pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert3 = fitter.multi_results(tdf_bt3, None, \n",
    "                                      tdf_bert_comb['prediction'].astype('str'), tdf_bert_comb_probs['probs'], \n",
    "                                      tdf_feat_results, tdf_feat_probs,\n",
    "                                      ['Caps','Hassub'],['Quotes'])\n",
    "tdf_comb_bert3.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res4 = tdf_sub.copy()\n",
    "tdf_res4.loc[tdf_res4['Setting'] == 'zero_shot', 'Label'] = tdf_comb_bert3['Prediction']\n",
    "# tdf_res4.to_csv('data/test_sub_20220114_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0dff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert4 = fitter.multi_results(tdf_bt3, None, \n",
    "                                      tdf_bert_comb['prediction'].astype('str'), tdf_bert_comb_probs['probs'], \n",
    "                                      tdf_feat_results, tdf_feat_probs,\n",
    "                                      ['Caps','Hassub'],['Quotes'], agreeonly=True)\n",
    "tdf_comb_bert4.groupby(['Language','Prediction'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1206be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_res5 = tdf_sub.copy()\n",
    "tdf_res5.loc[tdf_res4['Setting'] == 'zero_shot', 'Label'] = tdf_comb_bert4['Prediction']\n",
    "# tdf_res5.to_csv('data/test_sub_20220114_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert4[tdf_comb_bert4['Prediction'] != tdf_comb_bert2['Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comb_bert4[tdf_comb_bert4['Prediction'] != tdf_comb_bert3['Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d9f44c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
