{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9b_p85gxaGc"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook provides a baseline for each setting in [Subtask A of SemEval 2022 Task 2](https://sites.google.com/view/semeval2022task2-idiomaticity#h.qq7eefmehqf9). In addition this provides some helpful pre-processing scripts that you are free to use with your experiments. \n",
    "\n",
    "Please start by stepping through this notebook so you have a clear idea as to what is expected of the task and what you need to submit. \n",
    "\n",
    "These baselines are based on the results described in the paper “[AStitchInLanguageModels: Dataset and Methods for the Exploration of Idiomaticity in Pre-Trained Language Models](https://arxiv.org/abs/2109.04413)”. \n",
    "\n",
    "## Zero-shot setting: Methodology \n",
    "\n",
    "Note that in the zero-shot setting you are NOT allowed to train the model using the one-shot data. \n",
    "\n",
    "In the zero-shot setting, we choose to include the context (the sentences preceding and succeeding the one containing the idioms). We do not add the idiom as an additional feature (in the “second input sentence”). This is based on the results presented in the dataset paper. \n",
    "\n",
    "We use Multilingual BERT for this setting.\n",
    "\n",
    "## One-shot setting: Methodology\n",
    "\n",
    "In the one shot setting, we train the model on both the zero-shot and one-shot data. In this setting, we exclude the context (the sentences preceding and succeeding the one containing the idioms) and also add the idiom as an additional feature in the “second sentence”. Again, this is based on the results presented in the dataset paper. \n",
    "\n",
    "We also use Multilingual BERT for this setting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "do-TXGBemGgH"
   },
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WsITUAnzvFl"
   },
   "source": [
    "Download the Task data and evaluation scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qq3qhQdpl-1-",
    "outputId": "7606d743-6823-40a3-eb64-f9fcaff2cd4c"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-0POB9tzfNx"
   },
   "source": [
    "Download the “AStitchInLanguageModels” code which we make use of. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "affNQCRktdx4",
    "outputId": "60fc820d-51c7-481c-f355-e5f0918b6a05"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60w-An2vzikk"
   },
   "source": [
    "Download and install an editable version of huggingfaces transformers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8BhcLYcmVvd",
    "outputId": "cb0935d9-a95d-415b-de4b-d80bd68924dd"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/huggingface/transformers.git\n",
    "#%cd transformers/\n",
    "#!pip install --editable .\n",
    "#%cd /content/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huVMnwTSzmjJ"
   },
   "source": [
    "Required for run_glue ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tsWits5tw1t",
    "outputId": "71c7e873-1817-4cfe-af58-eae8489fb57d"
   },
   "outputs": [],
   "source": [
    "## run_glue needs this. \n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-igYdTTgzp9e"
   },
   "source": [
    "Editable install requires runtime restart unless we do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uOuKplBmmbeB"
   },
   "outputs": [],
   "source": [
    "import site\n",
    "site.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvC8kAGNnKk_"
   },
   "source": [
    "# Imports and Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aOw3MaG7nN77"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MzDtW9eXnOhG"
   },
   "outputs": [],
   "source": [
    "def load_csv( path, delimiter=',' ) : \n",
    "  header = None\n",
    "  data   = list()\n",
    "  with open( path, encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader( csvfile, delimiter=delimiter ) \n",
    "    for row in reader : \n",
    "      if header is None : \n",
    "        header = row\n",
    "        continue\n",
    "      data.append( row ) \n",
    "  return header, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WwtDsdtAnSZu"
   },
   "outputs": [],
   "source": [
    "def write_csv( data, location ) : \n",
    "  with open( location, 'w', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer( csvfile ) \n",
    "    writer.writerows( data ) \n",
    "  print( \"Wrote {}\".format( location ) ) \n",
    "  return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9Io3D3_z4wt"
   },
   "source": [
    "The following function creates a submission file from the predictions output by run_glue (the text classification script from huggingface transformers - see below). \n",
    "\n",
    "Note that we set it up so we can load up results for only one setting. \n",
    "\n",
    "It requires as input the submission format file, which is available with the data. You can call this after completing each setting to load up results for both settings (see below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Re31vnLoQWww"
   },
   "outputs": [],
   "source": [
    "def insert_to_submission_file( submission_format_file, input_file, prediction_format_file, setting ) :\n",
    "    submission_header, submission_content = load_csv( submission_format_file )\n",
    "    input_header     , input_data         = load_csv( input_file             )\n",
    "    prediction_header, prediction_data    = load_csv( prediction_format_file, '\\t' )\n",
    "\n",
    "    assert len( input_data ) == len( prediction_data )\n",
    "\n",
    "    ## submission_header ['ID', 'Language', 'Setting', 'Label']\n",
    "    ## input_header      ['label', 'sentence1' ]\n",
    "    ## prediction_header ['index', 'prediction']\n",
    "\n",
    "    prediction_data = list( reversed( prediction_data ) )\n",
    "\n",
    "    started_insert  = False\n",
    "    for elem in submission_content : \n",
    "        if elem[ submission_header.index( 'Setting' ) ] != setting :\n",
    "            if started_insert :\n",
    "                if len( prediction_data ) == 0 :\n",
    "                    break\n",
    "                else : \n",
    "                    raise Exception( \"Update should to contiguous ... something wrong.\" ) \n",
    "            continue\n",
    "        started_insert = True\n",
    "        elem[ submission_header.index( 'Label' ) ] = prediction_data.pop()[ prediction_header.index( 'prediction' ) ]\n",
    "\n",
    "    return [ submission_header ] + submission_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44LyZ-OXmgQW"
   },
   "source": [
    "# Pre-process: Create train and dev and evaluation data in required format\n",
    "\n",
    "In the zero-shot setting, we choose to include the context (the sentences preceding and succeeding the one containing the idioms). We do not add the idiom as an additional feature (in the “second input sentence”). \n",
    "\n",
    "In the one shot setting, we train the model on both the zero-shot and one-shot data. In this setting, we exclude the context (the sentences preceding and succeeding the one containing the idioms) and also add the idiom as an additional feature in the “second sentence”. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-3ymBcEmxaV"
   },
   "source": [
    "## Functions for pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MthVK7EQm6m_"
   },
   "source": [
    "### _get_train_data\n",
    "\n",
    "This function generates training data in the format required by the huggingface’s example script. It will include and exclude the MWE and the context based on parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cPGq-Y1Jmvv5"
   },
   "outputs": [],
   "source": [
    "def _get_train_data( data_location, file_name, include_context, include_idiom ) :\n",
    "    \n",
    "    file_name = os.path.join( data_location, file_name ) \n",
    "\n",
    "    header, data = load_csv( file_name )\n",
    "\n",
    "    out_header = [ 'label', 'sentence1' ]\n",
    "    if include_idiom :\n",
    "        out_header = [ 'label', 'sentence1', 'sentence2' ]\n",
    "        \n",
    "    # ['DataID', 'Language', 'MWE', 'Setting', 'Previous', 'Target', 'Next', 'Label']\n",
    "    out_data = list()\n",
    "    for elem in data :\n",
    "        label     = elem[ header.index( 'Label'  ) ]\n",
    "        sentence1 = elem[ header.index( 'Target' ) ]\n",
    "        if include_context :\n",
    "            sentence1 = ' '.join( [ elem[ header.index( 'Previous' ) ], elem[ header.index( 'Target' ) ], elem[ header.index( 'Next' ) ] ] )\n",
    "        this_row = None\n",
    "        if not include_idiom :\n",
    "            this_row = [ label, sentence1 ] \n",
    "        else :\n",
    "            sentence2 = elem[ header.index( 'MWE' ) ]\n",
    "            this_row = [ label, sentence1, sentence2 ]\n",
    "        out_data.append( this_row )\n",
    "        assert len( out_header ) == len( this_row )\n",
    "    return [ out_header ] + out_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cytociCB3WZM"
   },
   "source": [
    "### _get_dev_eval_data\n",
    "\n",
    "This function generates training dev and eval data in the format required by the huggingface’s example script. It will include and exclude the MWE and the context based on parameters. \n",
    "\n",
    "Additionally, if there is no gold label provides (as in the case of eval) it will generate a file that can be used to generate predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qe4YQJ9Sm-B2"
   },
   "outputs": [],
   "source": [
    "def _get_dev_eval_data( data_location, input_file_name, gold_file_name, include_context, include_idiom ) :\n",
    "\n",
    "    input_headers, input_data = load_csv( os.path.join( data_location, input_file_name ) )\n",
    "    gold_header  = gold_data = None\n",
    "    if not gold_file_name is None : \n",
    "        gold_header  , gold_data  = load_csv( os.path.join( data_location, gold_file_name  ) )\n",
    "        assert len( input_data ) == len( gold_data )\n",
    "\n",
    "    # ['ID', 'Language', 'MWE', 'Previous', 'Target', 'Next']\n",
    "    # ['ID', 'DataID', 'Language', 'Label']\n",
    "    \n",
    "    out_header = [ 'label', 'sentence1' ]\n",
    "    if include_idiom :\n",
    "        out_header = [ 'label', 'sentence1', 'sentence2' ]\n",
    "\n",
    "    out_data = list()\n",
    "    for index in range( len( input_data ) ) :\n",
    "        label = 1\n",
    "        if not gold_file_name is None : \n",
    "            this_input_id = input_data[ index ][ input_headers.index( 'ID' ) ]\n",
    "            this_gold_id  = gold_data [ index ][ gold_header  .index( 'ID' ) ]\n",
    "            assert this_input_id == this_gold_id\n",
    "            \n",
    "            label     = gold_data[ index ][ gold_header.index( 'Label'  ) ]\n",
    "            \n",
    "        elem      = input_data[ index ]\n",
    "        sentence1 = elem[ input_headers.index( 'Target' ) ]\n",
    "        if include_context :\n",
    "            sentence1 = ' '.join( [ elem[ input_headers.index( 'Previous' ) ], elem[ input_headers.index( 'Target' ) ], elem[ input_headers.index( 'Next' ) ] ] )\n",
    "        this_row = None\n",
    "        if not include_idiom :\n",
    "            this_row = [ label, sentence1 ] \n",
    "        else :\n",
    "            sentence2 = elem[ input_headers.index( 'MWE' ) ]\n",
    "            this_row = [ label, sentence1, sentence2 ]\n",
    "        assert len( out_header ) == len( this_row ) \n",
    "        out_data.append( this_row )\n",
    "        \n",
    "\n",
    "    return [ out_header ] + out_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjIbyTnn3fHP"
   },
   "source": [
    "### create_data\n",
    "\n",
    "This function generates the training, development and evaluation data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "w1tr-zNvnBCV"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the results presented in `AStitchInLanguageModels' we work with not including the idiom for the zero shot setting and including it in the one shot setting.\n",
    "\"\"\"\n",
    "def create_data( input_location, output_location ) :\n",
    "\n",
    "    \n",
    "    ## Zero shot data\n",
    "    train_data = _get_train_data(\n",
    "        data_location   = input_location,\n",
    "        file_name       = 'train_zero_shot.csv',\n",
    "        include_context = True,\n",
    "        include_idiom   = False\n",
    "    )\n",
    "    write_csv( train_data, os.path.join( output_location, 'ZeroShot', 'train.csv' ) )\n",
    "    \n",
    "    dev_data = _get_dev_eval_data(\n",
    "        data_location    = input_location,\n",
    "        input_file_name  = 'dev.csv',\n",
    "        gold_file_name   = 'dev_gold.csv', \n",
    "        include_context  = True,\n",
    "        include_idiom    = False\n",
    "    )        \n",
    "    write_csv( dev_data, os.path.join( output_location, 'ZeroShot', 'dev.csv' ) )\n",
    "    \n",
    "    eval_data = _get_dev_eval_data(\n",
    "        data_location    = input_location,\n",
    "        input_file_name  = 'eval.csv',\n",
    "        gold_file_name   = None , ## Don't have gold evaluation file -- submit to CodaLab\n",
    "        include_context  = True,\n",
    "        include_idiom    = False\n",
    "    )\n",
    "    write_csv( eval_data, os.path.join( output_location, 'ZeroShot', 'eval.csv' ) )\n",
    "\n",
    "    test_data = _get_dev_eval_data(\n",
    "        data_location    = input_location,\n",
    "        input_file_name  = 'eval.csv',\n",
    "        gold_file_name   = None , ## Don't have gold evaluation file -- submit to CodaLab\n",
    "        include_context  = True,\n",
    "        include_idiom    = False\n",
    "    )\n",
    "    write_csv( eval_data, os.path.join( output_location, 'ZeroShot', 'eval.csv' ) )\n",
    "    \n",
    "\n",
    "    ## OneShot Data (combine both for training)\n",
    "    train_zero_data = _get_train_data(\n",
    "        data_location   = input_location,\n",
    "        file_name       = 'train_zero_shot.csv',\n",
    "        include_context = False,\n",
    "        include_idiom   = True\n",
    "    )\n",
    "    train_one_data = _get_train_data(\n",
    "        data_location   = input_location,\n",
    "        file_name       = 'train_one_shot.csv',\n",
    "        include_context = False,\n",
    "        include_idiom   = True\n",
    "    )\n",
    "\n",
    "    assert train_zero_data[0] == train_one_data[0] ## Headers\n",
    "    train_data = train_one_data + train_zero_data[1:]\n",
    "    write_csv( train_data, os.path.join( output_location, 'OneShot', 'train.csv' ) )\n",
    "    \n",
    "    dev_data = _get_dev_eval_data(\n",
    "        data_location    = input_location,\n",
    "        input_file_name  = 'dev.csv',\n",
    "        gold_file_name   = 'dev_gold.csv', \n",
    "        include_context  = False,\n",
    "        include_idiom    = True\n",
    "    )        \n",
    "    write_csv( dev_data, os.path.join( output_location, 'OneShot', 'dev.csv' ) )\n",
    "    \n",
    "    eval_data = _get_dev_eval_data(\n",
    "        data_location    = input_location,\n",
    "        input_file_name  = 'eval.csv',\n",
    "        gold_file_name   = None,\n",
    "        include_context  = False,\n",
    "        include_idiom    = True\n",
    "    )\n",
    "    write_csv( eval_data, os.path.join( output_location, 'OneShot', 'eval.csv' ) )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data( input_location, output_location ) :\n",
    "\n",
    "    test_data = _get_dev_eval_data(\n",
    "        data_location    = input_location,\n",
    "        input_file_name  = 'test.csv',\n",
    "        gold_file_name   = None , ## Don't have gold evaluation file -- submit to CodaLab\n",
    "        include_context  = True,\n",
    "        include_idiom    = False\n",
    "    )\n",
    "    write_csv( test_data, os.path.join( output_location, 'ZeroShot', 'test.csv' ) )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmQfvym8ndKH"
   },
   "source": [
    "## Setup and Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxCgaHlKnpMR",
    "outputId": "6d216c97-dad6-4ec7-9e6b-cf9484dcd220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AStitchInLanguageModels  make_submission.sh  SemEval_2022_Task2-idiomaticity\r\n",
      "data\t\t\t models\t\t     SubTaskA-bert.ipynb\r\n",
      "Data\t\t\t outputs\t     SubTaskA-zeroshot.ipynb\r\n",
      "jupyter.10140283.out\t pyproject.toml      SubTaskA-zeroshot-loaded.ipynb\r\n",
      "lib\t\t\t README.md\t     xlm-sentiment\r\n",
      "LICENSE\t\t\t requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = 'Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pkeKLg-Hngs4",
    "outputId": "7ec6726f-295c-4e43-b5a4-127560c3ffe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Data/ZeroShot/train.csv\n",
      "Wrote Data/ZeroShot/dev.csv\n",
      "Wrote Data/ZeroShot/eval.csv\n",
      "Wrote Data/OneShot/train.csv\n",
      "Wrote Data/OneShot/dev.csv\n",
      "Wrote Data/OneShot/eval.csv\n"
     ]
    }
   ],
   "source": [
    "Path( os.path.join( outpath, 'ZeroShot' ) ).mkdir(parents=True, exist_ok=True)\n",
    "Path( os.path.join( outpath, 'ZeroShotPlus' ) ).mkdir(parents=True, exist_ok=True)\n",
    "Path( os.path.join( outpath, 'OneShot' ) ).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "create_data( 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', outpath )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Data/ZeroShot/test.csv\n"
     ]
    }
   ],
   "source": [
    "create_test_data( 'SemEval_2022_Task2-idiomaticity/SubTaskA/TestData/', outpath )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uP-Ol7hfoC8a"
   },
   "source": [
    "# Zero Shot Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-GiQvnkoL67"
   },
   "source": [
    "## Train Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_k0BwA0uoKAu",
    "outputId": "8f439b38-1815-4adf-c070-053b34fc9e5f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/16/2021 22:22:40 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/16/2021 22:22:40 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/0/runs/Dec16_22-22-40_r16g07.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/0/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/0/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/16/2021 22:22:40 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train.csv\n",
      "12/16/2021 22:22:40 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev.csv\n",
      "12/16/2021 22:22:55 - WARNING - datasets.builder -   Using custom data configuration default-624d189b26d2a2c1\n",
      "Downloading and preparing dataset csv/default to /users/sitkonen/.cache/huggingface/datasets/csv/default-624d189b26d2a2c1/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 6232.25it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.40it/s]\n",
      "Dataset csv downloaded and prepared to /users/sitkonen/.cache/huggingface/datasets/csv/default-624d189b26d2a2c1/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.69it/s]\n",
      "[INFO|configuration_utils.py:588] 2021-12-16 22:22:58,202 >> loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /users/sitkonen/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "[INFO|configuration_utils.py:625] 2021-12-16 22:22:58,203 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:588] 2021-12-16 22:22:59,369 >> loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /users/sitkonen/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "[INFO|configuration_utils.py:625] 2021-12-16 22:22:59,370 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-16 22:23:02,693 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /users/sitkonen/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-16 22:23:02,694 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /users/sitkonen/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-16 22:23:02,694 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-16 22:23:02,694 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-16 22:23:02,694 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /users/sitkonen/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "[INFO|configuration_utils.py:588] 2021-12-16 22:23:03,264 >> loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /users/sitkonen/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "[INFO|configuration_utils.py:625] 2021-12-16 22:23:03,265 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1340] 2021-12-16 22:23:06,164 >> loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /users/sitkonen/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:1599] 2021-12-16 22:23:10,459 >> Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:1610] 2021-12-16 22:23:10,459 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.90ba/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.35ba/s]\n",
      "12/16/2021 22:23:13 - INFO - __main__ -   Sample 3155 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 14156, 10114, 11486, 119, 10212, 117, 10105, 20169, 10410, 11940, 10134, 15556, 21756, 10155, 34624, 50575, 10901, 117, 10473, 10531, 30419, 12172, 10472, 24278, 10105, 16672, 11356, 11444, 18703, 30159, 100, 187, 38587, 10106, 10827, 19376, 119, 30159, 11059, 13745, 10105, 20169, 10410, 10924, 61637, 10114, 14045, 10686, 10105, 18077, 117, 10319, 10134, 10873, 40851, 10106, 88651, 10169, 10751, 22975, 10978, 10105, 39189, 100, 187, 17090, 10155, 23874, 22392, 10708, 10105, 47723, 11630, 61637, 10189, 11951, 78275, 18745, 119, 21194, 119, 10386, 105315, 14234, 11598, 10855, 117, 12373, 10105, 39189, 29914, 10454, 39575, 25385, 119, 10258, 13990, 10114, 17876, 10474, 17090, 12166, 10105, 42230, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0, 'sentence1': 'According to history.com, the leap day was originally discovered by Egyptian astronomers, but this discovery did not reach the western world until Julius Caesar’s reign in 45 BC. Caesar then created the leap year calendar to fix the problem, which was later adapted in accordance with new knowledge about the earth’s orbit by Pope Gregory into the Gregorian calendar that we observe today. Feb. 29 happens every four years, because the earth technically requires 365.25 days to complete its orbit around the sun.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "12/16/2021 22:23:13 - INFO - __main__ -   Sample 3445 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 138, 70747, 10143, 34862, 117, 12943, 18965, 41583, 117, 59216, 10104, 77302, 10121, 24457, 14732, 10147, 21367, 10220, 10427, 10614, 64440, 173, 10321, 22849, 10220, 12656, 12114, 13360, 100, 22798, 10212, 47097, 19075, 10220, 10427, 66130, 10107, 87537, 10143, 72154, 27187, 10242, 95322, 49323, 113, 46743, 114, 117, 169, 11419, 118, 107041, 10149, 13218, 27062, 18965, 41583, 82389, 10138, 25574, 25819, 10104, 15395, 64440, 173, 99702, 10121, 10303, 35474, 10147, 11793, 28223, 10266, 11675, 10104, 57833, 169, 54728, 10143, 17857, 119, 152, 20229, 117, 12943, 12593, 117, 10448, 183, 26219, 10567, 55227, 16686, 10242, 10139, 104915, 110285, 55167, 102453, 10107, 11793, 36818, 23821, 10104, 10106, 63996, 11498, 10266, 23571, 55167, 117, 10402, 34338, 169, 54728, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'sentence1': 'A saída da crise, segundo Bachelet, depende de ações que garantam renda para os mais pobres e vacina para todos São Paulo – Alta comissária para os Direitos Humanos da Organização das Nações Unidas (ONU), a ex-presidenta do Chile Michelle Bachelet criticou governantes de países pobres e ricos que optaram pela economia em vez de promover a saúde da população. O resultado, segundo ela, foi o aprofundamento das desigualdades sociais causadas pela histórica falta de investimento em áreas sociais, entre elas a saúde.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "12/16/2021 22:23:13 - INFO - __main__ -   Sample 331 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 77961, 80677, 41131, 117, 10106, 36944, 10169, 144, 11011, 10731, 117, 10529, 14628, 169, 10751, 13170, 10108, 53730, 52828, 10111, 99024, 11327, 26483, 10841, 76456, 81635, 74062, 92233, 112, 187, 119, 10576, 10725, 34062, 10160, 10105, 25000, 39039, 10858, 20924, 25539, 12357, 10195, 117, 77961, 80677, 41131, 10309, 46948, 10336, 10169, 10105, 107, 33671, 20924, 93218, 10108, 10105, 13567, 107, 17725, 117, 10142, 10105, 20206, 80677, 41131, 119, 10117, 34713, 10134, 23736, 10160, 10105, 22712, 53329, 20640, 30328, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'sentence1': 'Concept Smoke Screen, in partnership with G4S, have developed a new way of defending cash and guards against attacks when replenishing ATM\\'s. On May 11th at the IFSEC Security Industry Awards 2009, Concept Smoke Screen were honoured with the \"Physical Security Product of the Year\" award, for the Guardian Smoke Screen. The ceremony was conducted at the Birmingham Hilton Metropole.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "[INFO|trainer.py:541] 2021-12-16 22:23:47,599 >> The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:1196] 2021-12-16 22:23:47,682 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2021-12-16 22:23:47,682 >>   Num examples = 4491\n",
      "[INFO|trainer.py:1198] 2021-12-16 22:23:47,682 >>   Num Epochs = 9\n",
      "[INFO|trainer.py:1199] 2021-12-16 22:23:47,682 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:1200] 2021-12-16 22:23:47,682 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1201] 2021-12-16 22:23:47,682 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2021-12-16 22:23:47,682 >>   Total optimization steps = 1269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|████▍                                   | 141/1269 [00:38<04:02,  4.66it/s][INFO|trainer.py:541] 2021-12-16 22:24:27,265 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:24:27,267 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:24:27,267 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:24:27,267 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/93 [00:00<00:02, 38.24it/s]\u001b[A\n",
      "  9%|███▊                                        | 8/93 [00:00<00:02, 33.66it/s]\u001b[A\n",
      " 13%|█████▌                                     | 12/93 [00:00<00:02, 30.07it/s]\u001b[A\n",
      " 17%|███████▍                                   | 16/93 [00:00<00:02, 29.13it/s]\u001b[A\n",
      " 22%|█████████▏                                 | 20/93 [00:00<00:02, 31.34it/s]\u001b[A\n",
      " 26%|███████████                                | 24/93 [00:00<00:02, 31.07it/s]\u001b[A\n",
      " 30%|████████████▉                              | 28/93 [00:00<00:02, 30.17it/s]\u001b[A\n",
      " 34%|██████████████▊                            | 32/93 [00:01<00:02, 29.27it/s]\u001b[A\n",
      " 38%|████████████████▏                          | 35/93 [00:01<00:01, 29.24it/s]\u001b[A\n",
      " 42%|██████████████████                         | 39/93 [00:01<00:01, 31.80it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 43/93 [00:01<00:01, 29.55it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 47/93 [00:01<00:01, 29.08it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 50/93 [00:01<00:01, 29.05it/s]\u001b[A\n",
      " 58%|████████████████████████▉                  | 54/93 [00:01<00:01, 29.43it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 57/93 [00:01<00:01, 29.30it/s]\u001b[A\n",
      " 65%|███████████████████████████▋               | 60/93 [00:02<00:01, 28.82it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 64/93 [00:02<00:00, 30.71it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 68/93 [00:02<00:00, 27.57it/s]\u001b[A\n",
      " 77%|█████████████████████████████████▎         | 72/93 [00:02<00:00, 27.64it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▋        | 75/93 [00:02<00:00, 28.05it/s]\u001b[A\n",
      " 84%|████████████████████████████████████       | 78/93 [00:02<00:00, 28.48it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 81/93 [00:02<00:00, 28.70it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▊    | 84/93 [00:02<00:00, 28.84it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 88/93 [00:02<00:00, 31.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6797577142715454, 'eval_accuracy': 0.6265223026275635, 'eval_f1': 0.6202466598150052, 'eval_runtime': 3.9042, 'eval_samples_per_second': 189.284, 'eval_steps_per_second': 23.821, 'epoch': 1.0}\n",
      " 11%|████▍                                   | 141/1269 [00:42<04:02,  4.66it/s]\n",
      "100%|███████████████████████████████████████████| 93/93 [00:03<00:00, 29.39it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-16 22:24:31,278 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-141\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:24:31,331 >> Configuration saved in models/ZeroShot/0/checkpoint-141/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:24:34,608 >> Model weights saved in models/ZeroShot/0/checkpoint-141/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:24:34,646 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-141/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:24:34,673 >> Special tokens file saved in models/ZeroShot/0/checkpoint-141/special_tokens_map.json\n",
      " 22%|████████▉                               | 282/1269 [01:29<03:30,  4.68it/s][INFO|trainer.py:541] 2021-12-16 22:25:17,524 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:25:17,538 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:25:17,539 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:25:17,539 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/93 [00:00<00:02, 34.90it/s]\u001b[A\n",
      "  9%|███▊                                        | 8/93 [00:00<00:02, 32.64it/s]\u001b[A\n",
      " 13%|█████▌                                     | 12/93 [00:00<00:02, 27.75it/s]\u001b[A\n",
      " 17%|███████▍                                   | 16/93 [00:00<00:02, 30.69it/s]\u001b[A\n",
      " 22%|█████████▏                                 | 20/93 [00:00<00:02, 28.37it/s]\u001b[A\n",
      " 25%|██████████▋                                | 23/93 [00:00<00:02, 28.29it/s]\u001b[A\n",
      " 29%|████████████▍                              | 27/93 [00:00<00:02, 29.46it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 31/93 [00:01<00:02, 29.96it/s]\u001b[A\n",
      " 38%|████████████████▏                          | 35/93 [00:01<00:02, 28.10it/s]\u001b[A\n",
      " 41%|█████████████████▌                         | 38/93 [00:01<00:02, 27.50it/s]\u001b[A\n",
      " 45%|███████████████████▍                       | 42/93 [00:01<00:01, 29.43it/s]\u001b[A\n",
      " 49%|█████████████████████▎                     | 46/93 [00:01<00:01, 28.69it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 49/93 [00:01<00:01, 28.25it/s]\u001b[A\n",
      " 58%|████████████████████████▉                  | 54/93 [00:01<00:01, 29.39it/s]\u001b[A\n",
      " 61%|██████████████████████████▎                | 57/93 [00:01<00:01, 28.93it/s]\u001b[A\n",
      " 66%|████████████████████████████▏              | 61/93 [00:02<00:01, 30.08it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 65/93 [00:02<00:00, 30.41it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 69/93 [00:02<00:00, 30.20it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▊         | 73/93 [00:02<00:00, 29.13it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▌       | 77/93 [00:02<00:00, 30.33it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 81/93 [00:02<00:00, 28.66it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▊    | 84/93 [00:02<00:00, 28.83it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▏  | 87/93 [00:02<00:00, 28.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9897983074188232, 'eval_accuracy': 0.6359946131706238, 'eval_f1': 0.6358639007189631, 'eval_runtime': 3.183, 'eval_samples_per_second': 232.173, 'eval_steps_per_second': 29.218, 'epoch': 2.0}\n",
      " 22%|████████▉                               | 282/1269 [01:32<03:30,  4.68it/s]\n",
      "100%|███████████████████████████████████████████| 93/93 [00:03<00:00, 27.60it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-16 22:25:20,828 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-282\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:25:20,872 >> Configuration saved in models/ZeroShot/0/checkpoint-282/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:25:23,629 >> Model weights saved in models/ZeroShot/0/checkpoint-282/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:25:23,665 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-282/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:25:23,701 >> Special tokens file saved in models/ZeroShot/0/checkpoint-282/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-16 22:25:29,719 >> Deleting older checkpoint [models/ZeroShot/0/checkpoint-141] due to args.save_total_limit\n",
      " 33%|█████████████▎                          | 423/1269 [02:21<03:29,  4.04it/s][INFO|trainer.py:541] 2021-12-16 22:26:09,897 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:26:09,908 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:26:09,908 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:26:09,908 >>   Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/93 [00:00<00:02, 33.20it/s]\u001b[A\n",
      "  9%|███▊                                        | 8/93 [00:00<00:02, 32.95it/s]\u001b[A\n",
      " 13%|█████▌                                     | 12/93 [00:00<00:02, 33.35it/s]\u001b[A\n",
      " 17%|███████▍                                   | 16/93 [00:00<00:02, 32.64it/s]\u001b[A\n",
      " 22%|█████████▏                                 | 20/93 [00:00<00:02, 29.93it/s]\u001b[A\n",
      " 26%|███████████                                | 24/93 [00:00<00:02, 30.47it/s]\u001b[A\n",
      " 30%|████████████▉                              | 28/93 [00:00<00:02, 30.48it/s]\u001b[A\n",
      " 34%|██████████████▊                            | 32/93 [00:01<00:01, 31.18it/s]\u001b[A\n",
      " 39%|████████████████▋                          | 36/93 [00:01<00:01, 29.67it/s]\u001b[A\n",
      " 42%|██████████████████                         | 39/93 [00:01<00:01, 29.60it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 43/93 [00:01<00:01, 30.43it/s]\u001b[A\n",
      " 51%|█████████████████████▋                     | 47/93 [00:01<00:01, 29.80it/s]\u001b[A\n",
      " 55%|███████████████████████▌                   | 51/93 [00:01<00:01, 30.49it/s]\u001b[A\n",
      " 59%|█████████████████████████▍                 | 55/93 [00:01<00:01, 31.02it/s]\u001b[A\n",
      " 63%|███████████████████████████▎               | 59/93 [00:01<00:01, 32.27it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 63/93 [00:02<00:00, 33.94it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 67/93 [00:02<00:00, 32.65it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 71/93 [00:02<00:00, 31.21it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▋        | 75/93 [00:02<00:00, 30.74it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 79/93 [00:02<00:00, 32.41it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 83/93 [00:02<00:00, 31.22it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▏  | 87/93 [00:02<00:00, 31.53it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 91/93 [00:02<00:00, 31.64it/s]\u001b[A\n",
      "{'eval_loss': 1.0711168050765991, 'eval_accuracy': 0.6576454639434814, 'eval_f1': 0.6573945294390358, 'eval_runtime': 3.1591, 'eval_samples_per_second': 233.927, 'eval_steps_per_second': 29.439, 'epoch': 3.0}\n",
      "\n",
      " 33%|█████████████▎                          | 423/1269 [02:24<03:29,  4.04it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-16 22:26:13,184 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-423\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:26:13,239 >> Configuration saved in models/ZeroShot/0/checkpoint-423/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:26:15,498 >> Model weights saved in models/ZeroShot/0/checkpoint-423/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:26:15,541 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-423/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:26:15,577 >> Special tokens file saved in models/ZeroShot/0/checkpoint-423/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-16 22:26:22,034 >> Deleting older checkpoint [models/ZeroShot/0/checkpoint-282] due to args.save_total_limit\n",
      "{'loss': 0.3256, 'learning_rate': 1.2119779353821908e-05, 'epoch': 3.55}        \n",
      " 44%|█████████████████▊                      | 564/1269 [03:10<02:33,  4.60it/s][INFO|trainer.py:541] 2021-12-16 22:26:58,401 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:26:58,403 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:26:58,403 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:26:58,403 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/93 [00:00<00:02, 37.07it/s]\u001b[A\n",
      "  9%|███▊                                        | 8/93 [00:00<00:02, 35.33it/s]\u001b[A\n",
      " 13%|█████▌                                     | 12/93 [00:00<00:02, 33.87it/s]\u001b[A\n",
      " 17%|███████▍                                   | 16/93 [00:00<00:02, 35.28it/s]\u001b[A\n",
      " 22%|█████████▏                                 | 20/93 [00:00<00:02, 33.02it/s]\u001b[A\n",
      " 26%|███████████                                | 24/93 [00:00<00:02, 33.89it/s]\u001b[A\n",
      " 30%|████████████▉                              | 28/93 [00:00<00:02, 32.27it/s]\u001b[A\n",
      " 34%|██████████████▊                            | 32/93 [00:00<00:01, 33.27it/s]\u001b[A\n",
      " 39%|████████████████▋                          | 36/93 [00:01<00:01, 32.14it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 40/93 [00:01<00:01, 32.70it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 44/93 [00:01<00:01, 30.14it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 48/93 [00:01<00:01, 28.49it/s]\u001b[A\n",
      " 55%|███████████████████████▌                   | 51/93 [00:01<00:01, 27.64it/s]\u001b[A\n",
      " 58%|████████████████████████▉                  | 54/93 [00:01<00:01, 27.35it/s]\u001b[A\n",
      " 62%|██████████████████████████▊                | 58/93 [00:01<00:01, 27.98it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 62/93 [00:02<00:01, 29.58it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 65/93 [00:02<00:00, 29.50it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 68/93 [00:02<00:00, 29.56it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 71/93 [00:02<00:00, 28.97it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▏        | 74/93 [00:02<00:00, 28.78it/s]\u001b[A\n",
      " 84%|████████████████████████████████████       | 78/93 [00:02<00:00, 31.34it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▉     | 82/93 [00:02<00:00, 29.43it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▎   | 85/93 [00:02<00:00, 28.54it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 88/93 [00:02<00:00, 27.83it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 91/93 [00:03<00:00, 27.59it/s]\u001b[A\n",
      "{'eval_loss': 1.5946825742721558, 'eval_accuracy': 0.6644113659858704, 'eval_f1': 0.6644058361654752, 'eval_runtime': 3.107, 'eval_samples_per_second': 237.847, 'eval_steps_per_second': 29.932, 'epoch': 4.0}\n",
      "\n",
      " 44%|█████████████████▊                      | 564/1269 [03:13<02:33,  4.60it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-16 22:27:01,676 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-564\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:27:01,713 >> Configuration saved in models/ZeroShot/0/checkpoint-564/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:27:04,533 >> Model weights saved in models/ZeroShot/0/checkpoint-564/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:27:04,583 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-564/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:27:04,622 >> Special tokens file saved in models/ZeroShot/0/checkpoint-564/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-16 22:27:10,737 >> Deleting older checkpoint [models/ZeroShot/0/checkpoint-423] due to args.save_total_limit\n",
      " 56%|██████████████████████▏                 | 705/1269 [03:58<02:01,  4.65it/s][INFO|trainer.py:541] 2021-12-16 22:27:46,814 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:27:46,853 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:27:46,853 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:27:46,853 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/93 [00:00<00:02, 39.65it/s]\u001b[A\n",
      "  9%|███▊                                        | 8/93 [00:00<00:02, 30.52it/s]\u001b[A\n",
      " 13%|█████▌                                     | 12/93 [00:00<00:02, 27.65it/s]\u001b[A\n",
      " 17%|███████▍                                   | 16/93 [00:00<00:02, 30.64it/s]\u001b[A\n",
      " 22%|█████████▏                                 | 20/93 [00:00<00:02, 29.16it/s]\u001b[A\n",
      " 26%|███████████                                | 24/93 [00:00<00:02, 27.67it/s]\u001b[A\n",
      " 30%|████████████▉                              | 28/93 [00:00<00:02, 30.77it/s]\u001b[A\n",
      " 34%|██████████████▊                            | 32/93 [00:01<00:01, 32.07it/s]\u001b[A\n",
      " 39%|████████████████▋                          | 36/93 [00:01<00:01, 29.32it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 40/93 [00:01<00:01, 29.44it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 44/93 [00:01<00:01, 29.05it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 48/93 [00:01<00:01, 29.46it/s]\u001b[A\n",
      " 55%|███████████████████████▌                   | 51/93 [00:01<00:01, 29.11it/s]\u001b[A\n",
      " 59%|█████████████████████████▍                 | 55/93 [00:01<00:01, 30.62it/s]\u001b[A\n",
      " 63%|███████████████████████████▎               | 59/93 [00:01<00:01, 31.76it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 63/93 [00:02<00:00, 30.82it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 67/93 [00:02<00:00, 30.18it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 71/93 [00:02<00:00, 29.93it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▋        | 75/93 [00:02<00:00, 28.87it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 79/93 [00:02<00:00, 29.72it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▉     | 82/93 [00:02<00:00, 27.16it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▊   | 86/93 [00:02<00:00, 30.03it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 90/93 [00:02<00:00, 31.71it/s]\u001b[A\n",
      "{'eval_loss': 1.926710844039917, 'eval_accuracy': 0.6738836169242859, 'eval_f1': 0.6722608972483379, 'eval_runtime': 3.1092, 'eval_samples_per_second': 237.685, 'eval_steps_per_second': 29.912, 'epoch': 5.0}\n",
      "\n",
      " 56%|██████████████████████▏                 | 705/1269 [04:01<02:01,  4.65it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-16 22:27:50,177 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-705\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:27:50,232 >> Configuration saved in models/ZeroShot/0/checkpoint-705/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:27:52,493 >> Model weights saved in models/ZeroShot/0/checkpoint-705/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:27:52,551 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-705/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:27:52,580 >> Special tokens file saved in models/ZeroShot/0/checkpoint-705/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-16 22:27:58,661 >> Deleting older checkpoint [models/ZeroShot/0/checkpoint-564] due to args.save_total_limit\n",
      " 67%|██████████████████████████▋             | 846/1269 [04:47<01:29,  4.75it/s][INFO|trainer.py:541] 2021-12-16 22:28:35,973 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:28:35,975 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:28:35,975 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:28:35,975 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/93 [00:00<00:02, 39.64it/s]\u001b[A\n",
      "  9%|███▊                                        | 8/93 [00:00<00:02, 35.43it/s]\u001b[A\n",
      " 13%|█████▌                                     | 12/93 [00:00<00:02, 34.23it/s]\u001b[A\n",
      " 17%|███████▍                                   | 16/93 [00:00<00:02, 30.97it/s]\u001b[A\n",
      " 22%|█████████▏                                 | 20/93 [00:00<00:02, 28.82it/s]\u001b[A\n",
      " 26%|███████████                                | 24/93 [00:00<00:02, 31.15it/s]\u001b[A\n",
      " 30%|████████████▉                              | 28/93 [00:00<00:02, 29.49it/s]\u001b[A\n",
      " 34%|██████████████▊                            | 32/93 [00:01<00:01, 31.99it/s]\u001b[A\n",
      " 39%|████████████████▋                          | 36/93 [00:01<00:01, 33.33it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 40/93 [00:01<00:01, 33.19it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 44/93 [00:01<00:01, 32.63it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 48/93 [00:01<00:01, 32.58it/s]\u001b[A\n",
      " 56%|████████████████████████                   | 52/93 [00:01<00:01, 30.54it/s]\u001b[A\n",
      " 60%|█████████████████████████▉                 | 56/93 [00:01<00:01, 30.28it/s]\u001b[A\n",
      " 65%|███████████████████████████▋               | 60/93 [00:01<00:01, 29.60it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 63/93 [00:02<00:01, 28.68it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 67/93 [00:02<00:00, 30.52it/s]\u001b[A\n",
      " 76%|████████████████████████████████▊          | 71/93 [00:02<00:00, 29.96it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▋        | 75/93 [00:02<00:00, 31.19it/s]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 79/93 [00:02<00:00, 32.18it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 83/93 [00:02<00:00, 31.61it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▏  | 87/93 [00:02<00:00, 32.26it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████ | 91/93 [00:02<00:00, 32.25it/s]\u001b[A\n",
      "{'eval_loss': 2.050426959991455, 'eval_accuracy': 0.6874154210090637, 'eval_f1': 0.6866718671132933, 'eval_runtime': 2.9951, 'eval_samples_per_second': 246.736, 'eval_steps_per_second': 31.051, 'epoch': 6.0}\n",
      "\n",
      " 67%|██████████████████████████▋             | 846/1269 [04:50<01:29,  4.75it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-16 22:28:39,142 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-846\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:28:39,195 >> Configuration saved in models/ZeroShot/0/checkpoint-846/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:28:43,575 >> Model weights saved in models/ZeroShot/0/checkpoint-846/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:28:43,616 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-846/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:28:43,650 >> Special tokens file saved in models/ZeroShot/0/checkpoint-846/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-16 22:28:49,622 >> Deleting older checkpoint [models/ZeroShot/0/checkpoint-705] due to args.save_total_limit\n",
      " 78%|███████████████████████████████         | 987/1269 [05:37<01:00,  4.68it/s][INFO|trainer.py:541] 2021-12-16 22:29:25,811 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:29:25,813 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:29:25,813 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:29:25,813 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 3/93 [00:00<00:03, 28.98it/s]\u001b[A\n",
      "  6%|██▊                                         | 6/93 [00:00<00:03, 26.21it/s]\u001b[A\n",
      " 11%|████▌                                      | 10/93 [00:00<00:02, 29.33it/s]\u001b[A\n",
      " 14%|██████                                     | 13/93 [00:00<00:02, 28.15it/s]\u001b[A\n",
      " 18%|███████▊                                   | 17/93 [00:00<00:02, 29.36it/s]\u001b[A\n",
      " 23%|█████████▋                                 | 21/93 [00:00<00:02, 30.55it/s]\u001b[A\n",
      " 27%|███████████▌                               | 25/93 [00:00<00:02, 30.35it/s]\u001b[A\n",
      " 31%|█████████████▍                             | 29/93 [00:00<00:02, 30.14it/s]\u001b[A\n",
      " 35%|███████████████▎                           | 33/93 [00:01<00:01, 30.95it/s]\u001b[A\n",
      " 40%|█████████████████                          | 37/93 [00:01<00:01, 30.93it/s]\u001b[A\n",
      " 44%|██████████████████▉                        | 41/93 [00:01<00:01, 31.51it/s]\u001b[A\n",
      " 48%|████████████████████▊                      | 45/93 [00:01<00:01, 31.28it/s]\u001b[A\n",
      " 53%|██████████████████████▋                    | 49/93 [00:01<00:01, 31.10it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 53/93 [00:01<00:01, 31.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████▎                | 57/93 [00:01<00:01, 28.90it/s]\u001b[A\n",
      " 65%|███████████████████████████▋               | 60/93 [00:02<00:01, 27.67it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 64/93 [00:02<00:01, 27.94it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 67/93 [00:02<00:00, 28.05it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 70/93 [00:02<00:00, 28.15it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▊         | 73/93 [00:02<00:00, 28.43it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▏       | 76/93 [00:02<00:00, 27.74it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 80/93 [00:02<00:00, 27.97it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▊    | 84/93 [00:02<00:00, 30.83it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 88/93 [00:02<00:00, 30.78it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████▌| 92/93 [00:03<00:00, 29.65it/s]\u001b[A\n",
      "{'eval_loss': 2.116579055786133, 'eval_accuracy': 0.6874154210090637, 'eval_f1': 0.6859779147604673, 'eval_runtime': 3.1582, 'eval_samples_per_second': 233.996, 'eval_steps_per_second': 29.447, 'epoch': 7.0}\n",
      "\n",
      " 78%|███████████████████████████████         | 987/1269 [05:40<01:00,  4.68it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-16 22:29:29,122 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-987\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:29:29,165 >> Configuration saved in models/ZeroShot/0/checkpoint-987/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:29:32,507 >> Model weights saved in models/ZeroShot/0/checkpoint-987/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:29:32,565 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-987/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:29:32,588 >> Special tokens file saved in models/ZeroShot/0/checkpoint-987/special_tokens_map.json\n",
      "{'loss': 0.028, 'learning_rate': 4.239558707643815e-06, 'epoch': 7.09}          \n",
      " 89%|██████████████████████████████████▋    | 1128/1269 [06:24<00:30,  4.67it/s][INFO|trainer.py:541] 2021-12-16 22:30:12,945 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:30:12,947 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:30:12,947 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:30:12,947 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▉                                          | 4/93 [00:00<00:02, 31.00it/s]\u001b[A\n",
      "  9%|███▊                                        | 8/93 [00:00<00:02, 29.40it/s]\u001b[A\n",
      " 13%|█████▌                                     | 12/93 [00:00<00:02, 31.99it/s]\u001b[A\n",
      " 17%|███████▍                                   | 16/93 [00:00<00:02, 29.97it/s]\u001b[A\n",
      " 22%|█████████▏                                 | 20/93 [00:00<00:02, 31.99it/s]\u001b[A\n",
      " 26%|███████████                                | 24/93 [00:00<00:02, 30.07it/s]\u001b[A\n",
      " 30%|████████████▉                              | 28/93 [00:00<00:02, 30.91it/s]\u001b[A\n",
      " 34%|██████████████▊                            | 32/93 [00:01<00:01, 31.80it/s]\u001b[A\n",
      " 39%|████████████████▋                          | 36/93 [00:01<00:01, 31.24it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 40/93 [00:01<00:01, 30.13it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 44/93 [00:01<00:01, 29.80it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 48/93 [00:01<00:01, 31.87it/s]\u001b[A\n",
      " 56%|████████████████████████                   | 52/93 [00:01<00:01, 32.34it/s]\u001b[A\n",
      " 60%|█████████████████████████▉                 | 56/93 [00:01<00:01, 30.50it/s]\u001b[A\n",
      " 65%|███████████████████████████▋               | 60/93 [00:01<00:01, 30.17it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 64/93 [00:02<00:00, 29.81it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 68/93 [00:02<00:00, 29.92it/s]\u001b[A\n",
      " 77%|█████████████████████████████████▎         | 72/93 [00:02<00:00, 31.28it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▏       | 76/93 [00:02<00:00, 32.66it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 80/93 [00:02<00:00, 30.03it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▊    | 84/93 [00:02<00:00, 30.65it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 88/93 [00:02<00:00, 30.85it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████▌| 92/93 [00:02<00:00, 31.79it/s]\u001b[A\n",
      "{'eval_loss': 2.183459520339966, 'eval_accuracy': 0.6955345273017883, 'eval_f1': 0.6939000929667437, 'eval_runtime': 3.0395, 'eval_samples_per_second': 243.132, 'eval_steps_per_second': 30.597, 'epoch': 8.0}\n",
      "\n",
      " 89%|██████████████████████████████████▋    | 1128/1269 [06:27<00:30,  4.67it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-16 22:30:16,142 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-1128\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:30:16,196 >> Configuration saved in models/ZeroShot/0/checkpoint-1128/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:30:21,349 >> Model weights saved in models/ZeroShot/0/checkpoint-1128/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:30:21,384 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-1128/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:30:21,429 >> Special tokens file saved in models/ZeroShot/0/checkpoint-1128/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-16 22:30:26,536 >> Deleting older checkpoint [models/ZeroShot/0/checkpoint-846] due to args.save_total_limit\n",
      "[INFO|trainer.py:2073] 2021-12-16 22:30:27,124 >> Deleting older checkpoint [models/ZeroShot/0/checkpoint-987] due to args.save_total_limit\n",
      "100%|███████████████████████████████████████| 1269/1269 [07:14<00:00,  4.78it/s][INFO|trainer.py:541] 2021-12-16 22:31:02,982 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:31:03,010 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:31:03,010 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:31:03,010 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|██▎                                         | 5/93 [00:00<00:02, 33.46it/s]\u001b[A\n",
      " 10%|████▎                                       | 9/93 [00:00<00:02, 32.22it/s]\u001b[A\n",
      " 14%|██████                                     | 13/93 [00:00<00:02, 31.31it/s]\u001b[A\n",
      " 18%|███████▊                                   | 17/93 [00:00<00:02, 29.04it/s]\u001b[A\n",
      " 22%|█████████▏                                 | 20/93 [00:00<00:02, 28.97it/s]\u001b[A\n",
      " 26%|███████████                                | 24/93 [00:00<00:02, 31.02it/s]\u001b[A\n",
      " 30%|████████████▉                              | 28/93 [00:00<00:02, 31.88it/s]\u001b[A\n",
      " 34%|██████████████▊                            | 32/93 [00:01<00:01, 30.71it/s]\u001b[A\n",
      " 39%|████████████████▋                          | 36/93 [00:01<00:01, 32.65it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 40/93 [00:01<00:01, 32.44it/s]\u001b[A\n",
      " 47%|████████████████████▎                      | 44/93 [00:01<00:01, 31.89it/s]\u001b[A\n",
      " 52%|██████████████████████▏                    | 48/93 [00:01<00:01, 31.70it/s]\u001b[A\n",
      " 56%|████████████████████████                   | 52/93 [00:01<00:01, 31.45it/s]\u001b[A\n",
      " 60%|█████████████████████████▉                 | 56/93 [00:01<00:01, 31.49it/s]\u001b[A\n",
      " 65%|███████████████████████████▋               | 60/93 [00:01<00:01, 30.10it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 64/93 [00:02<00:00, 31.90it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 68/93 [00:02<00:00, 30.92it/s]\u001b[A\n",
      " 77%|█████████████████████████████████▎         | 72/93 [00:02<00:00, 31.18it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▏       | 76/93 [00:02<00:00, 30.21it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 80/93 [00:02<00:00, 29.63it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▊    | 84/93 [00:02<00:00, 30.30it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 88/93 [00:02<00:00, 30.58it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████▌| 92/93 [00:02<00:00, 28.72it/s]\u001b[A\n",
      "{'eval_loss': 2.227385997772217, 'eval_accuracy': 0.6806495189666748, 'eval_f1': 0.6773260116633611, 'eval_runtime': 3.1581, 'eval_samples_per_second': 234.001, 'eval_steps_per_second': 29.448, 'epoch': 9.0}\n",
      "\n",
      "100%|███████████████████████████████████████| 1269/1269 [07:18<00:00,  4.78it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-16 22:31:06,334 >> Saving model checkpoint to models/ZeroShot/0/checkpoint-1269\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:31:06,363 >> Configuration saved in models/ZeroShot/0/checkpoint-1269/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:31:08,609 >> Model weights saved in models/ZeroShot/0/checkpoint-1269/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:31:08,658 >> tokenizer config file saved in models/ZeroShot/0/checkpoint-1269/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:31:08,673 >> Special tokens file saved in models/ZeroShot/0/checkpoint-1269/special_tokens_map.json\n",
      "[INFO|trainer.py:1409] 2021-12-16 22:31:14,675 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:1418] 2021-12-16 22:31:14,676 >> Loading best model from models/ZeroShot/0/checkpoint-1128 (score: 0.6939000929667437).\n",
      "{'train_runtime': 448.1311, 'train_samples_per_second': 90.195, 'train_steps_per_second': 2.832, 'train_loss': 0.14067163572619523, 'epoch': 9.0}\n",
      "100%|███████████████████████████████████████| 1269/1269 [07:27<00:00,  2.83it/s]\n",
      "[INFO|trainer.py:1995] 2021-12-16 22:31:16,037 >> Saving model checkpoint to models/ZeroShot/0/\n",
      "[INFO|configuration_utils.py:417] 2021-12-16 22:31:16,067 >> Configuration saved in models/ZeroShot/0/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-16 22:31:18,722 >> Model weights saved in models/ZeroShot/0/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-16 22:31:18,758 >> tokenizer config file saved in models/ZeroShot/0/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-16 22:31:18,788 >> Special tokens file saved in models/ZeroShot/0/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        9.0\n",
      "  train_loss               =     0.1407\n",
      "  train_runtime            = 0:07:28.13\n",
      "  train_samples            =       4491\n",
      "  train_samples_per_second =     90.195\n",
      "  train_steps_per_second   =      2.832\n",
      "12/16/2021 22:31:19 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2021-12-16 22:31:19,418 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-16 22:31:19,420 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-16 22:31:19,420 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-16 22:31:19,420 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 93/93 [00:03<00:00, 28.23it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        9.0\n",
      "  eval_accuracy           =     0.6955\n",
      "  eval_f1                 =     0.6939\n",
      "  eval_loss               =     2.1835\n",
      "  eval_runtime            = 0:00:03.10\n",
      "  eval_samples            =        739\n",
      "  eval_samples_per_second =    237.768\n",
      "  eval_steps_per_second   =     29.922\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'bert-base-multilingual-cased' \\\n",
    "    \t--do_train \\\n",
    "    \t--do_eval \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/0/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrfwDiORPDyS",
    "outputId": "fd468b6a-810e-4743-8e39-794a5bb9de2c"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ibb2Uo0vPPc3"
   },
   "outputs": [],
   "source": [
    "## Create save path\n",
    "#!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/\n",
    "## Copy saved model.\n",
    "#!cp -r /content/models/ZeroShot/0/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etL-Ic6bPmtA"
   },
   "outputs": [],
   "source": [
    "## Bring back saved model here. \n",
    "#!mkdir -p /content/models/ZeroShot/0/\n",
    "# !cp -r /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/* /content/models/ZeroShot/0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bN4iUHWP45b"
   },
   "source": [
    "## Evaluation On Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "houOZpcYO-Pw",
    "outputId": "e8583e14-6ffc-4c18-c718-98400b394f30",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/12/2022 14:16:24 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/12/2022 14:16:24 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/0/eval-dev/runs/Jan12_14-16-24_r18g08.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/0/eval-dev/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/0/eval-dev/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "01/12/2022 14:16:25 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train.csv\n",
      "01/12/2022 14:16:25 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev.csv\n",
      "01/12/2022 14:16:25 - INFO - __main__ -   load a local file for test: Data/ZeroShot/dev.csv\n",
      "01/12/2022 14:16:26 - WARNING - datasets.builder -   Using custom data configuration default-b865db4fc186caf3\n",
      "01/12/2022 14:16:27 - WARNING - datasets.builder -   Reusing dataset csv (/users/sitkonen/.cache/huggingface/datasets/csv/default-b865db4fc186caf3/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:01<00:00,  2.16it/s]\n",
      "[INFO|configuration_utils.py:586] 2022-01-12 14:16:28,934 >> loading configuration file models/ZeroShot/0/config.json\n",
      "[INFO|configuration_utils.py:625] 2022-01-12 14:16:28,935 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2022-01-12 14:16:29,228 >> Didn't find file models/ZeroShot/0/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:16:29,248 >> loading file models/ZeroShot/0/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:16:29,248 >> loading file models/ZeroShot/0/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:16:29,249 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:16:29,249 >> loading file models/ZeroShot/0/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:16:29,249 >> loading file models/ZeroShot/0/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1338] 2022-01-12 14:16:32,511 >> loading weights file models/ZeroShot/0/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1607] 2022-01-12 14:16:39,576 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[INFO|modeling_utils.py:1616] 2022-01-12 14:16:39,576 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/ZeroShot/0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "01/12/2022 14:16:39 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-b865db4fc186caf3/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-dfbf7090187a85ab.arrow\n",
      "01/12/2022 14:16:40 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-b865db4fc186caf3/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-5d3d7807dcd97e80.arrow\n",
      "01/12/2022 14:16:40 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-b865db4fc186caf3/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-a79d9b77090cea85.arrow\n",
      "01/12/2022 14:17:54 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2022-01-12 14:17:54,683 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2022-01-12 14:17:55,214 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2022-01-12 14:17:55,214 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2022-01-12 14:17:55,214 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 93/93 [00:04<00:00, 22.94it/s]\n",
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.6955\n",
      "  eval_f1                 =     0.6939\n",
      "  eval_loss               =     2.1835\n",
      "  eval_runtime            = 0:00:13.34\n",
      "  eval_samples            =        739\n",
      "  eval_samples_per_second =     55.367\n",
      "  eval_steps_per_second   =      6.968\n",
      "01/12/2022 14:18:08 - INFO - __main__ -   *** Test ***\n",
      "AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
      "  test_dataset.remove_columns_(\"label\")\n",
      "[INFO|trainer.py:541] 2022-01-12 14:18:08,894 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2022-01-12 14:18:08,897 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2245] 2022-01-12 14:18:08,897 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2022-01-12 14:18:08,897 >>   Batch size = 8\n",
      " 97%|█████████████████████████████████████████▌ | 90/93 [00:02<00:00, 32.44it/s][[1.85984731e-01 3.35870123e+00]\n",
      " [6.88745346e+01 1.61897596e-02]\n",
      " [3.12989622e-01 3.45286894e+00]\n",
      " ...\n",
      " [6.08094482e+01 1.72609743e-02]\n",
      " [8.51096725e+01 1.43152345e-02]\n",
      " [7.93834534e+01 1.41860256e-02]]\n",
      "[[5.2468609e-02 9.4753140e-01]\n",
      " [9.9976498e-01 2.3500637e-04]\n",
      " [8.3112419e-02 9.1688758e-01]\n",
      " ...\n",
      " [9.9971622e-01 2.8377294e-04]\n",
      " [9.9983186e-01 1.6816922e-04]\n",
      " [9.9982136e-01 1.7867063e-04]]\n",
      "01/12/2022 14:18:11 - INFO - __main__ -   ***** Test results None *****\n",
      "100%|███████████████████████████████████████████| 93/93 [00:03<00:00, 29.99it/s]\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/ZeroShot/0' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/0/eval-dev/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
    "      --test_file Data/ZeroShot/dev.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.array([[2,1], [3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.57142857])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(foo, axis=1)/np.sum(foo, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHqPYuTS3muJ"
   },
   "source": [
    "### Use predictions to create the submission file (for dev data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qfWUuwg7Qm-t"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'submission_format_file' : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
    "    'prediction_format_file' : 'models/ZeroShot/0/eval-dev/test_results_None.txt'                        ,\n",
    "    }\n",
    "params[ 'setting' ] = 'zero_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cgFGlGnTROJZ"
   },
   "outputs": [],
   "source": [
    " updated_data = insert_to_submission_file( **params )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zXcRbv70RZfR"
   },
   "outputs": [],
   "source": [
    "!mkdir -p outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ezIzyWTRePp",
    "outputId": "7de89b60-8070-46de-b295-fa90cf847955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote outputs/zero_shot_dev_formated.csv\n"
     ]
    }
   ],
   "source": [
    "write_csv( updated_data, 'outputs/zero_shot_dev_formated.csv' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the development data, we can run evaluation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "Dn6MyP9jRnFA",
    "outputId": "a4e5e3e6-287b-4de6-c643-e569e9c2b42e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Settings</th>\n",
       "      <th>Languages</th>\n",
       "      <th>F1 Score (Macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>EN</td>\n",
       "      <td>0.70485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>PT</td>\n",
       "      <td>0.611721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>EN,PT</td>\n",
       "      <td>0.6939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one_shot</td>\n",
       "      <td>EN</td>\n",
       "      <td>(None, None, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one_shot</td>\n",
       "      <td>PT</td>\n",
       "      <td>(None, None, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one_shot</td>\n",
       "      <td>EN,PT</td>\n",
       "      <td>(None, None, None)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Settings Languages    F1 Score (Macro)\n",
       "0  zero_shot        EN             0.70485\n",
       "1  zero_shot        PT            0.611721\n",
       "2  zero_shot     EN,PT              0.6939\n",
       "3   one_shot        EN  (None, None, None)\n",
       "4   one_shot        PT  (None, None, None)\n",
       "5   one_shot     EN,PT  (None, None, None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append( 'SemEval_2022_Task2-idiomaticity/SubTaskA/' ) \n",
    "from SubTask1Evaluator import evaluate_submission\n",
    "\n",
    "\n",
    "submission_file = 'outputs/zero_shot_dev_formated.csv'\n",
    "gold_file       = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
    "\n",
    "results = evaluate_submission( submission_file, gold_file )\n",
    "#%reload_ext google.colab.data_table\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data=results[1:], columns=results[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating separate models for English and multi-lingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = util.load_csv_dataframes('SemEval_2022_Task2-idiomaticity/SubTaskA/Data')\n",
    "tframes = util.load_csv_dataframes('SemEval_2022_Task2-idiomaticity/SubTaskA/TestData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = frames['train_zero_shot.csv']\n",
    "odf = frames['train_one_shot.csv']\n",
    "ddf = frames['dev.csv']\n",
    "ddf_gold = frames['dev_gold.csv']\n",
    "edf = frames['eval.csv']\n",
    "tdf = tframes['test.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_enindex = zdf['Language'] == 'EN'\n",
    "dev_enindex = ddf['Language'] == 'EN'\n",
    "eval_enindex = edf['Language'] == 'EN'\n",
    "test_enindex = tdf['Language'] == 'EN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_en = zdf[zdf_enindex].drop(['Language', 'DataID', 'Setting', 'Previous', 'Next'],\n",
    "                                axis=1).rename(columns={'Label': 'label',\n",
    "                                                        'Target': 'sentence1',\n",
    "                                                        'MWE': 'sentence2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_oth = zdf[~zdf_enindex].drop(['Language', 'DataID', 'Setting', 'Previous', 'Next'],\n",
    "                                 axis=1).rename(columns={'Label': 'label',\n",
    "                                                         'Target': 'sentence1',\n",
    "                                                         'MWE': 'sentence2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['label'] = ddf_gold['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_en = ddf[dev_enindex].drop(['Language', 'ID', 'Previous', 'Next'],\n",
    "                                axis=1).rename(columns={'Target': 'sentence1', 'MWE': 'sentence2'})\n",
    "ddf_oth = ddf[~dev_enindex].drop(['Language', 'ID', 'Previous', 'Next'],\n",
    "                                 axis=1).rename(columns={'Target': 'sentence1', 'MWE': 'sentence2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_en = edf[eval_enindex].drop(['Language', 'ID', 'Previous', 'Next'],\n",
    "                                 axis=1).rename(columns={'Target': 'sentence1', 'MWE': 'sentence2'})\n",
    "edf_oth = edf[~eval_enindex].drop(['Language', 'ID', 'Previous', 'Next'],\n",
    "                                   axis=1).rename(columns={'Target': 'sentence1', 'MWE': 'sentence2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_en = tdf[test_enindex].drop(['Language', 'ID', 'Previous', 'Next'],\n",
    "                                 axis=1).rename(columns={'Target': 'sentence1', 'MWE': 'sentence2'})\n",
    "tdf_oth = tdf[~test_enindex].drop(['Language', 'ID', 'Previous', 'Next'],\n",
    "                                   axis=1).rename(columns={'Target': 'sentence1', 'MWE': 'sentence2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf_en.to_csv('Data/ZeroShot/train_en_2.csv', index=False)\n",
    "zdf_oth.to_csv('Data/ZeroShot/train_ot_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_en.to_csv('Data/ZeroShot/dev_en_2.csv', index=False)\n",
    "ddf_oth.to_csv('Data/ZeroShot/dev_ot_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_en.to_csv('Data/ZeroShot/eval_en_2.csv', index=False)\n",
    "edf_oth.to_csv('Data/ZeroShot/eval_ot_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_en.to_csv('Data/ZeroShot/test_en.csv', index=False)\n",
    "tdf_oth.to_csv('Data/ZeroShot/test_ot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'bert-base-cased' \\\n",
    "    \t--do_train \\\n",
    "    \t--do_eval \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/1/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train_en_2.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev_en_2.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/17/2021 00:55:54 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/17/2021 00:55:54 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/2/runs/Dec17_00-55-54_r16g07.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/2/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/2/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/17/2021 00:55:54 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_ot_2.csv\n",
      "12/17/2021 00:55:54 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev_ot_2.csv\n",
      "12/17/2021 00:55:55 - WARNING - datasets.builder -   Using custom data configuration default-207064003a515ef3\n",
      "12/17/2021 00:55:55 - WARNING - datasets.builder -   Reusing dataset csv (/users/sitkonen/.cache/huggingface/datasets/csv/default-207064003a515ef3/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 63.48it/s]\n",
      "[INFO|configuration_utils.py:588] 2021-12-17 00:55:55,884 >> loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /users/sitkonen/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "[INFO|configuration_utils.py:625] 2021-12-17 00:55:55,884 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:588] 2021-12-17 00:55:56,915 >> loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /users/sitkonen/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "[INFO|configuration_utils.py:625] 2021-12-17 00:55:56,916 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-17 00:55:59,994 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /users/sitkonen/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-17 00:55:59,994 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /users/sitkonen/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-17 00:55:59,994 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-17 00:55:59,994 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-17 00:55:59,994 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /users/sitkonen/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "[INFO|configuration_utils.py:588] 2021-12-17 00:56:00,506 >> loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /users/sitkonen/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "[INFO|configuration_utils.py:625] 2021-12-17 00:56:00,506 >> Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1340] 2021-12-17 00:56:01,627 >> loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /users/sitkonen/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "[WARNING|modeling_utils.py:1599] 2021-12-17 00:56:03,864 >> Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:1610] 2021-12-17 00:56:03,864 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/17/2021 00:56:03 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-207064003a515ef3/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-1c0d49d71bfa7cac.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.05ba/s]\n",
      "12/17/2021 00:56:04 - INFO - __main__ -   Sample 788 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 17607, 11070, 117, 10126, 20114, 50510, 13168, 11782, 10293, 10398, 93898, 10107, 10220, 26561, 183, 16008, 60259, 15088, 10212, 169, 77868, 24283, 10229, 117, 21752, 10266, 25598, 254, 24960, 93262, 119, 102, 77868, 118, 24283, 10229, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'sentence1': 'Ao final, se dirigiu até cada um dos parlamentares para fazer o cumprimento com a mão fechada, tradicional em meio à pandemia.', 'sentence2': 'mão-fechada', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "12/17/2021 00:56:04 - INFO - __main__ -   Sample 861 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 138, 108234, 37078, 10104, 10722, 100745, 106495, 183, 17084, 10225, 100, 183, 38578, 10149, 11708, 17478, 100, 119, 102, 11708, 17478, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'sentence1': 'A Constituição Soviética de 1977 definiu o Partido como “o núcleo do sistema político”.', 'sentence2': 'sistema político', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "12/17/2021 00:56:04 - INFO - __main__ -   Sample 82 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 63412, 11449, 117, 10220, 12923, 23134, 173, 101058, 10104, 11675, 169, 77868, 10132, 20701, 117, 10678, 10419, 12606, 13495, 10605, 169, 47145, 10280, 173, 169, 13301, 61620, 37940, 119, 102, 13301, 61620, 37940, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'sentence1': 'Então, para dar início e colocar de vez a mão na massa, comece misturando a aveia e a farinha integral.', 'sentence2': 'farinha integral', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "[INFO|trainer.py:541] 2021-12-17 00:56:09,258 >> The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:1196] 2021-12-17 00:56:09,264 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2021-12-17 00:56:09,264 >>   Num examples = 1164\n",
      "[INFO|trainer.py:1198] 2021-12-17 00:56:09,264 >>   Num Epochs = 9\n",
      "[INFO|trainer.py:1199] 2021-12-17 00:56:09,264 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:1200] 2021-12-17 00:56:09,264 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1201] 2021-12-17 00:56:09,264 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2021-12-17 00:56:09,264 >>   Total optimization steps = 333\n",
      " 11%|████▋                                     | 37/333 [00:08<00:56,  5.20it/s][INFO|trainer.py:541] 2021-12-17 00:56:17,693 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:56:17,695 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:56:17,695 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:56:17,695 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:00<00:00, 56.09it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:00<00:00, 50.39it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:00<00:00, 48.58it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:00<00:00, 47.65it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:00<00:00, 47.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9441168308258057, 'eval_accuracy': 0.6263736486434937, 'eval_f1': 0.5457718909043456, 'eval_runtime': 0.7401, 'eval_samples_per_second': 368.847, 'eval_steps_per_second': 47.288, 'epoch': 1.0}\n",
      " 11%|████▋                                     | 37/333 [00:09<00:56,  5.20it/s]\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 46.99it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-17 00:56:18,439 >> Saving model checkpoint to models/ZeroShot/2/checkpoint-37\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:56:18,441 >> Configuration saved in models/ZeroShot/2/checkpoint-37/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:56:19,973 >> Model weights saved in models/ZeroShot/2/checkpoint-37/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:56:19,975 >> tokenizer config file saved in models/ZeroShot/2/checkpoint-37/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:56:19,976 >> Special tokens file saved in models/ZeroShot/2/checkpoint-37/special_tokens_map.json\n",
      " 22%|█████████▎                                | 74/333 [00:21<00:49,  5.19it/s][INFO|trainer.py:541] 2021-12-17 00:56:30,594 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:56:30,596 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:56:30,596 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:56:30,596 >>   Batch size = 8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:00<00:00, 55.08it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:00<00:00, 49.88it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:00<00:00, 48.12it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:00<00:00, 47.50it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:00<00:00, 47.21it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.3511855602264404, 'eval_accuracy': 0.6153846383094788, 'eval_f1': 0.5270192228363997, 'eval_runtime': 0.7423, 'eval_samples_per_second': 367.786, 'eval_steps_per_second': 47.152, 'epoch': 2.0}\n",
      " 22%|█████████▎                                | 74/333 [00:22<00:49,  5.19it/s]\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 47.01it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-17 00:56:31,342 >> Saving model checkpoint to models/ZeroShot/2/checkpoint-74\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:56:31,344 >> Configuration saved in models/ZeroShot/2/checkpoint-74/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:56:33,053 >> Model weights saved in models/ZeroShot/2/checkpoint-74/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:56:33,055 >> tokenizer config file saved in models/ZeroShot/2/checkpoint-74/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:56:33,056 >> Special tokens file saved in models/ZeroShot/2/checkpoint-74/special_tokens_map.json\n",
      " 33%|█████████████▋                           | 111/333 [00:35<00:58,  3.79it/s][INFO|trainer.py:541] 2021-12-17 00:56:44,954 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:56:45,533 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:56:45,534 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:56:45,534 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:00<00:00, 56.19it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:00<00:00, 50.06it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:00<00:00, 48.49it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:00<00:00, 47.66it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:00<00:00, 47.14it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.834763526916504, 'eval_accuracy': 0.593406617641449, 'eval_f1': 0.4960335279149828, 'eval_runtime': 1.5577, 'eval_samples_per_second': 175.255, 'eval_steps_per_second': 22.469, 'epoch': 3.0}\n",
      " 33%|█████████████▋                           | 111/333 [00:37<00:58,  3.79it/s]\n",
      "100%|███████████████████████████████████████████| 35/35 [00:01<00:00, 46.91it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-17 00:56:47,096 >> Saving model checkpoint to models/ZeroShot/2/checkpoint-111\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:56:47,098 >> Configuration saved in models/ZeroShot/2/checkpoint-111/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:56:48,222 >> Model weights saved in models/ZeroShot/2/checkpoint-111/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:56:48,224 >> tokenizer config file saved in models/ZeroShot/2/checkpoint-111/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:56:48,225 >> Special tokens file saved in models/ZeroShot/2/checkpoint-111/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-17 00:56:54,227 >> Deleting older checkpoint [models/ZeroShot/2/checkpoint-74] due to args.save_total_limit\n",
      " 44%|██████████████████▏                      | 148/333 [00:53<00:35,  5.21it/s][INFO|trainer.py:541] 2021-12-17 00:57:03,043 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:57:03,045 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:57:03,045 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:57:03,045 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:00<00:00, 56.16it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:00<00:00, 50.32it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:00<00:00, 48.63it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:00<00:00, 47.87it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:00<00:00, 47.37it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 33/35 [00:00<00:00, 47.16it/s]\u001b[A\n",
      "{'eval_loss': 2.0615971088409424, 'eval_accuracy': 0.6153846383094788, 'eval_f1': 0.5270192228363997, 'eval_runtime': 0.7376, 'eval_samples_per_second': 370.096, 'eval_steps_per_second': 47.448, 'epoch': 4.0}\n",
      "\n",
      " 44%|██████████████████▏                      | 148/333 [00:54<00:35,  5.21it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-17 00:57:03,787 >> Saving model checkpoint to models/ZeroShot/2/checkpoint-148\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:57:03,789 >> Configuration saved in models/ZeroShot/2/checkpoint-148/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:57:06,040 >> Model weights saved in models/ZeroShot/2/checkpoint-148/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:57:06,042 >> tokenizer config file saved in models/ZeroShot/2/checkpoint-148/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:57:06,043 >> Special tokens file saved in models/ZeroShot/2/checkpoint-148/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-17 00:57:10,013 >> Deleting older checkpoint [models/ZeroShot/2/checkpoint-111] due to args.save_total_limit\n",
      " 56%|██████████████████████▊                  | 185/333 [01:13<00:28,  5.21it/s][INFO|trainer.py:541] 2021-12-17 00:57:23,046 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:57:23,049 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:57:23,049 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:57:23,049 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 5/35 [00:00<00:00, 49.93it/s]\u001b[A\n",
      " 29%|████████████▎                              | 10/35 [00:00<00:00, 47.91it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 15/35 [00:00<00:00, 47.14it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 20/35 [00:00<00:00, 46.48it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 25/35 [00:00<00:00, 46.50it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 30/35 [00:00<00:00, 46.45it/s]\u001b[A\n",
      "{'eval_loss': 2.1764533519744873, 'eval_accuracy': 0.6043956279754639, 'eval_f1': 0.5153846153846153, 'eval_runtime': 0.97, 'eval_samples_per_second': 281.435, 'eval_steps_per_second': 36.081, 'epoch': 5.0}\n",
      "\n",
      " 56%|██████████████████████▊                  | 185/333 [01:14<00:28,  5.21it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-17 00:57:24,022 >> Saving model checkpoint to models/ZeroShot/2/checkpoint-185\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:57:24,024 >> Configuration saved in models/ZeroShot/2/checkpoint-185/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:57:25,339 >> Model weights saved in models/ZeroShot/2/checkpoint-185/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:57:25,340 >> tokenizer config file saved in models/ZeroShot/2/checkpoint-185/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:57:25,341 >> Special tokens file saved in models/ZeroShot/2/checkpoint-185/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2073] 2021-12-17 00:57:29,736 >> Deleting older checkpoint [models/ZeroShot/2/checkpoint-148] due to args.save_total_limit\n",
      " 67%|███████████████████████████▎             | 222/333 [01:29<00:21,  5.23it/s][INFO|trainer.py:541] 2021-12-17 00:57:38,329 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:57:38,456 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:57:38,456 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:57:38,456 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:00<00:00, 55.29it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:00<00:00, 49.98it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:00<00:00, 48.40it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:00<00:00, 47.63it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:00<00:00, 47.32it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 33/35 [00:00<00:00, 47.07it/s]\u001b[A\n",
      "{'eval_loss': 2.1115195751190186, 'eval_accuracy': 0.6520146727561951, 'eval_f1': 0.590239046972019, 'eval_runtime': 0.7404, 'eval_samples_per_second': 368.702, 'eval_steps_per_second': 47.269, 'epoch': 6.0}\n",
      "\n",
      " 67%|███████████████████████████▎             | 222/333 [01:29<00:21,  5.23it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-17 00:57:39,200 >> Saving model checkpoint to models/ZeroShot/2/checkpoint-222\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:57:39,202 >> Configuration saved in models/ZeroShot/2/checkpoint-222/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:57:41,934 >> Model weights saved in models/ZeroShot/2/checkpoint-222/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:57:41,936 >> tokenizer config file saved in models/ZeroShot/2/checkpoint-222/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:57:41,937 >> Special tokens file saved in models/ZeroShot/2/checkpoint-222/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-17 00:57:44,222 >> Deleting older checkpoint [models/ZeroShot/2/checkpoint-37] due to args.save_total_limit\n",
      "[INFO|trainer.py:2073] 2021-12-17 00:57:44,471 >> Deleting older checkpoint [models/ZeroShot/2/checkpoint-185] due to args.save_total_limit\n",
      " 78%|███████████████████████████████▉         | 259/333 [01:43<00:14,  5.22it/s][INFO|trainer.py:541] 2021-12-17 00:57:53,068 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:57:53,069 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:57:53,070 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:57:53,070 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:00<00:00, 55.32it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:00<00:00, 49.76it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:00<00:00, 48.21it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:00<00:00, 47.36it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:00<00:00, 47.07it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 33/35 [00:00<00:00, 46.90it/s]\u001b[A\n",
      "{'eval_loss': 2.355102062225342, 'eval_accuracy': 0.6263736486434937, 'eval_f1': 0.5523726851851851, 'eval_runtime': 0.7429, 'eval_samples_per_second': 367.502, 'eval_steps_per_second': 47.116, 'epoch': 7.0}\n",
      "\n",
      " 78%|███████████████████████████████▉         | 259/333 [01:44<00:14,  5.22it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-17 00:57:53,818 >> Saving model checkpoint to models/ZeroShot/2/checkpoint-259\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:57:53,820 >> Configuration saved in models/ZeroShot/2/checkpoint-259/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:57:54,908 >> Model weights saved in models/ZeroShot/2/checkpoint-259/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:57:54,912 >> tokenizer config file saved in models/ZeroShot/2/checkpoint-259/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:57:54,913 >> Special tokens file saved in models/ZeroShot/2/checkpoint-259/special_tokens_map.json\n",
      " 89%|████████████████████████████████████▍    | 296/333 [01:57<00:07,  5.25it/s][INFO|trainer.py:541] 2021-12-17 00:58:06,562 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:58:06,563 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:58:06,563 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:58:06,563 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:00<00:00, 55.42it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:00<00:00, 49.48it/s]\u001b[A\n",
      " 49%|████████████████████▉                      | 17/35 [00:00<00:00, 48.10it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 22/35 [00:00<00:00, 47.38it/s]\u001b[A\n",
      " 77%|█████████████████████████████████▏         | 27/35 [00:00<00:00, 47.03it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.4636988639831543, 'eval_accuracy': 0.622710645198822, 'eval_f1': 0.5463579898362507, 'eval_runtime': 0.7445, 'eval_samples_per_second': 366.707, 'eval_steps_per_second': 47.014, 'epoch': 8.0}\n",
      " 89%|████████████████████████████████████▍    | 296/333 [01:58<00:07,  5.25it/s]\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 46.87it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-17 00:58:07,311 >> Saving model checkpoint to models/ZeroShot/2/checkpoint-296\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:58:07,314 >> Configuration saved in models/ZeroShot/2/checkpoint-296/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:58:09,799 >> Model weights saved in models/ZeroShot/2/checkpoint-296/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:58:09,804 >> tokenizer config file saved in models/ZeroShot/2/checkpoint-296/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:58:09,812 >> Special tokens file saved in models/ZeroShot/2/checkpoint-296/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-17 00:58:13,213 >> Deleting older checkpoint [models/ZeroShot/2/checkpoint-259] due to args.save_total_limit\n",
      "100%|█████████████████████████████████████████| 333/333 [02:12<00:00,  5.25it/s][INFO|trainer.py:541] 2021-12-17 00:58:21,876 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:58:21,878 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:58:21,878 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:58:21,878 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:00<00:00, 55.25it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:00<00:00, 49.84it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:00<00:00, 48.32it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:00<00:00, 47.72it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:00<00:00, 47.34it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.441563844680786, 'eval_accuracy': 0.6263736486434937, 'eval_f1': 0.5523726851851851, 'eval_runtime': 0.7401, 'eval_samples_per_second': 368.881, 'eval_steps_per_second': 47.292, 'epoch': 9.0}\n",
      "100%|█████████████████████████████████████████| 333/333 [02:13<00:00,  5.25it/s]\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 47.11it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:1995] 2021-12-17 00:58:22,622 >> Saving model checkpoint to models/ZeroShot/2/checkpoint-333\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:58:22,624 >> Configuration saved in models/ZeroShot/2/checkpoint-333/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:58:24,443 >> Model weights saved in models/ZeroShot/2/checkpoint-333/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:58:24,445 >> tokenizer config file saved in models/ZeroShot/2/checkpoint-333/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:58:24,447 >> Special tokens file saved in models/ZeroShot/2/checkpoint-333/special_tokens_map.json\n",
      "[INFO|trainer.py:2073] 2021-12-17 00:58:27,596 >> Deleting older checkpoint [models/ZeroShot/2/checkpoint-296] due to args.save_total_limit\n",
      "[INFO|trainer.py:1409] 2021-12-17 00:58:27,918 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:1418] 2021-12-17 00:58:27,918 >> Loading best model from models/ZeroShot/2/checkpoint-222 (score: 0.590239046972019).\n",
      "{'train_runtime': 139.1705, 'train_samples_per_second': 75.275, 'train_steps_per_second': 2.393, 'train_loss': 0.10252386098867422, 'epoch': 9.0}\n",
      "100%|█████████████████████████████████████████| 333/333 [02:19<00:00,  2.39it/s]\n",
      "[INFO|trainer.py:1995] 2021-12-17 00:58:28,449 >> Saving model checkpoint to models/ZeroShot/2/\n",
      "[INFO|configuration_utils.py:417] 2021-12-17 00:58:28,450 >> Configuration saved in models/ZeroShot/2/config.json\n",
      "[INFO|modeling_utils.py:1058] 2021-12-17 00:58:29,498 >> Model weights saved in models/ZeroShot/2/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2034] 2021-12-17 00:58:29,499 >> tokenizer config file saved in models/ZeroShot/2/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2040] 2021-12-17 00:58:29,501 >> Special tokens file saved in models/ZeroShot/2/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        9.0\n",
      "  train_loss               =     0.1025\n",
      "  train_runtime            = 0:02:19.17\n",
      "  train_samples            =       1164\n",
      "  train_samples_per_second =     75.275\n",
      "  train_steps_per_second   =      2.393\n",
      "12/17/2021 00:58:29 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2021-12-17 00:58:29,693 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-17 00:58:29,695 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-17 00:58:29,695 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-17 00:58:29,695 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 48.19it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        9.0\n",
      "  eval_accuracy           =      0.652\n",
      "  eval_f1                 =     0.5902\n",
      "  eval_loss               =     2.1115\n",
      "  eval_runtime            = 0:00:00.74\n",
      "  eval_samples            =        273\n",
      "  eval_samples_per_second =    366.575\n",
      "  eval_steps_per_second   =     46.997\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'bert-base-multilingual-cased' \\\n",
    "    \t--do_train \\\n",
    "    \t--do_eval \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/2/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train_ot_2.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev_ot_2.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for language-separated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 21:39:27 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 21:39:27 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/1/eval-dev/runs/Dec20_21-39-26_r18g08.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/1/eval-dev/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/1/eval-dev/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 21:39:27 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_en_2.csv\n",
      "12/20/2021 21:39:27 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev_en_2.csv\n",
      "12/20/2021 21:39:27 - INFO - __main__ -   load a local file for test: Data/ZeroShot/dev_en_2.csv\n",
      "12/20/2021 21:39:28 - WARNING - datasets.builder -   Using custom data configuration default-703aab5a1881fdc4\n",
      "12/20/2021 21:39:28 - WARNING - datasets.builder -   Reusing dataset csv (/users/sitkonen/.cache/huggingface/datasets/csv/default-703aab5a1881fdc4/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 24.41it/s]\n",
      "[INFO|configuration_utils.py:586] 2021-12-20 21:39:28,425 >> loading configuration file models/ZeroShot/1/config.json\n",
      "[INFO|configuration_utils.py:625] 2021-12-20 21:39:28,426 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 21:39:28,536 >> Didn't find file models/ZeroShot/1/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:39:28,549 >> loading file models/ZeroShot/1/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:39:28,549 >> loading file models/ZeroShot/1/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:39:28,549 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:39:28,549 >> loading file models/ZeroShot/1/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:39:28,549 >> loading file models/ZeroShot/1/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1338] 2021-12-20 21:39:29,248 >> loading weights file models/ZeroShot/1/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1607] 2021-12-20 21:39:32,317 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[INFO|modeling_utils.py:1616] 2021-12-20 21:39:32,317 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/ZeroShot/1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "12/20/2021 21:39:32 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-703aab5a1881fdc4/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-f04b2c3030c7edc6.arrow\n",
      "12/20/2021 21:39:32 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-703aab5a1881fdc4/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-c35b18c550312a61.arrow\n",
      "12/20/2021 21:39:32 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-703aab5a1881fdc4/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-5aa02422372b248b.arrow\n",
      "12/20/2021 21:40:05 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2021-12-20 21:40:05,455 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:40:05,950 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:40:05,950 >>   Num examples = 466\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:40:05,950 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 59/59 [00:01<00:00, 42.70it/s]\n",
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.7682\n",
      "  eval_f1                 =     0.7605\n",
      "  eval_loss               =     1.0696\n",
      "  eval_runtime            = 0:00:03.63\n",
      "  eval_samples            =        466\n",
      "  eval_samples_per_second =    128.108\n",
      "  eval_steps_per_second   =      16.22\n",
      "12/20/2021 21:40:09 - INFO - __main__ -   *** Test ***\n",
      "AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
      "  test_dataset.remove_columns_(\"label\")\n",
      "[INFO|trainer.py:541] 2021-12-20 21:40:09,635 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:40:09,637 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:40:09,637 >>   Num examples = 466\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:40:09,637 >>   Batch size = 8\n",
      " 97%|█████████████████████████████████████████▌ | 57/59 [00:01<00:00, 45.43it/s][[ 0.14015754  3.4728734 ]\n",
      " [ 2.453974    0.23520221]\n",
      " [ 1.0561429   0.46132907]\n",
      " [ 3.827353    0.15104884]\n",
      " [ 6.796733    0.08889908]\n",
      " [ 0.03739276 16.024462  ]\n",
      " [ 1.095785    0.56941485]\n",
      " [ 2.3789182   0.24694401]\n",
      " [ 3.8399265   0.16093034]\n",
      " [ 2.7059748   0.2197619 ]\n",
      " [ 1.2842641   0.4346311 ]\n",
      " [ 0.07929524  6.1664953 ]\n",
      " [ 0.05886547  8.456268  ]\n",
      " [ 0.05442519 12.38576   ]\n",
      " [ 0.06305556 11.429794  ]\n",
      " [ 0.06326404 10.718592  ]\n",
      " [ 0.06603669 10.850031  ]\n",
      " [ 0.07848272  9.201639  ]\n",
      " [ 0.03800882 15.806222  ]\n",
      " [ 0.03898237 15.512296  ]\n",
      " [ 0.03895763 15.002945  ]\n",
      " [ 0.03595441 16.445078  ]\n",
      " [ 0.03802652 16.410082  ]\n",
      " [ 0.03994792 15.562682  ]\n",
      " [ 0.03507163 17.181364  ]\n",
      " [ 0.03770718 15.974969  ]\n",
      " [ 0.04541622 14.039096  ]\n",
      " [ 0.04150949 14.74497   ]\n",
      " [ 0.03835222 16.203524  ]\n",
      " [ 0.03649128 16.035376  ]\n",
      " [ 0.04361102 13.864791  ]\n",
      " [ 0.03670273 16.7237    ]\n",
      " [ 0.05602768 12.084775  ]\n",
      " [ 0.06037049  8.176787  ]\n",
      " [ 0.12918258  3.3840296 ]\n",
      " [ 0.11159363  3.7502294 ]\n",
      " [ 0.11300787  3.601454  ]\n",
      " [ 0.50005066  0.79150003]\n",
      " [ 0.16778794  2.6201394 ]\n",
      " [ 0.2425325   1.6199955 ]\n",
      " [ 0.6801259   0.5777756 ]\n",
      " [ 0.09130798  4.990564  ]\n",
      " [ 0.05473709 10.216377  ]\n",
      " [ 0.06776319  6.7114453 ]\n",
      " [ 0.09221686  4.580584  ]\n",
      " [ 0.3855005   0.95263976]\n",
      " [ 0.06248258  7.64839   ]\n",
      " [ 0.0338482  18.086298  ]\n",
      " [ 0.03329497 20.596083  ]\n",
      " [ 0.03560899 18.902426  ]\n",
      " [ 0.03355175 19.024353  ]\n",
      " [ 0.03885111 18.949219  ]\n",
      " [ 0.03353546 21.51682   ]\n",
      " [ 0.03153655 21.18593   ]\n",
      " [ 0.03697688 18.598238  ]\n",
      " [ 0.03179457 19.820461  ]\n",
      " [ 0.02903056 21.307709  ]\n",
      " [ 0.03890997 18.323324  ]\n",
      " [ 0.03718821 18.004658  ]\n",
      " [ 0.03074481 21.136583  ]\n",
      " [ 0.04282303 16.75371   ]\n",
      " [ 0.0341171  20.12093   ]\n",
      " [ 0.03506102 19.126892  ]\n",
      " [ 0.04432401 16.296417  ]\n",
      " [ 0.03419974 19.568323  ]\n",
      " [ 0.0395683  17.031912  ]\n",
      " [ 0.04624145 14.93666   ]\n",
      " [ 0.04572195 15.804876  ]\n",
      " [ 0.04642784 14.8552885 ]\n",
      " [ 0.04076914 17.131245  ]\n",
      " [ 0.03696504 19.663198  ]\n",
      " [ 0.04285812 17.215033  ]\n",
      " [ 0.03969626 17.7847    ]\n",
      " [ 0.04211994 16.124632  ]\n",
      " [ 0.04449822 15.863474  ]\n",
      " [ 0.04148468 15.71556   ]\n",
      " [ 0.04294255 16.261229  ]\n",
      " [ 0.04605876 15.947045  ]\n",
      " [ 0.04473239 14.73947   ]\n",
      " [ 6.608298    0.09283634]\n",
      " [ 0.10360038  5.3517737 ]\n",
      " [ 0.05196858 13.857309  ]\n",
      " [ 0.05535596 12.892661  ]\n",
      " [ 0.04907811 12.964092  ]\n",
      " [22.988846    0.03056171]\n",
      " [22.765152    0.03873907]\n",
      " [21.747116    0.03217316]\n",
      " [23.15057     0.03457122]\n",
      " [11.653373    0.05278759]\n",
      " [22.994446    0.03668364]\n",
      " [17.66661     0.03974268]\n",
      " [19.256004    0.05375313]\n",
      " [23.898596    0.03191433]\n",
      " [23.081345    0.03422276]\n",
      " [14.228364    0.04084419]\n",
      " [19.430462    0.03254272]\n",
      " [26.310066    0.03575399]\n",
      " [24.764553    0.03373691]\n",
      " [ 0.30554134  1.665045  ]\n",
      " [24.81036     0.03168501]\n",
      " [27.075182    0.03297255]\n",
      " [ 0.03795227 13.748218  ]\n",
      " [ 4.022741    0.13929886]\n",
      " [16.238384    0.04218886]\n",
      " [ 2.0251167   0.29484192]\n",
      " [22.510475    0.03480345]\n",
      " [14.033362    0.04535104]\n",
      " [ 0.0383255  14.448808  ]\n",
      " [ 0.06836087  9.875376  ]\n",
      " [ 0.04420406 13.656663  ]\n",
      " [ 0.05462985 12.107677  ]\n",
      " [ 0.10894991  4.3227644 ]\n",
      " [ 0.04650889 14.287135  ]\n",
      " [ 0.05301258  8.903786  ]\n",
      " [ 0.08131766  8.629108  ]\n",
      " [ 0.04449458 13.687592  ]\n",
      " [ 0.04751999 13.209411  ]\n",
      " [ 0.04644014 12.917278  ]\n",
      " [ 0.04888626 11.935113  ]\n",
      " [ 0.51955986  1.0243987 ]\n",
      " [ 0.04381047 14.092924  ]\n",
      " [ 0.04393732 14.2885895 ]\n",
      " [ 0.05883852 11.921782  ]\n",
      " [ 0.07358103  9.805676  ]\n",
      " [ 0.05199868 13.012471  ]\n",
      " [ 0.04561549 13.890266  ]\n",
      " [ 0.08194021  5.9009757 ]\n",
      " [ 0.05622815 10.774294  ]\n",
      " [24.14486     0.03773493]\n",
      " [23.993671    0.03375145]\n",
      " [23.283142    0.03545297]\n",
      " [24.255508    0.0404852 ]\n",
      " [15.557715    0.04224898]\n",
      " [24.760767    0.03586636]\n",
      " [22.998108    0.04271221]\n",
      " [18.609486    0.03618734]\n",
      " [22.9327      0.04281546]\n",
      " [25.17813     0.03544666]\n",
      " [23.247652    0.04205003]\n",
      " [23.759632    0.03439129]\n",
      " [ 4.228707    0.13219193]\n",
      " [ 0.05428537 10.324391  ]\n",
      " [ 0.05127012 12.735256  ]\n",
      " [ 0.14507574  3.016058  ]\n",
      " [ 0.07143696 10.089453  ]\n",
      " [ 0.07080308  7.75932   ]\n",
      " [ 0.07592036  8.955272  ]\n",
      " [21.891909    0.03933786]\n",
      " [ 0.07345457  7.8358035 ]\n",
      " [18.90387     0.03716645]\n",
      " [23.46942     0.0347123 ]\n",
      " [ 0.04967937  9.874175  ]\n",
      " [ 4.011636    0.14630398]\n",
      " [20.72037     0.04185571]\n",
      " [11.635006    0.0520522 ]\n",
      " [24.420242    0.03591287]\n",
      " [14.099302    0.05120504]\n",
      " [20.01621     0.04066686]\n",
      " [19.565111    0.04007284]\n",
      " [ 7.9825635   0.06907719]\n",
      " [15.777611    0.04386478]\n",
      " [14.84176     0.04670263]\n",
      " [23.61347     0.03519055]\n",
      " [11.8989105   0.05571593]\n",
      " [ 0.03649105 13.701141  ]\n",
      " [ 0.03457224 16.146269  ]\n",
      " [ 0.03525558 15.164284  ]\n",
      " [ 0.05084288  8.443338  ]\n",
      " [ 0.43294597  1.0790702 ]\n",
      " [ 1.2368578   0.41637206]\n",
      " [ 1.7433096   0.30597958]\n",
      " [12.684965    0.04800402]\n",
      " [ 1.0554518   0.5240218 ]\n",
      " [ 8.302375    0.06318922]\n",
      " [ 0.10673441  4.872938  ]\n",
      " [ 0.1200262   3.6937428 ]\n",
      " [ 0.19026034  2.4819808 ]\n",
      " [11.9248      0.04975236]\n",
      " [ 0.05040971 12.384629  ]\n",
      " [ 0.0986097   5.402322  ]\n",
      " [ 0.08936852  5.837675  ]\n",
      " [ 0.12514535  3.8442466 ]\n",
      " [ 0.06184866 11.791434  ]\n",
      " [ 0.06143053 11.601995  ]\n",
      " [ 0.05141421 10.423534  ]\n",
      " [20.447334    0.03878146]\n",
      " [23.76962     0.03776679]\n",
      " [22.86837     0.03394407]\n",
      " [21.993525    0.04119612]\n",
      " [24.978409    0.03499656]\n",
      " [23.83331     0.03370379]\n",
      " [20.543222    0.04053608]\n",
      " [24.220947    0.03625933]\n",
      " [23.222038    0.03937127]\n",
      " [ 0.05851814 11.421162  ]\n",
      " [ 0.05827117  8.9220915 ]\n",
      " [ 0.11000611  3.9902043 ]\n",
      " [ 0.04309777 13.964905  ]\n",
      " [ 0.03993312 12.780743  ]\n",
      " [ 0.05298997  8.750168  ]\n",
      " [ 0.07358193  9.119863  ]\n",
      " [ 0.09468435  7.5670266 ]\n",
      " [ 0.0476724  13.565869  ]\n",
      " [15.342816    0.0441268 ]\n",
      " [21.246708    0.03489436]\n",
      " [26.283815    0.03071576]\n",
      " [26.901005    0.0346194 ]\n",
      " [ 0.16629414  3.20391   ]\n",
      " [25.980528    0.03463059]\n",
      " [26.367126    0.03220166]\n",
      " [25.03225     0.0382459 ]\n",
      " [25.443455    0.03098005]\n",
      " [ 0.12123507  5.3638434 ]\n",
      " [ 0.0975594   7.4367824 ]\n",
      " [ 0.12885776  5.2124634 ]\n",
      " [ 0.0452624  15.196248  ]\n",
      " [ 0.03854806 16.954895  ]\n",
      " [ 0.05390584 12.804236  ]\n",
      " [ 0.05090591 13.938808  ]\n",
      " [ 0.04716533 13.968122  ]\n",
      " [ 0.05948303 11.942984  ]\n",
      " [ 0.05920736 11.789486  ]\n",
      " [ 0.03850424 17.723139  ]\n",
      " [ 0.03601699 18.734388  ]\n",
      " [ 0.04071328 15.752785  ]\n",
      " [ 0.03921202 16.644667  ]\n",
      " [ 0.03795443 16.202042  ]\n",
      " [ 0.03457358 18.839693  ]\n",
      " [ 0.04959401 13.709378  ]\n",
      " [ 0.04444708 15.2991905 ]\n",
      " [ 0.21487737  1.3682852 ]\n",
      " [ 0.11990605  3.167971  ]\n",
      " [ 0.05360136 11.180295  ]\n",
      " [ 0.09607294  4.1069336 ]\n",
      " [ 0.10161714  6.9424534 ]\n",
      " [ 0.08401322  8.012112  ]\n",
      " [ 0.06853368 10.261949  ]\n",
      " [ 0.1377382   2.1799004 ]\n",
      " [ 0.05041226  9.4236    ]\n",
      " [ 0.07407675  4.5733137 ]\n",
      " [ 0.08180938  8.584787  ]\n",
      " [ 0.07544427  7.8947625 ]\n",
      " [ 0.06068593  7.12226   ]\n",
      " [ 0.04355487 12.954388  ]\n",
      " [ 2.039649    0.3331673 ]\n",
      " [ 0.03666919 17.811981  ]\n",
      " [ 0.03509245 18.269346  ]\n",
      " [ 0.0397     16.867432  ]\n",
      " [ 0.04622008 15.17255   ]\n",
      " [ 0.04530006 14.523515  ]\n",
      " [ 0.04197617 15.888927  ]\n",
      " [ 0.04342553 15.881798  ]\n",
      " [ 0.03568844 17.77774   ]\n",
      " [ 0.03651928 17.072302  ]\n",
      " [ 0.03831112 16.079954  ]\n",
      " [ 0.04132602 16.090572  ]\n",
      " [ 0.0407627  15.567625  ]\n",
      " [ 0.04275232 16.603762  ]\n",
      " [ 0.03501924 18.889353  ]\n",
      " [ 0.03041964 20.747444  ]\n",
      " [ 0.03597715 18.630219  ]\n",
      " [ 0.03505773 18.117664  ]\n",
      " [ 0.03790357 17.711319  ]\n",
      " [ 0.03457411 18.982197  ]\n",
      " [ 0.03468346 18.858234  ]\n",
      " [ 0.03253993 20.212315  ]\n",
      " [ 0.04166602 15.813923  ]\n",
      " [ 0.04538793 14.688189  ]\n",
      " [ 0.0356304  17.75154   ]\n",
      " [ 0.03452924 17.777943  ]\n",
      " [ 0.04663768 15.192428  ]\n",
      " [ 0.03844997 16.79761   ]\n",
      " [ 0.03525737 18.142687  ]\n",
      " [ 0.03062853 19.628515  ]\n",
      " [ 0.03455704 18.076237  ]\n",
      " [ 0.04027294 16.553932  ]\n",
      " [ 2.9465854   0.14251767]\n",
      " [15.008497    0.03878687]\n",
      " [ 4.6269054   0.09837812]\n",
      " [ 0.77890384  0.5349603 ]\n",
      " [ 0.342403    0.85443866]\n",
      " [ 2.437156    0.1864319 ]\n",
      " [ 1.1504905   0.37826884]\n",
      " [ 6.635697    0.07080311]\n",
      " [22.178286    0.03531049]\n",
      " [11.958159    0.04650829]\n",
      " [18.256313    0.03503966]\n",
      " [ 4.425891    0.09392314]\n",
      " [ 0.43995184  0.79037464]\n",
      " [10.702981    0.05155961]\n",
      " [25.335573    0.03826593]\n",
      " [ 0.04970753 12.51694   ]\n",
      " [ 8.813518    0.06824583]\n",
      " [23.657997    0.03539003]\n",
      " [ 4.289874    0.12598988]\n",
      " [17.205662    0.04238767]\n",
      " [19.865213    0.04019967]\n",
      " [ 1.5003649   0.40445346]\n",
      " [12.594991    0.04979653]\n",
      " [22.163734    0.03835532]\n",
      " [ 0.38956845  1.1141092 ]\n",
      " [ 0.13139431  3.3215852 ]\n",
      " [ 0.04093894 13.241372  ]\n",
      " [ 0.06596497  7.074183  ]\n",
      " [ 0.0873872   4.4037523 ]\n",
      " [ 0.08792179  5.632673  ]\n",
      " [ 0.07205139  6.418249  ]\n",
      " [ 0.12323773  3.5153534 ]\n",
      " [22.789606    0.03567097]\n",
      " [ 0.04434826 12.271871  ]\n",
      " [ 1.0039084   0.52135587]\n",
      " [11.3828745   0.05346994]\n",
      " [ 0.21806967  1.6834203 ]\n",
      " [ 2.2182715   0.26053423]\n",
      " [ 0.4418532   0.96996254]\n",
      " [ 0.0779353   9.359855  ]\n",
      " [ 0.06793838  9.654056  ]\n",
      " [ 0.07833896  9.343712  ]\n",
      " [ 0.08500018  4.9080877 ]\n",
      " [ 0.07486469  9.420934  ]\n",
      " [ 0.0623068  11.276427  ]\n",
      " [22.311682    0.03267059]\n",
      " [23.132921    0.03412351]\n",
      " [21.821486    0.03484877]\n",
      " [24.285658    0.03315025]\n",
      " [23.220732    0.03164983]\n",
      " [24.121506    0.03290458]\n",
      " [25.21184     0.03277327]\n",
      " [ 8.530316    0.05912083]\n",
      " [23.212446    0.04085872]\n",
      " [23.136938    0.03343176]\n",
      " [24.495096    0.03560327]\n",
      " [20.575937    0.03625474]\n",
      " [24.618204    0.0325049 ]\n",
      " [20.966932    0.03411599]\n",
      " [11.030663    0.04849593]\n",
      " [ 0.03921085 17.46651   ]\n",
      " [ 0.03503606 19.228432  ]\n",
      " [ 0.04535433 14.61886   ]\n",
      " [ 0.03974149 16.642647  ]\n",
      " [ 0.04260576 14.59358   ]\n",
      " [ 0.04925937 12.564996  ]\n",
      " [ 0.07132579  9.370619  ]\n",
      " [ 0.0467864  13.8270235 ]\n",
      " [ 0.24034122  2.135366  ]\n",
      " [ 0.03844066 16.548605  ]\n",
      " [ 0.6140971   1.043239  ]\n",
      " [ 0.04905366 12.829214  ]\n",
      " [ 0.04697625 13.134029  ]\n",
      " [ 0.04288291 15.34437   ]\n",
      " [ 0.06759932  8.718816  ]\n",
      " [ 0.16593683  2.2543623 ]\n",
      " [22.98093     0.03393054]\n",
      " [25.263588    0.03748748]\n",
      " [23.634974    0.04179201]\n",
      " [ 0.09482133  7.5691466 ]\n",
      " [25.023127    0.03582793]\n",
      " [23.930513    0.03179485]\n",
      " [ 2.8701181   0.19447516]\n",
      " [25.274927    0.0316719 ]\n",
      " [22.379354    0.03333831]\n",
      " [17.16418     0.03908068]\n",
      " [ 6.9107966   0.08816149]\n",
      " [22.38358     0.03897769]\n",
      " [ 1.2248238   0.39529786]\n",
      " [24.36247     0.0355013 ]\n",
      " [ 7.7341475   0.07988745]\n",
      " [ 3.5048838   0.13898812]\n",
      " [19.481382    0.03871891]\n",
      " [ 6.832984    0.08154762]\n",
      " [ 6.306031    0.08655306]\n",
      " [14.798696    0.0449171 ]\n",
      " [15.701298    0.04387881]\n",
      " [ 9.988507    0.06170723]\n",
      " [ 0.04328316 13.734975  ]\n",
      " [ 0.04311327 11.696548  ]\n",
      " [ 0.07304118  6.498554  ]\n",
      " [ 1.5389565   0.36296946]\n",
      " [ 1.7943095   0.31852254]\n",
      " [26.199183    0.03416893]\n",
      " [26.266222    0.03286846]\n",
      " [20.460537    0.03744171]\n",
      " [ 6.1563425   0.09669294]\n",
      " [ 0.060513   11.137286  ]\n",
      " [ 0.06252465 10.704895  ]\n",
      " [ 0.05372462 12.060439  ]\n",
      " [ 0.04866204 12.132904  ]\n",
      " [ 0.07930822  8.668874  ]\n",
      " [ 0.06393033 10.79884   ]\n",
      " [ 0.08407702  8.181618  ]\n",
      " [ 0.06011406 10.932201  ]\n",
      " [ 0.05543284 12.751735  ]\n",
      " [ 0.04357926 15.30638   ]\n",
      " [ 0.05164554 13.29727   ]\n",
      " [21.988485    0.04547828]\n",
      " [17.597013    0.04128889]\n",
      " [23.700602    0.03771153]\n",
      " [ 8.972393    0.06926452]\n",
      " [ 3.7644014   0.1544438 ]\n",
      " [20.696028    0.03713938]\n",
      " [17.719408    0.03716074]\n",
      " [17.225784    0.04149214]\n",
      " [20.88412     0.03625974]\n",
      " [20.708437    0.04963432]\n",
      " [22.848383    0.04012817]\n",
      " [ 5.7243633   0.09659196]\n",
      " [ 0.14833769  3.6352339 ]\n",
      " [16.364702    0.04503378]\n",
      " [15.0076275   0.04626898]\n",
      " [ 3.190139    0.20432058]\n",
      " [20.884737    0.04815222]\n",
      " [ 0.06547858 11.346513  ]\n",
      " [ 0.06651393 11.347662  ]\n",
      " [ 0.09375313  7.9192696 ]\n",
      " [21.39305     0.04035828]\n",
      " [ 0.10848845  3.9322724 ]\n",
      " [24.264135    0.03722467]\n",
      " [20.60127     0.03507142]\n",
      " [19.097948    0.05033585]\n",
      " [26.0463      0.03118644]\n",
      " [26.182592    0.03352341]\n",
      " [26.531792    0.03279236]\n",
      " [25.49473     0.03022853]\n",
      " [21.359201    0.03290736]\n",
      " [18.333029    0.03731298]\n",
      " [23.361437    0.03340712]\n",
      " [25.602745    0.03211183]\n",
      " [ 0.08486378  6.453919  ]\n",
      " [ 0.03982453 15.713095  ]\n",
      " [ 0.05683638 10.67308   ]\n",
      " [ 0.04778486 14.293496  ]\n",
      " [ 0.03863346 15.918076  ]\n",
      " [ 0.04219415 14.9404745 ]\n",
      " [ 0.06158104  9.458018  ]\n",
      " [ 0.05013489 12.000226  ]\n",
      " [ 0.07379937  7.798886  ]\n",
      " [ 0.07110688  8.037977  ]\n",
      " [ 0.03976415 16.525194  ]\n",
      " [ 0.03982498 15.699629  ]\n",
      " [ 0.04148938 15.70366   ]\n",
      " [ 0.04308574 14.635742  ]\n",
      " [ 0.04132758 14.521269  ]\n",
      " [ 0.1020445   6.8314447 ]\n",
      " [21.820663    0.03665852]\n",
      " [10.782136    0.05752236]\n",
      " [19.283306    0.03966097]\n",
      " [ 5.7775764   0.0910699 ]\n",
      " [18.39492     0.04093317]\n",
      " [19.744846    0.04042823]\n",
      " [20.542727    0.03661744]\n",
      " [19.315369    0.03827825]\n",
      " [15.699296    0.04398656]\n",
      " [20.315763    0.03783352]\n",
      " [14.852717    0.04920092]\n",
      " [19.210903    0.03928259]\n",
      " [ 2.7012296   0.20080164]\n",
      " [13.002078    0.05223257]\n",
      " [ 0.60863435  0.72264457]\n",
      " [17.5386      0.03854776]\n",
      " [ 0.12690769  3.805528  ]\n",
      " [23.985905    0.03340153]\n",
      " [ 2.116738    0.27762654]\n",
      " [23.96122     0.0402889 ]\n",
      " [21.672058    0.03302405]\n",
      " [21.92624     0.04629659]\n",
      " [19.0109      0.03625312]]\n",
      "[[0.03879223 0.9612078 ]\n",
      " [0.9125374  0.08746254]\n",
      " [0.6959884  0.30401158]\n",
      " [0.9620328  0.03796722]\n",
      " [0.98708916 0.01291081]\n",
      " [0.00232805 0.9976719 ]\n",
      " [0.6580501  0.34194985]\n",
      " [0.905957   0.09404302]\n",
      " [0.95977604 0.04022397]\n",
      " [0.92488664 0.07511336]\n",
      " [0.74714506 0.2528549 ]\n",
      " [0.01269579 0.9873042 ]\n",
      " [0.00691304 0.99308693]\n",
      " [0.00437495 0.995625  ]\n",
      " [0.0054865  0.99451345]\n",
      " [0.00586764 0.9941324 ]\n",
      " [0.0060495  0.99395055]\n",
      " [0.00845708 0.99154294]\n",
      " [0.00239891 0.9976011 ]\n",
      " [0.0025067  0.9974933 ]\n",
      " [0.00258994 0.99741006]\n",
      " [0.00218156 0.99781847]\n",
      " [0.00231191 0.99768806]\n",
      " [0.00256033 0.9974397 ]\n",
      " [0.0020371  0.99796283]\n",
      " [0.00235483 0.99764514]\n",
      " [0.00322455 0.99677545]\n",
      " [0.00280726 0.99719274]\n",
      " [0.00236132 0.99763864]\n",
      " [0.00227051 0.9977295 ]\n",
      " [0.00313559 0.99686444]\n",
      " [0.00218985 0.9978101 ]\n",
      " [0.00461483 0.99538517]\n",
      " [0.00732904 0.99267095]\n",
      " [0.0367705  0.9632295 ]\n",
      " [0.02889662 0.97110337]\n",
      " [0.03042375 0.9695763 ]\n",
      " [0.3871708  0.61282927]\n",
      " [0.06018376 0.93981624]\n",
      " [0.13021684 0.86978316]\n",
      " [0.540683   0.45931706]\n",
      " [0.01796739 0.9820326 ]\n",
      " [0.00532923 0.99467075]\n",
      " [0.00999574 0.99000424]\n",
      " [0.01973481 0.98026514]\n",
      " [0.28808677 0.7119132 ]\n",
      " [0.00810318 0.99189687]\n",
      " [0.00186799 0.99813205]\n",
      " [0.00161396 0.998386  ]\n",
      " [0.00188029 0.9981198 ]\n",
      " [0.00176052 0.99823946]\n",
      " [0.00204608 0.99795395]\n",
      " [0.00155614 0.9984439 ]\n",
      " [0.00148635 0.9985137 ]\n",
      " [0.00198425 0.9980157 ]\n",
      " [0.00160156 0.9983984 ]\n",
      " [0.00136059 0.99863946]\n",
      " [0.00211902 0.997881  ]\n",
      " [0.00206122 0.9979388 ]\n",
      " [0.00145247 0.99854755]\n",
      " [0.00254952 0.9974504 ]\n",
      " [0.00169273 0.9983073 ]\n",
      " [0.00182972 0.9981703 ]\n",
      " [0.00271248 0.99728745]\n",
      " [0.00174466 0.9982553 ]\n",
      " [0.0023178  0.9976822 ]\n",
      " [0.00308628 0.9969137 ]\n",
      " [0.00288456 0.99711543]\n",
      " [0.0031156  0.9968844 ]\n",
      " [0.00237416 0.9976258 ]\n",
      " [0.00187638 0.99812365]\n",
      " [0.00248339 0.99751663]\n",
      " [0.00222707 0.99777293]\n",
      " [0.00260534 0.9973947 ]\n",
      " [0.00279723 0.99720275]\n",
      " [0.00263277 0.9973672 ]\n",
      " [0.00263384 0.9973662 ]\n",
      " [0.00287991 0.9971201 ]\n",
      " [0.00302569 0.99697435]\n",
      " [0.98614615 0.01385382]\n",
      " [0.01899052 0.9810095 ]\n",
      " [0.00373625 0.99626374]\n",
      " [0.00427525 0.99572474]\n",
      " [0.00377142 0.9962286 ]\n",
      " [0.99867237 0.00132765]\n",
      " [0.99830127 0.00169879]\n",
      " [0.99852276 0.00147724]\n",
      " [0.99850893 0.00149109]\n",
      " [0.9954906  0.00450939]\n",
      " [0.9984072  0.00159279]\n",
      " [0.9977554  0.00224454]\n",
      " [0.9972163  0.00278373]\n",
      " [0.9986664  0.00133363]\n",
      " [0.9985195  0.00148051]\n",
      " [0.9971376  0.0028624 ]\n",
      " [0.998328   0.00167203]\n",
      " [0.9986429  0.0013571 ]\n",
      " [0.9986395  0.00136045]\n",
      " [0.15505098 0.84494907]\n",
      " [0.9987245  0.00127546]\n",
      " [0.99878365 0.00121633]\n",
      " [0.00275292 0.99724704]\n",
      " [0.9665311  0.03346889]\n",
      " [0.9974086  0.00259136]\n",
      " [0.8729107  0.12708929]\n",
      " [0.9984563  0.00154371]\n",
      " [0.9967787  0.00322125]\n",
      " [0.00264549 0.9973545 ]\n",
      " [0.00687477 0.9931252 ]\n",
      " [0.00322637 0.99677366]\n",
      " [0.00449173 0.99550825]\n",
      " [0.02458415 0.9754158 ]\n",
      " [0.00324474 0.99675524]\n",
      " [0.0059187  0.99408126]\n",
      " [0.00933567 0.9906643 ]\n",
      " [0.00324019 0.99675983]\n",
      " [0.00358454 0.9964155 ]\n",
      " [0.00358232 0.9964177 ]\n",
      " [0.00407929 0.9959207 ]\n",
      " [0.33651152 0.66348845]\n",
      " [0.00309905 0.9969009 ]\n",
      " [0.00306557 0.9969344 ]\n",
      " [0.00491114 0.9950888 ]\n",
      " [0.00744803 0.992552  ]\n",
      " [0.00398016 0.9960198 ]\n",
      " [0.00327324 0.99672675]\n",
      " [0.0136957  0.9863043 ]\n",
      " [0.00519164 0.9948084 ]\n",
      " [0.9984396  0.00156042]\n",
      " [0.99859536 0.00140471]\n",
      " [0.9984796  0.00152037]\n",
      " [0.99833363 0.00166633]\n",
      " [0.99729174 0.00270827]\n",
      " [0.9985536  0.00144642]\n",
      " [0.9981463  0.00185376]\n",
      " [0.99805915 0.00194079]\n",
      " [0.99813646 0.00186353]\n",
      " [0.99859416 0.00140586]\n",
      " [0.9981945  0.00180552]\n",
      " [0.99855465 0.00144538]\n",
      " [0.9696869  0.030313  ]\n",
      " [0.00523047 0.9947696 ]\n",
      " [0.0040097  0.9959903 ]\n",
      " [0.04589358 0.9541064 ]\n",
      " [0.00703058 0.99296945]\n",
      " [0.0090424  0.9909576 ]\n",
      " [0.00840646 0.99159354]\n",
      " [0.9982063  0.00179369]\n",
      " [0.00928716 0.9907129 ]\n",
      " [0.99803776 0.00196222]\n",
      " [0.9985232  0.00147686]\n",
      " [0.00500606 0.9949939 ]\n",
      " [0.9648133  0.03518665]\n",
      " [0.9979841  0.00201596]\n",
      " [0.99554616 0.00445383]\n",
      " [0.9985315  0.00146846]\n",
      " [0.9963814  0.0036186 ]\n",
      " [0.9979724  0.00202758]\n",
      " [0.997956   0.00204399]\n",
      " [0.99142075 0.00857927]\n",
      " [0.9972275  0.00277248]\n",
      " [0.9968632  0.00313683]\n",
      " [0.99851197 0.00148806]\n",
      " [0.9953394  0.00466062]\n",
      " [0.00265628 0.9973437 ]\n",
      " [0.00213662 0.99786335]\n",
      " [0.00231952 0.9976805 ]\n",
      " [0.00598561 0.9940143 ]\n",
      " [0.28633687 0.71366316]\n",
      " [0.7481463  0.2518537 ]\n",
      " [0.8506899  0.1493101 ]\n",
      " [0.99622995 0.00377006]\n",
      " [0.6682301  0.3317699 ]\n",
      " [0.9924465  0.00755349]\n",
      " [0.02143402 0.978566  ]\n",
      " [0.03147181 0.9685282 ]\n",
      " [0.07119879 0.9288012 ]\n",
      " [0.9958452  0.00415484]\n",
      " [0.00405384 0.99594617]\n",
      " [0.017926   0.98207396]\n",
      " [0.01507809 0.98492193]\n",
      " [0.03152759 0.9684724 ]\n",
      " [0.00521785 0.99478215]\n",
      " [0.00526694 0.99473304]\n",
      " [0.0049083  0.9950917 ]\n",
      " [0.9981069  0.00189306]\n",
      " [0.9984136  0.00158635]\n",
      " [0.99851793 0.00148212]\n",
      " [0.9981304  0.0018696 ]\n",
      " [0.9986009  0.00139911]\n",
      " [0.9985879  0.00141215]\n",
      " [0.99803066 0.00196932]\n",
      " [0.99850523 0.00149479]\n",
      " [0.9983074  0.00169256]\n",
      " [0.00509754 0.99490243]\n",
      " [0.00648873 0.99351126]\n",
      " [0.02682938 0.9731706 ]\n",
      " [0.00307665 0.9969234 ]\n",
      " [0.00311474 0.99688524]\n",
      " [0.00601943 0.9939806 ]\n",
      " [0.00800374 0.9919963 ]\n",
      " [0.01235812 0.98764193]\n",
      " [0.00350184 0.99649817]\n",
      " [0.9971322  0.00286781]\n",
      " [0.99836034 0.00163965]\n",
      " [0.99883276 0.00116725]\n",
      " [0.9987147  0.00128526]\n",
      " [0.04934245 0.95065755]\n",
      " [0.99866885 0.00133117]\n",
      " [0.9987802  0.00121979]\n",
      " [0.9984745  0.00152553]\n",
      " [0.9987839  0.00121612]\n",
      " [0.0221027  0.97789735]\n",
      " [0.01294863 0.98705137]\n",
      " [0.0241247  0.9758753 ]\n",
      " [0.00296968 0.9970303 ]\n",
      " [0.00226841 0.9977316 ]\n",
      " [0.00419235 0.99580765]\n",
      " [0.00363881 0.9963612 ]\n",
      " [0.00336528 0.9966348 ]\n",
      " [0.0049559  0.9950441 ]\n",
      " [0.00499695 0.9950031 ]\n",
      " [0.00216783 0.9978322 ]\n",
      " [0.00191882 0.9980812 ]\n",
      " [0.00257785 0.99742216]\n",
      " [0.00235029 0.9976497 ]\n",
      " [0.0023371  0.9976629 ]\n",
      " [0.00183178 0.9981682 ]\n",
      " [0.00360448 0.9963955 ]\n",
      " [0.00289678 0.9971032 ]\n",
      " [0.13572666 0.8642733 ]\n",
      " [0.03646914 0.9635309 ]\n",
      " [0.0047714  0.9952286 ]\n",
      " [0.02285815 0.9771418 ]\n",
      " [0.01442591 0.98557407]\n",
      " [0.01037697 0.98962307]\n",
      " [0.00663412 0.9933659 ]\n",
      " [0.0594304  0.9405696 ]\n",
      " [0.00532111 0.9946789 ]\n",
      " [0.01593943 0.9840606 ]\n",
      " [0.00943962 0.9905604 ]\n",
      " [0.00946579 0.99053425]\n",
      " [0.00844861 0.99155134]\n",
      " [0.0033509  0.9966491 ]\n",
      " [0.85958993 0.14041008]\n",
      " [0.00205445 0.99794555]\n",
      " [0.00191715 0.9980828 ]\n",
      " [0.00234812 0.9976519 ]\n",
      " [0.00303704 0.99696296]\n",
      " [0.00310939 0.9968906 ]\n",
      " [0.00263489 0.9973651 ]\n",
      " [0.00272684 0.99727315]\n",
      " [0.00200346 0.99799657]\n",
      " [0.00213453 0.99786544]\n",
      " [0.00237688 0.99762315]\n",
      " [0.00256176 0.9974382 ]\n",
      " [0.00261159 0.9973884 ]\n",
      " [0.00256824 0.9974317 ]\n",
      " [0.00185048 0.9981495 ]\n",
      " [0.00146404 0.99853593]\n",
      " [0.0019274  0.9980726 ]\n",
      " [0.00193127 0.99806875]\n",
      " [0.00213551 0.99786454]\n",
      " [0.00181809 0.9981819 ]\n",
      " [0.00183579 0.99816424]\n",
      " [0.00160732 0.9983927 ]\n",
      " [0.00262784 0.99737215]\n",
      " [0.00308058 0.9969194 ]\n",
      " [0.00200315 0.9979968 ]\n",
      " [0.00193849 0.99806154]\n",
      " [0.0030604  0.9969396 ]\n",
      " [0.00228379 0.9977162 ]\n",
      " [0.00193957 0.9980604 ]\n",
      " [0.00155798 0.99844205]\n",
      " [0.00190809 0.9980919 ]\n",
      " [0.00242693 0.997573  ]\n",
      " [0.9538644  0.04613562]\n",
      " [0.99742234 0.00257767]\n",
      " [0.97918046 0.02081952]\n",
      " [0.59283435 0.40716562]\n",
      " [0.2860888  0.7139112 ]\n",
      " [0.9289401  0.0710599 ]\n",
      " [0.75256485 0.24743517]\n",
      " [0.9894426  0.01055739]\n",
      " [0.9984104  0.00158959]\n",
      " [0.9961259  0.00387418]\n",
      " [0.99808437 0.00191564]\n",
      " [0.9792197  0.02078031]\n",
      " [0.3575895  0.6424105 ]\n",
      " [0.9952058  0.00479422]\n",
      " [0.99849194 0.00150809]\n",
      " [0.00395551 0.9960445 ]\n",
      " [0.9923162  0.00768381]\n",
      " [0.9985063  0.00149367]\n",
      " [0.9714688  0.0285312 ]\n",
      " [0.9975425  0.00245753]\n",
      " [0.9979805  0.00201953]\n",
      " [0.7876682  0.21233177]\n",
      " [0.9960619  0.00393811]\n",
      " [0.9982725  0.00172755]\n",
      " [0.2590771  0.74092287]\n",
      " [0.03805244 0.96194756]\n",
      " [0.00308222 0.9969178 ]\n",
      " [0.0092386  0.9907614 ]\n",
      " [0.01945769 0.98054236]\n",
      " [0.01536935 0.9846307 ]\n",
      " [0.01110139 0.9888986 ]\n",
      " [0.03386963 0.9661303 ]\n",
      " [0.9984372  0.00156278]\n",
      " [0.0036008  0.99639916]\n",
      " [0.65818655 0.34181347]\n",
      " [0.9953246  0.00467544]\n",
      " [0.11468358 0.88531643]\n",
      " [0.89489526 0.10510474]\n",
      " [0.31296802 0.6870319 ]\n",
      " [0.00825779 0.9917422 ]\n",
      " [0.00698811 0.99301183]\n",
      " [0.00831443 0.9916856 ]\n",
      " [0.01702357 0.98297644]\n",
      " [0.00788398 0.99211603]\n",
      " [0.00549504 0.994505  ]\n",
      " [0.99853784 0.00146214]\n",
      " [0.99852705 0.00147293]\n",
      " [0.9984055  0.00159445]\n",
      " [0.99863684 0.00136315]\n",
      " [0.9986388  0.00136114]\n",
      " [0.9986378  0.00136226]\n",
      " [0.99870175 0.00129823]\n",
      " [0.993117   0.00688297]\n",
      " [0.99824286 0.00175711]\n",
      " [0.99855715 0.00144287]\n",
      " [0.9985486  0.00145138]\n",
      " [0.99824107 0.0017589 ]\n",
      " [0.99868137 0.00131862]\n",
      " [0.9983755  0.00162449]\n",
      " [0.99562275 0.00437722]\n",
      " [0.00223989 0.9977601 ]\n",
      " [0.00181878 0.9981812 ]\n",
      " [0.00309286 0.9969072 ]\n",
      " [0.00238224 0.9976178 ]\n",
      " [0.00291099 0.997089  ]\n",
      " [0.00390506 0.99609494]\n",
      " [0.00755414 0.9924458 ]\n",
      " [0.00337228 0.99662775]\n",
      " [0.10116618 0.8988338 ]\n",
      " [0.00231751 0.9976825 ]\n",
      " [0.37053263 0.62946737]\n",
      " [0.00380903 0.996191  ]\n",
      " [0.00356394 0.99643606]\n",
      " [0.00278691 0.99721307]\n",
      " [0.00769362 0.9923064 ]\n",
      " [0.06856047 0.9314396 ]\n",
      " [0.99852574 0.00147429]\n",
      " [0.99851835 0.00148166]\n",
      " [0.99823487 0.00176511]\n",
      " [0.01237235 0.9876276 ]\n",
      " [0.99857026 0.00142975]\n",
      " [0.9986731  0.00132687]\n",
      " [0.93654126 0.06345872]\n",
      " [0.9987485  0.00125153]\n",
      " [0.9985125  0.00148747]\n",
      " [0.9977282  0.0022717 ]\n",
      " [0.98740363 0.01259637]\n",
      " [0.99826163 0.00173832]\n",
      " [0.7560073  0.24399269]\n",
      " [0.9985449  0.00145509]\n",
      " [0.98977643 0.01022359]\n",
      " [0.961857   0.03814298]\n",
      " [0.9980164  0.00198354]\n",
      " [0.9882063  0.01179366]\n",
      " [0.9864604  0.0135396 ]\n",
      " [0.996974   0.00302602]\n",
      " [0.9972132  0.00278681]\n",
      " [0.99386007 0.00613989]\n",
      " [0.00314141 0.9968586 ]\n",
      " [0.00367245 0.9963275 ]\n",
      " [0.01111468 0.98888534]\n",
      " [0.8091569  0.1908431 ]\n",
      " [0.84924376 0.15075621]\n",
      " [0.9986975  0.0013025 ]\n",
      " [0.99875015 0.00124979]\n",
      " [0.9981734  0.00182661]\n",
      " [0.98453665 0.01546336]\n",
      " [0.00540401 0.994596  ]\n",
      " [0.00580684 0.99419314]\n",
      " [0.00443486 0.9955652 ]\n",
      " [0.00399473 0.99600524]\n",
      " [0.00906568 0.9909343 ]\n",
      " [0.00588527 0.9941147 ]\n",
      " [0.0101718  0.9898282 ]\n",
      " [0.00546874 0.9945313 ]\n",
      " [0.00432827 0.9956717 ]\n",
      " [0.00283905 0.997161  ]\n",
      " [0.00386889 0.9961311 ]\n",
      " [0.99793595 0.00206401]\n",
      " [0.99765915 0.00234087]\n",
      " [0.99841136 0.00158864]\n",
      " [0.99233943 0.0076606 ]\n",
      " [0.96058947 0.03941054]\n",
      " [0.9982087  0.0017913 ]\n",
      " [0.9979072  0.00209279]\n",
      " [0.99759704 0.00240293]\n",
      " [0.99826676 0.00173323]\n",
      " [0.9976089  0.00239109]\n",
      " [0.9982468  0.0017532 ]\n",
      " [0.9834062  0.01659383]\n",
      " [0.03920573 0.96079427]\n",
      " [0.9972556  0.00274433]\n",
      " [0.9969264  0.00307356]\n",
      " [0.9398076  0.06019237]\n",
      " [0.9976997  0.00230031]\n",
      " [0.0057377  0.99426234]\n",
      " [0.00582731 0.9941727 ]\n",
      " [0.0117001  0.98829997]\n",
      " [0.9981171  0.00188296]\n",
      " [0.02684852 0.97315145]\n",
      " [0.9984682  0.00153179]\n",
      " [0.99830043 0.0016995 ]\n",
      " [0.9973713  0.00262874]\n",
      " [0.99880403 0.00119591]\n",
      " [0.99872124 0.00127873]\n",
      " [0.9987655  0.00123444]\n",
      " [0.9988158  0.00118427]\n",
      " [0.9984617  0.00153829]\n",
      " [0.9979688  0.00203115]\n",
      " [0.99857205 0.00142797]\n",
      " [0.99874735 0.00125266]\n",
      " [0.01297853 0.9870215 ]\n",
      " [0.00252807 0.9974719 ]\n",
      " [0.005297   0.994703  ]\n",
      " [0.00333198 0.99666804]\n",
      " [0.00242114 0.99757886]\n",
      " [0.0028162  0.9971838 ]\n",
      " [0.00646887 0.99353117]\n",
      " [0.00416045 0.9958396 ]\n",
      " [0.0093741  0.99062586]\n",
      " [0.00876879 0.9912312 ]\n",
      " [0.0024005  0.9975995 ]\n",
      " [0.00253026 0.9974697 ]\n",
      " [0.00263506 0.99736494]\n",
      " [0.00293523 0.99706477]\n",
      " [0.00283793 0.9971621 ]\n",
      " [0.01471763 0.98528236]\n",
      " [0.9983228  0.00167717]\n",
      " [0.9946933  0.00530666]\n",
      " [0.99794745 0.00205253]\n",
      " [0.984482   0.01551804]\n",
      " [0.99777967 0.0022203 ]\n",
      " [0.99795663 0.00204335]\n",
      " [0.9982207  0.00177933]\n",
      " [0.99802214 0.00197783]\n",
      " [0.99720603 0.00279399]\n",
      " [0.99814117 0.00185881]\n",
      " [0.9966983  0.00330165]\n",
      " [0.9979594  0.00204063]\n",
      " [0.9308065  0.06919348]\n",
      " [0.9959988  0.00400117]\n",
      " [0.4571802  0.5428198 ]\n",
      " [0.99780697 0.00219306]\n",
      " [0.03227203 0.967728  ]\n",
      " [0.99860936 0.00139061]\n",
      " [0.88405    0.11594999]\n",
      " [0.9983214  0.0016786 ]\n",
      " [0.99847853 0.00152149]\n",
      " [0.997893   0.00210702]\n",
      " [0.99809664 0.00190334]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 21:40:11 - INFO - __main__ -   ***** Test results None *****\r\n",
      "\r",
      "100%|███████████████████████████████████████████| 59/59 [00:01<00:00, 42.20it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/ZeroShot/1' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/1/eval-dev/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train_en_2.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev_en_2.csv \\\n",
    "      --test_file Data/ZeroShot/dev_en_2.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 21:40:21 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 21:40:21 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/2/eval-dev/runs/Dec20_21-40-21_r18g08.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/2/eval-dev/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/2/eval-dev/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 21:40:21 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_ot_2.csv\n",
      "12/20/2021 21:40:21 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev_ot_2.csv\n",
      "12/20/2021 21:40:21 - INFO - __main__ -   load a local file for test: Data/ZeroShot/dev_ot_2.csv\n",
      "12/20/2021 21:40:22 - WARNING - datasets.builder -   Using custom data configuration default-1e40555dd0f639e5\n",
      "12/20/2021 21:40:22 - WARNING - datasets.builder -   Reusing dataset csv (/users/sitkonen/.cache/huggingface/datasets/csv/default-1e40555dd0f639e5/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  8.40it/s]\n",
      "[INFO|configuration_utils.py:586] 2021-12-20 21:40:23,124 >> loading configuration file models/ZeroShot/2/config.json\n",
      "[INFO|configuration_utils.py:625] 2021-12-20 21:40:23,124 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 21:40:23,182 >> Didn't find file models/ZeroShot/2/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:23,187 >> loading file models/ZeroShot/2/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:23,187 >> loading file models/ZeroShot/2/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:23,187 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:23,187 >> loading file models/ZeroShot/2/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:23,187 >> loading file models/ZeroShot/2/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1338] 2021-12-20 21:40:23,377 >> loading weights file models/ZeroShot/2/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1607] 2021-12-20 21:40:27,573 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[INFO|modeling_utils.py:1616] 2021-12-20 21:40:27,574 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/ZeroShot/2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "12/20/2021 21:40:27 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-1e40555dd0f639e5/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-6a49b417ae7900d0.arrow\n",
      "12/20/2021 21:40:27 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-1e40555dd0f639e5/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-ec00aa53e4c165fb.arrow\n",
      "12/20/2021 21:40:28 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-1e40555dd0f639e5/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-44702576a2e81ff2.arrow\n",
      "12/20/2021 21:40:31 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2021-12-20 21:40:31,787 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, sentence2.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:40:31,789 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:40:31,789 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:40:31,789 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 43.71it/s]\n",
      "***** eval metrics *****\n",
      "  eval_accuracy           =      0.652\n",
      "  eval_f1                 =     0.5902\n",
      "  eval_loss               =     2.1115\n",
      "  eval_runtime            = 0:00:00.84\n",
      "  eval_samples            =        273\n",
      "  eval_samples_per_second =    324.522\n",
      "  eval_steps_per_second   =     41.605\n",
      "12/20/2021 21:40:32 - INFO - __main__ -   *** Test ***\n",
      "AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
      "  test_dataset.remove_columns_(\"label\")\n",
      "[INFO|trainer.py:541] 2021-12-20 21:40:32,756 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, sentence2.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:40:32,758 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:40:32,758 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:40:32,758 >>   Batch size = 8\n",
      " 91%|███████████████████████████████████████▎   | 32/35 [00:00<00:00, 45.21it/s][[23.047861    0.04174396]\n",
      " [21.661592    0.04321232]\n",
      " [23.283432    0.04290352]\n",
      " [25.580542    0.03644932]\n",
      " [27.283785    0.0341323 ]\n",
      " [24.871223    0.03827404]\n",
      " [23.069275    0.04013826]\n",
      " [22.902298    0.04063718]\n",
      " [23.378048    0.03972832]\n",
      " [21.318222    0.04315143]\n",
      " [20.9106      0.04473542]\n",
      " [23.599028    0.03919033]\n",
      " [20.83234     0.04367389]\n",
      " [24.38169     0.03879686]\n",
      " [19.82407     0.04558637]\n",
      " [23.950516    0.03741737]\n",
      " [19.916515    0.04685044]\n",
      " [16.18047     0.0580892 ]\n",
      " [ 0.11888608  7.3799257 ]\n",
      " [17.284248    0.05659631]\n",
      " [16.934126    0.05145643]\n",
      " [10.462829    0.10068922]\n",
      " [ 0.3773628   2.7126982 ]\n",
      " [19.17446     0.04986848]\n",
      " [20.461       0.04459984]\n",
      " [20.15349     0.04209136]\n",
      " [17.580965    0.05353843]\n",
      " [21.693892    0.04077082]\n",
      " [ 0.12275721  7.0769467 ]\n",
      " [28.634058    0.03519754]\n",
      " [28.573092    0.03568984]\n",
      " [29.675165    0.03407639]\n",
      " [28.78439     0.03520473]\n",
      " [27.038113    0.03509985]\n",
      " [27.131884    0.03670733]\n",
      " [29.114798    0.03286649]\n",
      " [27.51641     0.03652489]\n",
      " [24.115685    0.04120233]\n",
      " [27.621513    0.03483532]\n",
      " [27.167309    0.03484303]\n",
      " [25.926193    0.03770955]\n",
      " [25.800713    0.03644553]\n",
      " [28.357779    0.03483132]\n",
      " [29.068466    0.03295958]\n",
      " [28.162136    0.03458505]\n",
      " [27.696795    0.03470009]\n",
      " [27.427786    0.03639715]\n",
      " [27.806604    0.03662313]\n",
      " [26.05352     0.03541299]\n",
      " [26.82215     0.03733023]\n",
      " [28.221472    0.03585989]\n",
      " [27.923409    0.03686247]\n",
      " [28.242947    0.0355474 ]\n",
      " [29.767311    0.03415611]\n",
      " [27.449263    0.03629279]\n",
      " [ 1.8821541   0.74760246]\n",
      " [27.765081    0.03703777]\n",
      " [29.609636    0.03468366]\n",
      " [27.207386    0.03612947]\n",
      " [28.930813    0.03764053]\n",
      " [27.87599     0.03751399]\n",
      " [27.712337    0.03997513]\n",
      " [29.802423    0.03722425]\n",
      " [27.243277    0.03595626]\n",
      " [26.093657    0.03868698]\n",
      " [25.602459    0.03759823]\n",
      " [26.829855    0.03699604]\n",
      " [26.66206     0.03749764]\n",
      " [26.355759    0.03679363]\n",
      " [25.110699    0.03729409]\n",
      " [21.546633    0.0457452 ]\n",
      " [24.515686    0.03768737]\n",
      " [22.189774    0.04447151]\n",
      " [24.813368    0.03856834]\n",
      " [23.220959    0.04364032]\n",
      " [23.317074    0.04023032]\n",
      " [24.652071    0.03868078]\n",
      " [24.426136    0.03889491]\n",
      " [25.712116    0.03778309]\n",
      " [25.522024    0.03894811]\n",
      " [ 0.9665799   1.5230026 ]\n",
      " [28.053833    0.0362014 ]\n",
      " [24.361403    0.03993283]\n",
      " [27.429976    0.0350688 ]\n",
      " [29.070976    0.03668303]\n",
      " [28.17096     0.03471579]\n",
      " [27.502153    0.03575234]\n",
      " [26.62762     0.03632859]\n",
      " [26.806118    0.0365031 ]\n",
      " [24.862629    0.03977946]\n",
      " [24.587526    0.03929255]\n",
      " [26.445126    0.03591092]\n",
      " [28.302687    0.03479278]\n",
      " [26.53474     0.03712434]\n",
      " [29.2199      0.03508492]\n",
      " [27.58647     0.03667492]\n",
      " [25.002201    0.04107265]\n",
      " [ 0.11162455  8.40742   ]\n",
      " [11.679687    0.14021747]\n",
      " [19.38424     0.05781038]\n",
      " [ 1.4354922   1.1045011 ]\n",
      " [21.64258     0.05918696]\n",
      " [25.37226     0.0408686 ]\n",
      " [24.769657    0.04501426]\n",
      " [22.964674    0.04824491]\n",
      " [26.111263    0.04619162]\n",
      " [24.845821    0.03973633]\n",
      " [21.814516    0.04569745]\n",
      " [23.831991    0.04462298]\n",
      " [26.862665    0.03500132]\n",
      " [25.374115    0.04488937]\n",
      " [24.028276    0.04259662]\n",
      " [ 0.13052009  6.8871403 ]\n",
      " [18.68547     0.06134391]\n",
      " [16.18479     0.0749493 ]\n",
      " [24.670473    0.04064539]\n",
      " [ 0.13171753  6.743726  ]\n",
      " [30.081337    0.03509346]\n",
      " [28.619234    0.03451372]\n",
      " [29.756754    0.03663883]\n",
      " [27.32629     0.03725268]\n",
      " [28.21062     0.03474941]\n",
      " [29.031487    0.03418571]\n",
      " [29.37005     0.03515304]\n",
      " [27.484783    0.03567173]\n",
      " [27.229515    0.03707867]\n",
      " [29.705156    0.03482936]\n",
      " [28.847288    0.03483347]\n",
      " [ 0.11742309  7.58525   ]\n",
      " [28.07716     0.03573965]\n",
      " [25.595528    0.03639957]\n",
      " [26.789547    0.03659461]\n",
      " [27.609497    0.03681607]\n",
      " [27.981344    0.03450026]\n",
      " [30.18076     0.03589029]\n",
      " [26.443386    0.0368259 ]\n",
      " [29.139862    0.03530692]\n",
      " [27.41066     0.03653196]\n",
      " [26.051437    0.036343  ]\n",
      " [26.713917    0.0360177 ]\n",
      " [25.578337    0.03737102]\n",
      " [26.573067    0.0358121 ]\n",
      " [25.051397    0.03803115]\n",
      " [25.069088    0.03775449]\n",
      " [26.523329    0.0374002 ]\n",
      " [25.888126    0.03754651]\n",
      " [23.398947    0.04237713]\n",
      " [27.694565    0.03515583]\n",
      " [25.12857     0.04017955]\n",
      " [26.265226    0.03611116]\n",
      " [25.711765    0.03841518]\n",
      " [27.748243    0.03660108]\n",
      " [28.481352    0.03546976]\n",
      " [24.901407    0.04027545]\n",
      " [27.803493    0.03465704]\n",
      " [27.277304    0.03757032]\n",
      " [26.885757    0.03792448]\n",
      " [24.854431    0.04027747]\n",
      " [25.358257    0.03891602]\n",
      " [ 0.19228733  5.105415  ]\n",
      " [28.672709    0.03402616]\n",
      " [29.70369     0.03441023]\n",
      " [22.441813    0.0477616 ]\n",
      " [27.69945     0.03624742]\n",
      " [24.788233    0.04080399]\n",
      " [28.036602    0.03565434]\n",
      " [25.640825    0.03957303]\n",
      " [28.709396    0.03465592]\n",
      " [27.730091    0.03709628]\n",
      " [24.649004    0.0434123 ]\n",
      " [23.629541    0.0437445 ]\n",
      " [26.566898    0.03811361]\n",
      " [28.53965     0.0368022 ]\n",
      " [24.481382    0.05002052]\n",
      " [26.291906    0.03931156]\n",
      " [28.545113    0.03825146]\n",
      " [ 0.11468279  8.513715  ]\n",
      " [ 0.23890457  5.1612306 ]\n",
      " [ 0.10010476  9.347174  ]\n",
      " [ 0.10097874  9.097792  ]\n",
      " [ 0.1005661   9.106777  ]\n",
      " [ 0.10065379  8.970077  ]\n",
      " [ 0.11936738  7.735379  ]\n",
      " [ 0.10253086  8.843958  ]\n",
      " [ 0.12300585  7.1507125 ]\n",
      " [ 0.12517233  7.0236297 ]\n",
      " [ 0.12764332  6.925364  ]\n",
      " [ 0.11989562  7.1809363 ]\n",
      " [14.613825    0.081619  ]\n",
      " [ 0.13007268  6.8056817 ]\n",
      " [ 0.19694038  5.007875  ]\n",
      " [ 0.12843083  6.9270797 ]\n",
      " [ 0.13018075  6.79593   ]\n",
      " [ 0.12983981  6.8466425 ]\n",
      " [ 0.1406934   6.235034  ]\n",
      " [ 6.665075    0.20391147]\n",
      " [16.620216    0.07789534]\n",
      " [ 0.30561817  3.4128456 ]\n",
      " [ 0.13357528  6.68138   ]\n",
      " [26.112202    0.03845141]\n",
      " [25.383331    0.03882254]\n",
      " [27.276134    0.03804437]\n",
      " [27.862947    0.03546518]\n",
      " [29.348003    0.03495404]\n",
      " [27.82983     0.03727552]\n",
      " [27.834064    0.03610401]\n",
      " [26.292315    0.0373061 ]\n",
      " [26.497007    0.03742277]\n",
      " [26.726984    0.03686961]\n",
      " [30.540052    0.03524606]\n",
      " [26.133055    0.03811299]\n",
      " [26.873709    0.03899904]\n",
      " [27.903864    0.03663332]\n",
      " [28.114422    0.03730037]\n",
      " [27.466848    0.03765075]\n",
      " [27.377604    0.03759213]\n",
      " [29.414616    0.03571039]\n",
      " [27.790657    0.03637161]\n",
      " [25.014679    0.04078686]\n",
      " [22.353756    0.04950327]\n",
      " [29.459478    0.03460918]\n",
      " [29.932152    0.03294808]\n",
      " [24.975092    0.04054238]\n",
      " [26.423143    0.03807268]\n",
      " [24.850216    0.03807477]\n",
      " [26.77562     0.03686502]\n",
      " [26.955095    0.0356807 ]\n",
      " [27.914175    0.03542633]\n",
      " [ 0.11027716  7.950236  ]\n",
      " [ 0.12297624  7.1037064 ]\n",
      " [26.039528    0.03861728]\n",
      " [21.613466    0.04808181]\n",
      " [26.789362    0.04057131]\n",
      " [27.398138    0.03697015]\n",
      " [21.415543    0.04489268]\n",
      " [25.076391    0.03720898]\n",
      " [25.910528    0.03929847]\n",
      " [25.72928     0.04026666]\n",
      " [23.21458     0.04439136]\n",
      " [21.59744     0.05057439]\n",
      " [26.586945    0.03806046]\n",
      " [19.805456    0.062427  ]\n",
      " [22.200771    0.04834774]\n",
      " [ 0.95162666  1.4961756 ]\n",
      " [26.103935    0.03864143]\n",
      " [29.366196    0.03533467]\n",
      " [28.294209    0.04107992]\n",
      " [28.089304    0.03723064]\n",
      " [27.166822    0.03795556]\n",
      " [ 0.10590968  8.473128  ]\n",
      " [ 0.09241986  9.695848  ]\n",
      " [ 0.08554257 10.305665  ]\n",
      " [ 0.08998878  9.762164  ]\n",
      " [ 0.08588658 10.616147  ]\n",
      " [ 0.09096873  9.641492  ]\n",
      " [ 0.08965294  9.810018  ]\n",
      " [ 0.08456078 10.343275  ]\n",
      " [ 0.08864431 10.049644  ]\n",
      " [ 0.08756749 10.184474  ]\n",
      " [ 0.08533565 10.486081  ]\n",
      " [ 0.0847446  10.531184  ]\n",
      " [ 0.08740228 10.178556  ]\n",
      " [ 0.08864774  9.888885  ]\n",
      " [ 0.08822016 10.191029  ]\n",
      " [ 0.09484345  9.241027  ]\n",
      " [24.26995     0.0397904 ]\n",
      " [23.907127    0.03961013]\n",
      " [24.588112    0.03988216]\n",
      " [23.153915    0.04298904]\n",
      " [24.031229    0.04093944]\n",
      " [24.628101    0.03835629]\n",
      " [25.948235    0.03875768]\n",
      " [26.035572    0.03848143]]\n",
      "[[0.9981921  0.00180791]\n",
      " [0.9980091  0.00199091]\n",
      " [0.9981607  0.00183927]\n",
      " [0.9985771  0.00142286]\n",
      " [0.99875057 0.00124945]\n",
      " [0.99846345 0.00153652]\n",
      " [0.9982631  0.00173688]\n",
      " [0.9982287  0.00177123]\n",
      " [0.99830353 0.0016965 ]\n",
      " [0.99797994 0.00202007]\n",
      " [0.9978652  0.0021348 ]\n",
      " [0.9983421  0.00165792]\n",
      " [0.99790794 0.00209206]\n",
      " [0.9984113  0.0015887 ]\n",
      " [0.99770576 0.00229427]\n",
      " [0.9984402  0.00155984]\n",
      " [0.9976532  0.00234682]\n",
      " [0.9964228  0.00357724]\n",
      " [0.01585399 0.984146  ]\n",
      " [0.9967362  0.00326376]\n",
      " [0.9969706  0.00302942]\n",
      " [0.99046826 0.00953179]\n",
      " [0.12212147 0.87787855]\n",
      " [0.997406   0.00259403]\n",
      " [0.997825   0.00217501]\n",
      " [0.9979158  0.00208419]\n",
      " [0.9969639  0.003036  ]\n",
      " [0.9981241  0.00187584]\n",
      " [0.01705031 0.9829497 ]\n",
      " [0.99877226 0.00122771]\n",
      " [0.9987525  0.00124751]\n",
      " [0.99885297 0.001147  ]\n",
      " [0.99877846 0.00122156]\n",
      " [0.99870354 0.00129648]\n",
      " [0.99864894 0.00135109]\n",
      " [0.9988724  0.00112759]\n",
      " [0.99867433 0.00132563]\n",
      " [0.99829435 0.00170561]\n",
      " [0.9987404  0.00125958]\n",
      " [0.9987191  0.00128089]\n",
      " [0.9985476  0.00145238]\n",
      " [0.9985894  0.00141059]\n",
      " [0.9987732  0.00122677]\n",
      " [0.99886745 0.00113258]\n",
      " [0.9987734  0.00122656]\n",
      " [0.9987487  0.00125129]\n",
      " [0.9986747  0.00132526]\n",
      " [0.99868464 0.00131533]\n",
      " [0.99864256 0.0013574 ]\n",
      " [0.99861014 0.00138983]\n",
      " [0.99873096 0.00126905]\n",
      " [0.9986816  0.00131839]\n",
      " [0.99874294 0.00125705]\n",
      " [0.99885386 0.00114612]\n",
      " [0.9986796  0.00132043]\n",
      " [0.7157142  0.2842858 ]\n",
      " [0.99866784 0.00133219]\n",
      " [0.99883    0.00116999]\n",
      " [0.99867386 0.00132617]\n",
      " [0.9987007  0.00129936]\n",
      " [0.9986561  0.00134394]\n",
      " [0.9985596  0.00144043]\n",
      " [0.99875253 0.00124748]\n",
      " [0.99868196 0.00131808]\n",
      " [0.9985196  0.00148043]\n",
      " [0.9985336  0.00146639]\n",
      " [0.99862295 0.00137701]\n",
      " [0.99859554 0.00140443]\n",
      " [0.99860597 0.00139409]\n",
      " [0.998517   0.00148298]\n",
      " [0.9978814  0.00211858]\n",
      " [0.99846506 0.00153492]\n",
      " [0.99799985 0.00200014]\n",
      " [0.9984481  0.00155193]\n",
      " [0.9981242  0.00187583]\n",
      " [0.99827766 0.00172239]\n",
      " [0.99843335 0.00156661]\n",
      " [0.99841017 0.00158982]\n",
      " [0.9985327  0.00146731]\n",
      " [0.99847627 0.00152373]\n",
      " [0.38824978 0.6117502 ]\n",
      " [0.9987112  0.00128876]\n",
      " [0.9983635  0.0016365 ]\n",
      " [0.99872315 0.00127685]\n",
      " [0.9987398  0.00126025]\n",
      " [0.9987692  0.00123081]\n",
      " [0.9987017  0.0012983 ]\n",
      " [0.9986375  0.00136246]\n",
      " [0.9986401  0.00135989]\n",
      " [0.9984026  0.00159741]\n",
      " [0.99840444 0.00159552]\n",
      " [0.9986439  0.0013561 ]\n",
      " [0.9987722  0.0012278 ]\n",
      " [0.99860287 0.00139713]\n",
      " [0.9988007  0.00119928]\n",
      " [0.9986723  0.00132769]\n",
      " [0.9983599  0.00164007]\n",
      " [0.01310294 0.98689705]\n",
      " [0.9881371  0.01186283]\n",
      " [0.99702656 0.00297347]\n",
      " [0.56515586 0.4348441 ]\n",
      " [0.99727273 0.00272729]\n",
      " [0.9983918  0.00160817]\n",
      " [0.998186   0.00181402]\n",
      " [0.9979036  0.00209643]\n",
      " [0.9982341  0.00176591]\n",
      " [0.99840325 0.00159676]\n",
      " [0.99790955 0.00209044]\n",
      " [0.9981311  0.0018689 ]\n",
      " [0.9986987  0.00130128]\n",
      " [0.99823403 0.00176598]\n",
      " [0.99823034 0.00176963]\n",
      " [0.0185988  0.9814012 ]\n",
      " [0.99672776 0.00327223]\n",
      " [0.9953905  0.0046095 ]\n",
      " [0.99835515 0.00164482]\n",
      " [0.01915768 0.9808423 ]\n",
      " [0.9988347  0.00116526]\n",
      " [0.9987955  0.00120451]\n",
      " [0.99877024 0.00122976]\n",
      " [0.99863863 0.0013614 ]\n",
      " [0.9987697  0.00123027]\n",
      " [0.9988239  0.00117615]\n",
      " [0.99880457 0.00119547]\n",
      " [0.99870384 0.00129619]\n",
      " [0.9986401  0.00135986]\n",
      " [0.9988288  0.00117113]\n",
      " [0.9987939  0.00120606]\n",
      " [0.01524446 0.9847555 ]\n",
      " [0.9987287  0.00127129]\n",
      " [0.9985799  0.00142009]\n",
      " [0.9986359  0.00136414]\n",
      " [0.9986683  0.00133168]\n",
      " [0.99876857 0.00123146]\n",
      " [0.9988122  0.00118777]\n",
      " [0.9986093  0.00139069]\n",
      " [0.99878985 0.00121017]\n",
      " [0.998669   0.00133099]\n",
      " [0.9986069  0.0013931 ]\n",
      " [0.99865353 0.00134646]\n",
      " [0.9985411  0.00145891]\n",
      " [0.9986541  0.00134587]\n",
      " [0.9984842  0.00151582]\n",
      " [0.99849623 0.00150375]\n",
      " [0.99859196 0.0014081 ]\n",
      " [0.9985518  0.00144824]\n",
      " [0.9981922  0.0018078 ]\n",
      " [0.9987322  0.0012678 ]\n",
      " [0.99840355 0.00159641]\n",
      " [0.998627   0.00137298]\n",
      " [0.99850816 0.00149184]\n",
      " [0.9986827  0.0013173 ]\n",
      " [0.99875623 0.00124382]\n",
      " [0.9983852  0.00161478]\n",
      " [0.9987551  0.00124495]\n",
      " [0.9986245  0.00137545]\n",
      " [0.9985914  0.00140859]\n",
      " [0.9983821  0.00161791]\n",
      " [0.99846774 0.0015323 ]\n",
      " [0.03629636 0.96370363]\n",
      " [0.99881464 0.0011853 ]\n",
      " [0.9988429  0.00115711]\n",
      " [0.9978763  0.00212372]\n",
      " [0.9986931  0.00130689]\n",
      " [0.9983566  0.0016434 ]\n",
      " [0.99872994 0.00127009]\n",
      " [0.998459   0.00154098]\n",
      " [0.9987943  0.00120567]\n",
      " [0.998664   0.00133598]\n",
      " [0.99824184 0.00175812]\n",
      " [0.99815214 0.00184784]\n",
      " [0.9985674  0.00143257]\n",
      " [0.9987121  0.00128785]\n",
      " [0.997961   0.00203904]\n",
      " [0.998507   0.00149296]\n",
      " [0.99866176 0.00133824]\n",
      " [0.01329132 0.98670864]\n",
      " [0.04424048 0.9557595 ]\n",
      " [0.01059615 0.9894039 ]\n",
      " [0.01097742 0.98902255]\n",
      " [0.01092238 0.9890776 ]\n",
      " [0.01109655 0.98890346]\n",
      " [0.01519685 0.98480314]\n",
      " [0.01146046 0.9885396 ]\n",
      " [0.016911   0.98308897]\n",
      " [0.01750955 0.9824905 ]\n",
      " [0.01809772 0.9819023 ]\n",
      " [0.01642219 0.98357785]\n",
      " [0.9944459  0.00555403]\n",
      " [0.01875393 0.98124605]\n",
      " [0.03783811 0.9621619 ]\n",
      " [0.01820291 0.9817971 ]\n",
      " [0.01879565 0.98120433]\n",
      " [0.01861107 0.9813889 ]\n",
      " [0.02206703 0.977933  ]\n",
      " [0.9703142  0.02968582]\n",
      " [0.99533504 0.00466492]\n",
      " [0.08218936 0.9178106 ]\n",
      " [0.01960032 0.98039967]\n",
      " [0.9985296  0.00147038]\n",
      " [0.9984729  0.00152711]\n",
      " [0.99860716 0.00139284]\n",
      " [0.99872875 0.00127123]\n",
      " [0.9988104  0.0011896 ]\n",
      " [0.9986624  0.00133762]\n",
      " [0.99870455 0.00129544]\n",
      " [0.99858314 0.00141689]\n",
      " [0.9985897  0.00141035]\n",
      " [0.9986224  0.00137759]\n",
      " [0.99884725 0.00115276]\n",
      " [0.99854374 0.0014563 ]\n",
      " [0.9985509  0.00144909]\n",
      " [0.99868894 0.00131112]\n",
      " [0.99867505 0.00132498]\n",
      " [0.9986311  0.00136889]\n",
      " [0.9986288  0.00137122]\n",
      " [0.9987874  0.00121256]\n",
      " [0.9986929  0.00130706]\n",
      " [0.99837214 0.00162786]\n",
      " [0.99779034 0.00220965]\n",
      " [0.99882656 0.00117343]\n",
      " [0.9989005  0.00109955]\n",
      " [0.9983793  0.00162068]\n",
      " [0.9985612  0.00143881]\n",
      " [0.9984702  0.00152983]\n",
      " [0.9986251  0.00137492]\n",
      " [0.998678   0.00132196]\n",
      " [0.99873245 0.00126751]\n",
      " [0.01368116 0.9863189 ]\n",
      " [0.01701697 0.982983  ]\n",
      " [0.9985191  0.00148083]\n",
      " [0.99778026 0.00221968]\n",
      " [0.99848783 0.00151217]\n",
      " [0.99865246 0.00134755]\n",
      " [0.9979081  0.00209188]\n",
      " [0.9985184  0.00148163]\n",
      " [0.99848557 0.0015144 ]\n",
      " [0.99843746 0.00156257]\n",
      " [0.9980914  0.00190857]\n",
      " [0.99766374 0.00233621]\n",
      " [0.9985705  0.0014295 ]\n",
      " [0.9968579  0.00314211]\n",
      " [0.997827   0.00217302]\n",
      " [0.38876778 0.6112322 ]\n",
      " [0.9985219  0.0014781 ]\n",
      " [0.9987982  0.0012018 ]\n",
      " [0.9985502  0.00144978]\n",
      " [0.9986763  0.00132368]\n",
      " [0.9986048  0.00139518]\n",
      " [0.01234517 0.98765486]\n",
      " [0.0094419  0.99055815]\n",
      " [0.00823221 0.99176776]\n",
      " [0.00913392 0.99086607]\n",
      " [0.00802526 0.9919747 ]\n",
      " [0.00934694 0.99065304]\n",
      " [0.00905615 0.99094385]\n",
      " [0.00810914 0.9918909 ]\n",
      " [0.00874352 0.99125654]\n",
      " [0.00852484 0.99147516]\n",
      " [0.0080723  0.9919277 ]\n",
      " [0.00798278 0.9920172 ]\n",
      " [0.0085138  0.9914862 ]\n",
      " [0.00888474 0.9911153 ]\n",
      " [0.00858235 0.9914176 ]\n",
      " [0.01015904 0.9898409 ]\n",
      " [0.99836314 0.00163681]\n",
      " [0.9983459  0.00165409]\n",
      " [0.9983806  0.00161938]\n",
      " [0.9981468  0.00185322]\n",
      " [0.9982993  0.0017007 ]\n",
      " [0.998445   0.001555  ]\n",
      " [0.9985086  0.00149143]\n",
      " [0.9985242  0.00147585]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 21:40:33 - INFO - __main__ -   ***** Test results None *****\r\n",
      "\r",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 44.66it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/ZeroShot/2' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/2/eval-dev/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train_ot_2.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev_ot_2.csv \\\n",
    "      --test_file Data/ZeroShot/dev_ot_2.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine EN+PT results to Comb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk 'FNR==1 && NR!=1{next;}{print}' models/ZeroShot/1/eval-dev/test_results_None.txt models/ZeroShot/2/eval-dev/test_results_None.txt > models/ZeroShot/1/eval-dev/test_results_Comb.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_z = {\n",
    "    'submission_format_file' : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
    "    'prediction_format_file' : 'models/ZeroShot/1/eval-dev/test_results_Comb.txt'                        ,\n",
    "    }\n",
    "params_z[ 'setting' ] = 'zero_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = insert_to_submission_file( **params_z )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote outputs/zero_shot_dev_formated_comb.csv\n"
     ]
    }
   ],
   "source": [
    "write_csv( updated_data, 'outputs/zero_shot_dev_formated_comb.csv' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Settings</th>\n",
       "      <th>Languages</th>\n",
       "      <th>F1 Score (Macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>EN</td>\n",
       "      <td>0.760457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>PT</td>\n",
       "      <td>0.590239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>EN,PT</td>\n",
       "      <td>0.725061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one_shot</td>\n",
       "      <td>EN</td>\n",
       "      <td>(None, None, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one_shot</td>\n",
       "      <td>PT</td>\n",
       "      <td>(None, None, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one_shot</td>\n",
       "      <td>EN,PT</td>\n",
       "      <td>(None, None, None)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Settings Languages    F1 Score (Macro)\n",
       "0  zero_shot        EN            0.760457\n",
       "1  zero_shot        PT            0.590239\n",
       "2  zero_shot     EN,PT            0.725061\n",
       "3   one_shot        EN  (None, None, None)\n",
       "4   one_shot        PT  (None, None, None)\n",
       "5   one_shot     EN,PT  (None, None, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_comb = evaluate_submission( 'outputs/zero_shot_dev_formated_comb.csv', gold_file )\n",
    "#%reload_ext google.colab.data_table\n",
    "pd.DataFrame(data=results_comb[1:], columns=results_comb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the English results from the English model and Portuguese results from the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_0 = util.load_df('models/ZeroShot/0/eval-dev/test_results_None.txt', delimiter=\"\\t\")\n",
    "dres_1 = util.load_df('models/ZeroShot/1/eval-dev/test_results_None.txt', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_0['index'] = dres_0['index'].astype(int)\n",
    "dres_1['index'] = dres_1['index'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in dres_1.iterrows():\n",
    "    # print(i, row)\n",
    "    dres_0.loc[i, 'prediction'] = row['prediction']\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dres_0.to_csv('models/ZeroShot/1/eval-dev/test_results_Comb2.txt', index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_z2 = {\n",
    "    'submission_format_file' : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
    "    'prediction_format_file' : 'models/ZeroShot/1/eval-dev/test_results_Comb2.txt'                        ,\n",
    "    }\n",
    "params_z2[ 'setting' ] = 'zero_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote outputs/zero_shot_dev_formated_comb2.csv\n"
     ]
    }
   ],
   "source": [
    "updated_data = insert_to_submission_file( **params_z2 )\n",
    "write_csv( updated_data, 'outputs/zero_shot_dev_formated_comb2.csv' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Settings</th>\n",
       "      <th>Languages</th>\n",
       "      <th>F1 Score (Macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>EN</td>\n",
       "      <td>0.760457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>PT</td>\n",
       "      <td>0.611721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>EN,PT</td>\n",
       "      <td>0.721204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one_shot</td>\n",
       "      <td>EN</td>\n",
       "      <td>(None, None, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one_shot</td>\n",
       "      <td>PT</td>\n",
       "      <td>(None, None, None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one_shot</td>\n",
       "      <td>EN,PT</td>\n",
       "      <td>(None, None, None)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Settings Languages    F1 Score (Macro)\n",
       "0  zero_shot        EN            0.760457\n",
       "1  zero_shot        PT            0.611721\n",
       "2  zero_shot     EN,PT            0.721204\n",
       "3   one_shot        EN  (None, None, None)\n",
       "4   one_shot        PT  (None, None, None)\n",
       "5   one_shot     EN,PT  (None, None, None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_comb2 = evaluate_submission( 'outputs/zero_shot_dev_formated_comb2.csv', gold_file )\n",
    "#%reload_ext google.colab.data_table\n",
    "pd.DataFrame(data=results_comb2[1:], columns=results_comb2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, getting the PT results from the full model didn't seem to improve things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UX9ys7tTKVi"
   },
   "source": [
    "## Generate Eval Data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ets4flitTRZZ",
    "outputId": "1deda94d-73b9-4955-c0d4-4999e3b306ee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 21:40:36 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 21:40:36 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/0/eval-eval/runs/Dec20_21-40-36_r18g08.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/0/eval-eval/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/0/eval-eval/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 21:40:36 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train.csv\n",
      "12/20/2021 21:40:36 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev.csv\n",
      "12/20/2021 21:40:36 - INFO - __main__ -   load a local file for test: Data/ZeroShot/eval.csv\n",
      "12/20/2021 21:40:37 - WARNING - datasets.builder -   Using custom data configuration default-65d97e32ebc84f6f\n",
      "12/20/2021 21:40:37 - WARNING - datasets.builder -   Reusing dataset csv (/users/sitkonen/.cache/huggingface/datasets/csv/default-65d97e32ebc84f6f/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 13.19it/s]\n",
      "[INFO|configuration_utils.py:586] 2021-12-20 21:40:37,791 >> loading configuration file models/ZeroShot/0/config.json\n",
      "[INFO|configuration_utils.py:625] 2021-12-20 21:40:37,792 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 21:40:37,831 >> Didn't find file models/ZeroShot/0/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:37,832 >> loading file models/ZeroShot/0/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:37,832 >> loading file models/ZeroShot/0/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:37,832 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:37,832 >> loading file models/ZeroShot/0/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:37,832 >> loading file models/ZeroShot/0/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1338] 2021-12-20 21:40:38,011 >> loading weights file models/ZeroShot/0/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1607] 2021-12-20 21:40:40,910 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[INFO|modeling_utils.py:1616] 2021-12-20 21:40:40,910 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/ZeroShot/0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "12/20/2021 21:40:40 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-65d97e32ebc84f6f/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-d3b7fb367b54d9a1.arrow\n",
      "12/20/2021 21:40:41 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-65d97e32ebc84f6f/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-70529e314a2484a1.arrow\n",
      "12/20/2021 21:40:41 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-65d97e32ebc84f6f/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-c36e3848d5ad6f40.arrow\n",
      "12/20/2021 21:40:45 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2021-12-20 21:40:45,693 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:40:45,696 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:40:45,696 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:40:45,696 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 93/93 [00:02<00:00, 43.31it/s]\n",
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.6955\n",
      "  eval_f1                 =     0.6939\n",
      "  eval_loss               =     2.1835\n",
      "  eval_runtime            = 0:00:02.17\n",
      "  eval_samples            =        739\n",
      "  eval_samples_per_second =    339.875\n",
      "  eval_steps_per_second   =     42.772\n",
      "12/20/2021 21:40:47 - INFO - __main__ -   *** Test ***\n",
      "AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
      "  test_dataset.remove_columns_(\"label\")\n",
      "[INFO|trainer.py:541] 2021-12-20 21:40:47,961 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:40:47,963 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:40:47,963 >>   Num examples = 762\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:40:47,963 >>   Batch size = 8\n",
      " 99%|██████████████████████████████████████████▌| 95/96 [00:02<00:00, 46.08it/s][[1.3695826e-02 6.6186012e+01]\n",
      " [1.4715016e-02 6.9286613e+01]\n",
      " [1.5811309e-02 6.1395977e+01]\n",
      " ...\n",
      " [8.0651253e+01 1.4566456e-02]\n",
      " [8.4039612e+01 1.4244535e-02]\n",
      " [8.4626846e+01 1.4228908e-02]]\n",
      "[[2.0688650e-04 9.9979311e-01]\n",
      " [2.1233382e-04 9.9978763e-01]\n",
      " [2.5746375e-04 9.9974251e-01]\n",
      " ...\n",
      " [9.9981946e-01 1.8057780e-04]\n",
      " [9.9983054e-01 1.6946915e-04]\n",
      " [9.9983191e-01 1.6810879e-04]]\n",
      "12/20/2021 21:40:50 - INFO - __main__ -   ***** Test results None *****\n",
      "100%|███████████████████████████████████████████| 96/96 [00:02<00:00, 44.18it/s]\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/ZeroShot/0' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/0/eval-eval/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
    "      --test_file Data/ZeroShot/eval.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSS6PFfb4AAl"
   },
   "source": [
    "### Use predictions to create the submission file (for eval data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "WqxzrRBfTcnq"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'submission_format_file' : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/eval_submission_format.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/eval.csv'                   ,\n",
    "    'prediction_format_file' : 'models/ZeroShot/0/eval-eval/test_results_None.txt'                        ,\n",
    "    }\n",
    "params[ 'setting' ] = 'zero_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "IHqanuVDTz-r"
   },
   "outputs": [],
   "source": [
    " updated_data = insert_to_submission_file( **params )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKDBuxMLT5QU",
    "outputId": "f5eefcfb-ace6-4225-f64a-92bba8dd3ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote outputs/zero_shot_eval_formated.csv\n"
     ]
    }
   ],
   "source": [
    "write_csv( updated_data, 'outputs/zero_shot_eval_formated.csv' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use language-specific models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 21:40:53 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 21:40:53 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/1/eval-eval/runs/Dec20_21-40-53_r18g08.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/1/eval-eval/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/1/eval-eval/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 21:40:53 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_en_2.csv\n",
      "12/20/2021 21:40:53 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev_en_2.csv\n",
      "12/20/2021 21:40:53 - INFO - __main__ -   load a local file for test: Data/ZeroShot/eval_en_2.csv\n",
      "12/20/2021 21:40:54 - WARNING - datasets.builder -   Using custom data configuration default-54020116af6df121\n",
      "12/20/2021 21:40:54 - WARNING - datasets.builder -   Reusing dataset csv (/users/sitkonen/.cache/huggingface/datasets/csv/default-54020116af6df121/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 12.61it/s]\n",
      "[INFO|configuration_utils.py:586] 2021-12-20 21:40:54,349 >> loading configuration file models/ZeroShot/1/config.json\n",
      "[INFO|configuration_utils.py:625] 2021-12-20 21:40:54,350 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 21:40:54,354 >> Didn't find file models/ZeroShot/1/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:54,354 >> loading file models/ZeroShot/1/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:54,354 >> loading file models/ZeroShot/1/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:54,354 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:54,354 >> loading file models/ZeroShot/1/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:40:54,354 >> loading file models/ZeroShot/1/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1338] 2021-12-20 21:40:54,419 >> loading weights file models/ZeroShot/1/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1607] 2021-12-20 21:40:55,336 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[INFO|modeling_utils.py:1616] 2021-12-20 21:40:55,336 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/ZeroShot/1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "12/20/2021 21:40:55 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-54020116af6df121/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-144d2c25a45a9630.arrow\n",
      "12/20/2021 21:40:55 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-54020116af6df121/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-ea96df2174b99b77.arrow\n",
      "12/20/2021 21:40:55 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-54020116af6df121/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-02503f27866b9563.arrow\n",
      "12/20/2021 21:40:59 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2021-12-20 21:40:59,463 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:40:59,465 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:40:59,465 >>   Num examples = 466\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:40:59,465 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 59/59 [00:01<00:00, 44.51it/s]\n",
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.7682\n",
      "  eval_f1                 =     0.7605\n",
      "  eval_loss               =     1.0696\n",
      "  eval_runtime            = 0:00:01.36\n",
      "  eval_samples            =        466\n",
      "  eval_samples_per_second =    340.773\n",
      "  eval_steps_per_second   =     43.145\n",
      "12/20/2021 21:41:00 - INFO - __main__ -   *** Test ***\n",
      "AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
      "  test_dataset.remove_columns_(\"label\")\n",
      "[INFO|trainer.py:541] 2021-12-20 21:41:00,885 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:41:00,887 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:41:00,887 >>   Num examples = 483\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:41:00,887 >>   Batch size = 8\n",
      " 93%|████████████████████████████████████████▏  | 57/61 [00:01<00:00, 43.51it/s][[ 0.08278908  7.2746243 ]\n",
      " [ 0.03684703 17.620275  ]\n",
      " [ 0.03685274 18.047894  ]\n",
      " [ 0.04899527 12.483108  ]\n",
      " [ 0.03878136 16.80621   ]\n",
      " [ 0.30183083  2.3041894 ]\n",
      " [ 0.0410501  14.46208   ]\n",
      " [ 0.04904686 11.805721  ]\n",
      " [ 0.10382957  5.2814116 ]\n",
      " [ 2.920986    0.2311961 ]\n",
      " [ 1.8737153   0.327728  ]\n",
      " [ 0.0356465  16.888062  ]\n",
      " [ 0.71437657  0.75136745]\n",
      " [24.775135    0.03690014]\n",
      " [23.19164     0.04226122]\n",
      " [25.417337    0.03200001]\n",
      " [24.937435    0.03247053]\n",
      " [24.053545    0.03836707]\n",
      " [25.20521     0.03392418]\n",
      " [23.66465     0.04079532]\n",
      " [23.785727    0.0404459 ]\n",
      " [23.087463    0.04359766]\n",
      " [21.277847    0.04766747]\n",
      " [25.084621    0.03541473]\n",
      " [24.855148    0.03666307]\n",
      " [20.939747    0.04851723]\n",
      " [ 0.03941316 15.018608  ]\n",
      " [ 0.03822732 15.455197  ]\n",
      " [ 1.0752388   0.47588393]\n",
      " [ 1.3579193   0.39650115]\n",
      " [ 0.03318666 16.754389  ]\n",
      " [21.236578    0.04006829]\n",
      " [ 1.9418378   0.26428658]\n",
      " [ 0.18864736  2.1231964 ]\n",
      " [ 0.03334456 17.708727  ]\n",
      " [ 0.69925773  0.7961984 ]\n",
      " [ 0.0390282  15.53795   ]\n",
      " [ 0.15072174  2.9141695 ]\n",
      " [ 0.0332334  17.90163   ]\n",
      " [ 0.05296506 10.210722  ]\n",
      " [ 0.06104204  7.7887135 ]\n",
      " [ 0.05800447  7.839586  ]\n",
      " [ 0.45196256  0.94425166]\n",
      " [23.943037    0.03611743]\n",
      " [26.024317    0.03320342]\n",
      " [25.201353    0.03286577]\n",
      " [23.044174    0.03582652]\n",
      " [24.915316    0.03487789]\n",
      " [25.236244    0.03872555]\n",
      " [23.853506    0.03313185]\n",
      " [25.457922    0.03854357]\n",
      " [24.039911    0.03941919]\n",
      " [23.765488    0.03583311]\n",
      " [21.331568    0.05018126]\n",
      " [ 0.07537506  8.757631  ]\n",
      " [ 0.04169784 13.426526  ]\n",
      " [ 0.05219281 12.024541  ]\n",
      " [ 0.03657069 13.194434  ]\n",
      " [ 6.2732167   0.08212047]\n",
      " [14.402489    0.04246705]\n",
      " [ 2.7495782   0.17916542]\n",
      " [24.271112    0.03355611]\n",
      " [22.48984     0.03271506]\n",
      " [23.304163    0.03424478]\n",
      " [24.197157    0.03344062]\n",
      " [24.486414    0.03440451]\n",
      " [ 5.6774125   0.09092602]\n",
      " [21.892378    0.03212907]\n",
      " [23.051493    0.03198842]\n",
      " [25.005642    0.03545557]\n",
      " [ 0.03211435 20.924427  ]\n",
      " [ 0.04118609 18.255152  ]\n",
      " [ 0.03756167 19.3053    ]\n",
      " [ 0.04274886 17.212378  ]\n",
      " [ 0.03549583 19.486832  ]\n",
      " [ 0.03988937 17.98271   ]\n",
      " [ 0.04091084 18.065905  ]\n",
      " [ 0.04081396 17.518991  ]\n",
      " [ 0.0386897  18.436365  ]\n",
      " [ 0.04138526 17.493744  ]\n",
      " [ 0.04942201 14.963731  ]\n",
      " [ 0.04456938 16.11601   ]\n",
      " [ 0.0436224  16.189602  ]\n",
      " [ 0.04285631 16.441702  ]\n",
      " [ 0.04179366 17.232937  ]\n",
      " [ 0.05009396 14.421213  ]\n",
      " [ 0.49589536  1.082804  ]\n",
      " [ 0.04749217 14.554907  ]\n",
      " [ 0.03944448 15.935012  ]\n",
      " [ 0.04511627 14.147245  ]\n",
      " [ 0.04206249 15.1258135 ]\n",
      " [ 0.083373    7.236993  ]\n",
      " [ 0.04937169 13.4352455 ]\n",
      " [ 0.0567802  12.334288  ]\n",
      " [ 0.04349312 14.088197  ]\n",
      " [ 0.0471832  13.496448  ]\n",
      " [ 1.2754877   0.5575604 ]\n",
      " [ 0.05581841 10.075531  ]\n",
      " [ 0.16372904  3.0000067 ]\n",
      " [ 0.04013603 15.018255  ]\n",
      " [ 0.05025251 13.325036  ]\n",
      " [ 0.08580791  8.65016   ]\n",
      " [ 0.07181498  8.91506   ]\n",
      " [ 0.08055126  8.9821    ]\n",
      " [ 0.06838115 10.165846  ]\n",
      " [ 0.12444784  3.45595   ]\n",
      " [ 0.05640062  8.850173  ]\n",
      " [18.992762    0.03549833]\n",
      " [25.244394    0.03209284]\n",
      " [25.716505    0.03041009]\n",
      " [23.586376    0.0328904 ]\n",
      " [ 0.07415609  8.949226  ]\n",
      " [25.27173     0.03693571]\n",
      " [26.379686    0.03373213]\n",
      " [23.562546    0.03186128]\n",
      " [26.729336    0.0323204 ]\n",
      " [20.265404    0.03391165]\n",
      " [23.555845    0.03268854]\n",
      " [14.914721    0.04090253]\n",
      " [24.329033    0.03059321]\n",
      " [15.912244    0.03862719]\n",
      " [25.887815    0.03265034]\n",
      " [ 9.62848     0.06592379]\n",
      " [ 5.288907    0.11724401]\n",
      " [ 1.6864241   0.33403996]\n",
      " [ 0.14317764  3.353328  ]\n",
      " [ 1.6872243   0.36966187]\n",
      " [ 2.4107978   0.23179728]\n",
      " [ 0.25330037  1.5836103 ]\n",
      " [ 1.4606092   0.41722733]\n",
      " [ 4.398938    0.13432477]\n",
      " [ 0.07451582  8.102826  ]\n",
      " [ 0.25244352  1.7855941 ]\n",
      " [ 0.14994234  3.212195  ]\n",
      " [ 0.08900313  5.5269475 ]\n",
      " [ 0.09755444  4.6511784 ]\n",
      " [ 0.12462009  4.0424438 ]\n",
      " [ 0.9398646   0.48943177]\n",
      " [ 3.0013351   0.18976648]\n",
      " [ 1.2686579   0.40330744]\n",
      " [ 5.3755784   0.10732435]\n",
      " [ 0.06143846 10.734432  ]\n",
      " [ 0.2729122   1.4476624 ]\n",
      " [ 2.0708892   0.3714581 ]\n",
      " [ 1.6748928   0.48373312]\n",
      " [ 0.19191335  3.018787  ]\n",
      " [ 0.0795277   6.8692956 ]\n",
      " [ 0.05313466 12.663697  ]\n",
      " [ 4.16526     0.18644342]\n",
      " [ 2.0747316   0.36976695]\n",
      " [ 0.1640383   3.3741171 ]\n",
      " [15.634884    0.05531696]\n",
      " [ 6.6013613   0.10967243]\n",
      " [22.031748    0.0437495 ]\n",
      " [ 1.0140185   0.688716  ]\n",
      " [ 4.572699    0.17106012]\n",
      " [ 5.6731186   0.12879235]\n",
      " [ 0.338275    1.5241382 ]\n",
      " [ 9.571056    0.07331606]\n",
      " [12.171664    0.06251881]\n",
      " [ 2.586195    0.28367263]\n",
      " [ 2.942487    0.24275208]\n",
      " [ 0.39706153  1.2042708 ]\n",
      " [ 9.69659     0.07058376]\n",
      " [11.8896675   0.05469911]\n",
      " [ 7.017295    0.0885881 ]\n",
      " [ 2.0109432   0.3074019 ]\n",
      " [20.536852    0.03742796]\n",
      " [ 2.190546    0.35057095]\n",
      " [10.171359    0.06950188]\n",
      " [10.45285     0.06611286]\n",
      " [13.957075    0.05222427]\n",
      " [12.722416    0.05831681]\n",
      " [ 0.06463934  9.466419  ]\n",
      " [ 0.07810792  6.671616  ]\n",
      " [19.485485    0.03633347]\n",
      " [24.507532    0.0351101 ]\n",
      " [13.396892    0.04480803]\n",
      " [16.581125    0.03919179]\n",
      " [ 9.570424    0.05878247]\n",
      " [16.733332    0.03938858]\n",
      " [23.07242     0.03363039]\n",
      " [19.166744    0.03517836]\n",
      " [25.366613    0.03446505]\n",
      " [23.213097    0.0401096 ]\n",
      " [24.684477    0.03761325]\n",
      " [22.042969    0.03267495]\n",
      " [24.980473    0.03228277]\n",
      " [17.243654    0.0372284 ]\n",
      " [ 0.07000022 10.106893  ]\n",
      " [ 0.05642231  7.790395  ]\n",
      " [22.812922    0.0339938 ]\n",
      " [23.44697     0.03725602]\n",
      " [25.933075    0.03423495]\n",
      " [23.347147    0.03493225]\n",
      " [26.149492    0.03415022]\n",
      " [21.01178     0.03679407]\n",
      " [21.906443    0.03612631]\n",
      " [23.96674     0.03437256]\n",
      " [19.024948    0.03664091]\n",
      " [24.992592    0.03607603]\n",
      " [16.151066    0.04164717]\n",
      " [ 0.09104715  7.5688415 ]\n",
      " [ 0.08476479  8.2850685 ]\n",
      " [ 0.09390482  7.6262765 ]\n",
      " [21.884617    0.03374441]\n",
      " [20.089638    0.03363246]\n",
      " [23.69614     0.03737026]\n",
      " [23.001425    0.03309565]\n",
      " [23.95987     0.03708585]\n",
      " [22.887384    0.0339411 ]\n",
      " [21.811125    0.03736042]\n",
      " [23.850935    0.03603182]\n",
      " [23.403812    0.03495709]\n",
      " [22.754026    0.03282252]\n",
      " [22.490042    0.03991273]\n",
      " [23.607054    0.03456643]\n",
      " [ 9.570882    0.05222106]\n",
      " [21.154394    0.03447314]\n",
      " [17.670467    0.03831251]\n",
      " [ 0.04168892 14.761245  ]\n",
      " [ 6.2526603   0.11933969]\n",
      " [ 8.380457    0.08203026]\n",
      " [15.224796    0.04873535]\n",
      " [ 0.28088796  1.6696199 ]\n",
      " [ 3.9845898   0.1647772 ]\n",
      " [23.596624    0.03768901]\n",
      " [ 8.053925    0.08373147]\n",
      " [ 0.08869334  6.000893  ]\n",
      " [ 0.1644527   3.1563623 ]\n",
      " [ 0.93096733  0.6299514 ]\n",
      " [14.276467    0.05213149]\n",
      " [21.235044    0.03772464]\n",
      " [15.461436    0.0495737 ]\n",
      " [19.27215     0.04216285]\n",
      " [ 2.335012    0.22184141]\n",
      " [ 7.839783    0.07938173]\n",
      " [ 5.450388    0.11830931]\n",
      " [24.7153      0.03750954]\n",
      " [15.585834    0.04263102]\n",
      " [24.188322    0.03464652]\n",
      " [23.398575    0.03382586]\n",
      " [ 9.488648    0.05807811]\n",
      " [22.46441     0.03629456]\n",
      " [14.558395    0.04502402]\n",
      " [21.383455    0.03674711]\n",
      " [18.007397    0.03901922]\n",
      " [21.820126    0.0352001 ]\n",
      " [ 0.49547735  0.63252413]\n",
      " [ 0.06828588 10.621834  ]\n",
      " [ 0.078527    9.178227  ]\n",
      " [ 0.04124366 14.029057  ]\n",
      " [ 0.0727388  10.188229  ]\n",
      " [ 0.06553145 11.415921  ]\n",
      " [ 0.07115383 10.430865  ]\n",
      " [ 0.04909178 13.995078  ]\n",
      " [ 0.05570002 12.699904  ]\n",
      " [ 0.07195707  9.065295  ]\n",
      " [ 0.03731948 11.864389  ]\n",
      " [13.937928    0.04637331]\n",
      " [ 4.668514    0.10845504]\n",
      " [ 0.05876629 11.057301  ]\n",
      " [ 0.04354809 16.054203  ]\n",
      " [ 0.03870039 16.540262  ]\n",
      " [ 0.05026423 13.635431  ]\n",
      " [ 4.7318377   0.12453207]\n",
      " [ 0.04223054 16.882433  ]\n",
      " [ 0.03740472 17.105362  ]\n",
      " [ 0.04143601 16.876482  ]\n",
      " [ 0.03680564 17.63692   ]\n",
      " [ 0.03992784 18.127531  ]\n",
      " [ 0.03624323 18.530794  ]\n",
      " [ 0.0380688  17.30314   ]\n",
      " [ 0.03701704 18.162224  ]\n",
      " [ 0.03596145 17.788916  ]\n",
      " [ 0.04136489 17.064827  ]\n",
      " [ 0.05084005 12.397007  ]\n",
      " [ 0.3082554   1.4190978 ]\n",
      " [ 0.09051402  5.580857  ]\n",
      " [ 8.668278    0.0683468 ]\n",
      " [ 3.2900248   0.18179426]\n",
      " [ 0.1787374   2.3422654 ]\n",
      " [ 0.8963014   0.550265  ]\n",
      " [ 0.30459574  1.2360027 ]\n",
      " [ 0.04984947 10.774014  ]\n",
      " [ 6.1451707   0.08800393]\n",
      " [ 1.2165263   0.4300503 ]\n",
      " [ 0.1812975   1.9647391 ]\n",
      " [18.464434    0.04038291]\n",
      " [ 1.7164637   0.3096995 ]\n",
      " [ 4.1770873   0.1257409 ]\n",
      " [ 8.530304    0.06919977]\n",
      " [ 4.023025    0.15326528]\n",
      " [17.110682    0.04679786]\n",
      " [16.79755     0.05734315]\n",
      " [16.506184    0.0474554 ]\n",
      " [ 9.261909    0.06290007]\n",
      " [ 1.6421787   0.37214223]\n",
      " [16.519028    0.04849509]\n",
      " [ 7.912847    0.07391584]\n",
      " [18.284906    0.04239966]\n",
      " [ 0.06982313  9.111113  ]\n",
      " [ 0.10354375  4.456769  ]\n",
      " [14.9809475   0.04933392]\n",
      " [ 0.33434534  1.5088924 ]\n",
      " [ 0.25956485  1.8082238 ]\n",
      " [ 0.05448491 13.710349  ]\n",
      " [ 0.07298326 10.298911  ]\n",
      " [ 0.06546257 11.301297  ]\n",
      " [ 2.176647    0.2631949 ]\n",
      " [24.930212    0.03552028]\n",
      " [24.977623    0.03423407]\n",
      " [23.01663     0.03420427]\n",
      " [24.70457     0.03561248]\n",
      " [25.057669    0.03483847]\n",
      " [24.990805    0.03553959]\n",
      " [21.853071    0.034297  ]\n",
      " [24.740734    0.04104189]\n",
      " [20.832497    0.0356052 ]\n",
      " [26.061522    0.03526016]\n",
      " [22.990028    0.03302109]\n",
      " [ 0.46488473  1.0868515 ]\n",
      " [ 0.04602342 12.940589  ]\n",
      " [ 5.2683935   0.10090267]\n",
      " [ 0.06177735  8.2867775 ]\n",
      " [ 0.04215172 14.978916  ]\n",
      " [ 0.05916962 12.043672  ]\n",
      " [ 0.32928026  1.2718945 ]\n",
      " [ 0.04681489 13.337212  ]\n",
      " [ 0.04846249 12.713449  ]\n",
      " [ 0.04889021 13.184429  ]\n",
      " [ 0.05179274 13.273435  ]\n",
      " [ 0.0737098   6.937403  ]\n",
      " [ 0.04670599 11.809895  ]\n",
      " [ 0.06254306  8.334401  ]\n",
      " [ 0.11311389  3.899686  ]\n",
      " [ 0.09972203  4.6023927 ]\n",
      " [ 6.6396055   0.08642118]\n",
      " [ 0.06219095 11.13314   ]\n",
      " [23.485909    0.04018776]\n",
      " [24.591965    0.03564648]\n",
      " [24.639214    0.03714137]\n",
      " [17.213436    0.04222496]\n",
      " [24.872143    0.03649243]\n",
      " [22.602335    0.04315669]\n",
      " [22.906246    0.0445781 ]\n",
      " [23.099936    0.03463269]\n",
      " [24.441088    0.03731991]\n",
      " [23.719395    0.03409994]\n",
      " [21.181952    0.03513628]\n",
      " [ 0.21277969  1.9300979 ]\n",
      " [24.640188    0.03808168]\n",
      " [26.133715    0.0364894 ]\n",
      " [23.682108    0.03414807]\n",
      " [23.331856    0.04390188]\n",
      " [20.767847    0.04011972]\n",
      " [ 0.03674561 16.297468  ]\n",
      " [ 0.0414679  14.864907  ]\n",
      " [ 0.03945587 14.780699  ]\n",
      " [ 0.05125638 13.381317  ]\n",
      " [ 0.04687161 14.266623  ]\n",
      " [ 0.0377274  16.911848  ]\n",
      " [ 0.10337818  5.783998  ]\n",
      " [ 0.03946681 17.189648  ]\n",
      " [ 0.04365152 15.701821  ]\n",
      " [ 0.03706013 18.452108  ]\n",
      " [ 0.03990675 16.849758  ]\n",
      " [ 0.04350789 16.241558  ]\n",
      " [ 0.04296103 15.678412  ]\n",
      " [ 0.03906821 16.478626  ]\n",
      " [ 0.03734293 14.513976  ]\n",
      " [ 0.03484512 18.216614  ]\n",
      " [ 0.04519595 14.989487  ]\n",
      " [ 0.03869827 16.708479  ]\n",
      " [ 0.03190004 20.75354   ]\n",
      " [ 0.0367172  18.466467  ]\n",
      " [ 0.03964813 15.835322  ]\n",
      " [ 0.03626454 17.984558  ]\n",
      " [ 0.04617754 13.242643  ]\n",
      " [ 0.0341953  19.01087   ]\n",
      " [ 0.03312308 20.776014  ]\n",
      " [ 0.03998101 14.650789  ]\n",
      " [ 0.04719434 12.0831785 ]\n",
      " [ 0.04571534 13.18049   ]\n",
      " [ 0.03138344 19.62926   ]\n",
      " [ 0.03367304 19.231543  ]\n",
      " [ 0.6003169   0.84967923]\n",
      " [ 0.03811178 15.197056  ]\n",
      " [ 0.04883809 10.76521   ]\n",
      " [ 0.04701661 14.10437   ]\n",
      " [ 0.04512407 14.233426  ]\n",
      " [ 0.721093    0.71564555]\n",
      " [ 0.04372576 12.169851  ]\n",
      " [ 0.04050594 14.594616  ]\n",
      " [ 0.05015326 12.700426  ]\n",
      " [ 0.04059522 15.188895  ]\n",
      " [ 0.04590699 12.788668  ]\n",
      " [ 0.05334476  8.621515  ]\n",
      " [ 0.04550841 12.508148  ]\n",
      " [ 0.04699119 14.203079  ]\n",
      " [ 0.04245958 14.562577  ]\n",
      " [ 0.03508994 16.578417  ]\n",
      " [ 0.04468456 14.284123  ]\n",
      " [ 0.05520664 10.8001375 ]\n",
      " [ 0.04106355 13.647328  ]\n",
      " [ 0.04361615 14.949115  ]\n",
      " [ 0.04820855 14.069279  ]\n",
      " [ 0.04549376 14.200401  ]\n",
      " [ 0.04972575 12.426105  ]\n",
      " [ 0.03522867 16.529564  ]\n",
      " [ 0.04032359 15.127359  ]\n",
      " [ 0.05042934 11.150161  ]\n",
      " [ 0.03742092 17.257475  ]\n",
      " [ 0.04295062 13.730424  ]\n",
      " [ 0.38980833  1.5949878 ]\n",
      " [ 0.06636786  8.324093  ]\n",
      " [ 0.04330003 14.514394  ]\n",
      " [ 0.03761935 16.518517  ]\n",
      " [ 0.03716831 15.573024  ]\n",
      " [ 0.04146677 13.315667  ]\n",
      " [ 0.0447233  15.312842  ]\n",
      " [ 0.03914814 16.642235  ]\n",
      " [ 0.0374101  18.130407  ]\n",
      " [ 0.03295796 19.962296  ]\n",
      " [25.197754    0.03334547]\n",
      " [25.164957    0.03478526]\n",
      " [11.806007    0.05071675]\n",
      " [18.689512    0.03823513]\n",
      " [20.920187    0.03500424]\n",
      " [18.026852    0.03904767]\n",
      " [19.620384    0.03651882]\n",
      " [ 0.04017328 14.409764  ]\n",
      " [ 0.05875663 10.515594  ]\n",
      " [ 0.06276953 10.8701935 ]\n",
      " [ 0.07084162  9.869935  ]\n",
      " [ 0.07892628  8.535708  ]\n",
      " [ 0.04901226 12.74858   ]\n",
      " [14.203902    0.04503523]\n",
      " [24.371435    0.03959893]\n",
      " [ 0.42392427  1.038668  ]\n",
      " [21.640223    0.03823859]\n",
      " [ 2.5447743   0.24760231]\n",
      " [ 1.5883218   0.35880485]\n",
      " [26.036108    0.03349595]\n",
      " [ 2.2526255   0.26983276]\n",
      " [ 0.04132267 15.274799  ]\n",
      " [ 7.521745    0.09299117]\n",
      " [ 4.355453    0.1602998 ]\n",
      " [ 0.8866865   0.71697694]\n",
      " [ 2.0153441   0.30644295]\n",
      " [ 0.04187963 15.94736   ]\n",
      " [ 0.07200672  8.180032  ]\n",
      " [ 5.8311753   0.09997641]\n",
      " [16.508736    0.04129231]\n",
      " [20.670267    0.03722852]\n",
      " [24.646881    0.03456963]\n",
      " [23.330168    0.04206875]\n",
      " [23.4036      0.03989583]\n",
      " [13.488855    0.04918201]\n",
      " [20.940016    0.03674469]\n",
      " [22.801714    0.03519695]\n",
      " [20.584503    0.0371113 ]\n",
      " [23.92848     0.03528151]\n",
      " [22.788342    0.03771751]\n",
      " [23.973022    0.038784  ]\n",
      " [23.561764    0.03548858]\n",
      " [ 0.48271912  0.7266582 ]\n",
      " [ 0.07355937  6.8307467 ]\n",
      " [ 0.03891671 15.182111  ]\n",
      " [ 0.03627751 18.97948   ]\n",
      " [ 0.0345803  19.819197  ]\n",
      " [ 0.12480992  3.9103618 ]\n",
      " [ 0.03371346 19.587673  ]\n",
      " [ 0.03528772 19.058348  ]\n",
      " [ 0.03700925 15.182082  ]\n",
      " [ 0.03290809 20.164633  ]\n",
      " [ 0.03261247 21.03943   ]\n",
      " [ 0.03316191 19.587833  ]\n",
      " [ 0.03880697 14.242157  ]\n",
      " [ 0.03764524 18.532793  ]\n",
      " [ 0.03483905 18.327799  ]\n",
      " [ 0.03424738 20.070353  ]\n",
      " [ 0.03281379 18.717638  ]]\n",
      "[[0.01125247 0.98874754]\n",
      " [0.00208681 0.99791324]\n",
      " [0.00203778 0.9979623 ]\n",
      " [0.00390958 0.9960904 ]\n",
      " [0.00230225 0.9976977 ]\n",
      " [0.1158206  0.8841794 ]\n",
      " [0.00283043 0.99716955]\n",
      " [0.00413731 0.9958627 ]\n",
      " [0.01928039 0.9807196 ]\n",
      " [0.9266552  0.07334478]\n",
      " [0.8511304  0.14886962]\n",
      " [0.00210631 0.9978937 ]\n",
      " [0.48738155 0.5126185 ]\n",
      " [0.99851286 0.00148719]\n",
      " [0.99818105 0.00181895]\n",
      " [0.99874264 0.0012574 ]\n",
      " [0.9986996  0.00130039]\n",
      " [0.9984075  0.00159253]\n",
      " [0.9986559  0.00134411]\n",
      " [0.9982791  0.00172093]\n",
      " [0.99830246 0.00169754]\n",
      " [0.9981152  0.00188481]\n",
      " [0.9977648  0.00223523]\n",
      " [0.9985902  0.00140982]\n",
      " [0.9985271  0.0014729 ]\n",
      " [0.99768835 0.00231164]\n",
      " [0.00261742 0.9973826 ]\n",
      " [0.00246733 0.99753267]\n",
      " [0.69320035 0.30679965]\n",
      " [0.7739988  0.2260012 ]\n",
      " [0.00197686 0.9980232 ]\n",
      " [0.99811685 0.00188321]\n",
      " [0.88020325 0.11979678]\n",
      " [0.0816004  0.91839963]\n",
      " [0.00187941 0.9981206 ]\n",
      " [0.46758825 0.53241175]\n",
      " [0.00250551 0.9974945 ]\n",
      " [0.04917686 0.9508231 ]\n",
      " [0.00185301 0.998147  ]\n",
      " [0.00516043 0.99483955]\n",
      " [0.0077763  0.99222374]\n",
      " [0.00734458 0.99265546]\n",
      " [0.32370573 0.67629427]\n",
      " [0.9984938  0.0015062 ]\n",
      " [0.9987258  0.00127424]\n",
      " [0.9986976  0.00130243]\n",
      " [0.9984478  0.00155228]\n",
      " [0.9986021  0.0013979 ]\n",
      " [0.99846786 0.00153217]\n",
      " [0.99861294 0.00138705]\n",
      " [0.99848825 0.00151172]\n",
      " [0.99836296 0.00163705]\n",
      " [0.9984945  0.00150551]\n",
      " [0.9976531  0.00234692]\n",
      " [0.00853334 0.9914667 ]\n",
      " [0.00309602 0.996904  ]\n",
      " [0.00432177 0.99567825]\n",
      " [0.00276401 0.997236  ]\n",
      " [0.9870785  0.0129215 ]\n",
      " [0.99706006 0.00293992]\n",
      " [0.9388252  0.06117484]\n",
      " [0.9986194  0.00138064]\n",
      " [0.99854743 0.00145255]\n",
      " [0.9985327  0.00146731]\n",
      " [0.99861985 0.0013801 ]\n",
      " [0.9985969  0.00140307]\n",
      " [0.984237   0.01576295]\n",
      " [0.99853456 0.00146544]\n",
      " [0.99861425 0.00138577]\n",
      " [0.9985841  0.0014159 ]\n",
      " [0.00153243 0.99846756]\n",
      " [0.00225106 0.997749  ]\n",
      " [0.00194189 0.99805814]\n",
      " [0.00247746 0.99752253]\n",
      " [0.00181822 0.99818176]\n",
      " [0.0022133  0.99778664]\n",
      " [0.00225942 0.99774057]\n",
      " [0.00232428 0.9976757 ]\n",
      " [0.00209416 0.9979058 ]\n",
      " [0.00236013 0.99763983]\n",
      " [0.00329191 0.9967081 ]\n",
      " [0.00275791 0.9972421 ]\n",
      " [0.00268723 0.9973127 ]\n",
      " [0.00259979 0.9974002 ]\n",
      " [0.00241935 0.99758065]\n",
      " [0.00346161 0.9965384 ]\n",
      " [0.3141164  0.6858836 ]\n",
      " [0.00325235 0.9967477 ]\n",
      " [0.00246922 0.99753076]\n",
      " [0.00317891 0.9968211 ]\n",
      " [0.00277313 0.99722683]\n",
      " [0.01138918 0.9886108 ]\n",
      " [0.00366133 0.99633867]\n",
      " [0.00458235 0.99541765]\n",
      " [0.0030777  0.9969223 ]\n",
      " [0.00348379 0.9965162 ]\n",
      " [0.6958288  0.30417117]\n",
      " [0.00550947 0.9944905 ]\n",
      " [0.05175181 0.9482482 ]\n",
      " [0.00266536 0.9973346 ]\n",
      " [0.00375712 0.9962429 ]\n",
      " [0.00982237 0.99017763]\n",
      " [0.0079911  0.9920089 ]\n",
      " [0.00888827 0.99111176]\n",
      " [0.00668161 0.9933184 ]\n",
      " [0.03475811 0.9652419 ]\n",
      " [0.00633247 0.99366754]\n",
      " [0.9981345  0.00186556]\n",
      " [0.9987303  0.00126967]\n",
      " [0.9988189  0.00118112]\n",
      " [0.99860746 0.00139252]\n",
      " [0.00821821 0.99178183]\n",
      " [0.9985406  0.00145941]\n",
      " [0.998723   0.00127708]\n",
      " [0.99864966 0.00135037]\n",
      " [0.9987923  0.00120771]\n",
      " [0.99832946 0.00167058]\n",
      " [0.99861425 0.00138578]\n",
      " [0.9972651  0.00273493]\n",
      " [0.9987441  0.0012559 ]\n",
      " [0.9975783  0.00242163]\n",
      " [0.9987404  0.00125964]\n",
      " [0.9931998  0.00680019]\n",
      " [0.9783128  0.02168715]\n",
      " [0.8346716  0.16532832]\n",
      " [0.04094878 0.9590512 ]\n",
      " [0.8202808  0.17971916]\n",
      " [0.91228426 0.08771577]\n",
      " [0.13789476 0.8621052 ]\n",
      " [0.7778149  0.22218512]\n",
      " [0.9703691  0.02963093]\n",
      " [0.00911248 0.9908876 ]\n",
      " [0.12386598 0.87613404]\n",
      " [0.04459733 0.9554027 ]\n",
      " [0.01584828 0.9841517 ]\n",
      " [0.02054326 0.9794568 ]\n",
      " [0.02990597 0.9700941 ]\n",
      " [0.6575715  0.34242848]\n",
      " [0.9405326  0.05946739]\n",
      " [0.75878245 0.24121758]\n",
      " [0.98042566 0.01957437]\n",
      " [0.00569092 0.99430907]\n",
      " [0.1586169  0.8413831 ]\n",
      " [0.8479094  0.15209062]\n",
      " [0.7759069  0.22409308]\n",
      " [0.05977305 0.940227  ]\n",
      " [0.01144477 0.9885552 ]\n",
      " [0.00417829 0.9958217 ]\n",
      " [0.95715624 0.04284378]\n",
      " [0.84873503 0.15126495]\n",
      " [0.04636266 0.9536373 ]\n",
      " [0.99647444 0.00352557]\n",
      " [0.9836579  0.01634211]\n",
      " [0.9980182  0.00198181]\n",
      " [0.5955236  0.40447646]\n",
      " [0.96393996 0.03606004]\n",
      " [0.97780174 0.02219826]\n",
      " [0.18163262 0.8183674 ]\n",
      " [0.9923981  0.00760195]\n",
      " [0.9948898  0.00511017]\n",
      " [0.9011548  0.0988452 ]\n",
      " [0.9237884  0.07621157]\n",
      " [0.24795696 0.752043  ]\n",
      " [0.9927734  0.00722663]\n",
      " [0.9954205  0.00457949]\n",
      " [0.9875331  0.01246687]\n",
      " [0.8674046  0.1325954 ]\n",
      " [0.99818087 0.00181916]\n",
      " [0.86204064 0.13795939]\n",
      " [0.9932133  0.00678672]\n",
      " [0.9937149  0.00628511]\n",
      " [0.9962722  0.00372783]\n",
      " [0.9954371  0.00456287]\n",
      " [0.00678197 0.99321806]\n",
      " [0.01157202 0.988428  ]\n",
      " [0.99813884 0.00186117]\n",
      " [0.9985694  0.00143058]\n",
      " [0.9966665  0.00333351]\n",
      " [0.9976419  0.00235806]\n",
      " [0.9938954  0.0061046 ]\n",
      " [0.99765164 0.00234837]\n",
      " [0.9985445  0.00145548]\n",
      " [0.99816793 0.00183202]\n",
      " [0.99864316 0.00135683]\n",
      " [0.9982751  0.00172491]\n",
      " [0.9984786  0.00152144]\n",
      " [0.9985199  0.00148014]\n",
      " [0.9987094  0.00129065]\n",
      " [0.9978457  0.00215431]\n",
      " [0.00687835 0.9931216 ]\n",
      " [0.00719047 0.99280953]\n",
      " [0.9985121  0.00148789]\n",
      " [0.99841356 0.00158643]\n",
      " [0.9986816  0.00131839]\n",
      " [0.998506   0.00149398]\n",
      " [0.99869573 0.00130426]\n",
      " [0.9982519  0.00174805]\n",
      " [0.99835354 0.0016464 ]\n",
      " [0.9985679  0.00143212]\n",
      " [0.9980778  0.00192224]\n",
      " [0.99855864 0.00144139]\n",
      " [0.99742806 0.00257197]\n",
      " [0.01188622 0.98811376]\n",
      " [0.01012742 0.98987263]\n",
      " [0.01216355 0.9878364 ]\n",
      " [0.9984604  0.00153955]\n",
      " [0.9983287  0.00167132]\n",
      " [0.9984254  0.00157458]\n",
      " [0.9985632  0.00143678]\n",
      " [0.9984545  0.00154544]\n",
      " [0.99851924 0.00148077]\n",
      " [0.99829    0.00170998]\n",
      " [0.9984916  0.00150843]\n",
      " [0.9985086  0.00149142]\n",
      " [0.9985596  0.00144042]\n",
      " [0.99822843 0.00177154]\n",
      " [0.9985379  0.0014621 ]\n",
      " [0.99457335 0.00542663]\n",
      " [0.99837303 0.00162695]\n",
      " [0.99783653 0.00216348]\n",
      " [0.00281626 0.99718374]\n",
      " [0.98127127 0.01872876]\n",
      " [0.9903066  0.0096934 ]\n",
      " [0.9968091  0.00319084]\n",
      " [0.14400761 0.8559924 ]\n",
      " [0.96028864 0.03971141]\n",
      " [0.99840534 0.00159467]\n",
      " [0.98971057 0.01028938]\n",
      " [0.01456476 0.98543525]\n",
      " [0.04952179 0.9504782 ]\n",
      " [0.5964227  0.4035773 ]\n",
      " [0.99636173 0.00363828]\n",
      " [0.9982266  0.00177338]\n",
      " [0.99680394 0.00319603]\n",
      " [0.99781704 0.00218298]\n",
      " [0.91323656 0.08676345]\n",
      " [0.989976   0.010024  ]\n",
      " [0.9787545  0.02124542]\n",
      " [0.9984846  0.00151536]\n",
      " [0.9972722  0.00272778]\n",
      " [0.99856967 0.00143032]\n",
      " [0.9985565  0.00144355]\n",
      " [0.99391645 0.00608356]\n",
      " [0.9983869  0.00161304]\n",
      " [0.9969169  0.00308311]\n",
      " [0.99828446 0.00171553]\n",
      " [0.9978379  0.00216216]\n",
      " [0.9983894  0.0016106 ]\n",
      " [0.4392524  0.5607476 ]\n",
      " [0.00638776 0.99361223]\n",
      " [0.00848321 0.99151677]\n",
      " [0.00293126 0.99706876]\n",
      " [0.00708888 0.99291116]\n",
      " [0.00570759 0.9942924 ]\n",
      " [0.00677525 0.99322474]\n",
      " [0.00349553 0.9965045 ]\n",
      " [0.00436671 0.99563324]\n",
      " [0.00787513 0.9921249 ]\n",
      " [0.00313564 0.9968644 ]\n",
      " [0.9966839  0.0033161 ]\n",
      " [0.97729623 0.02270374]\n",
      " [0.00528661 0.99471337]\n",
      " [0.00270523 0.9972947 ]\n",
      " [0.00233431 0.9976657 ]\n",
      " [0.00367276 0.9963272 ]\n",
      " [0.97435695 0.02564304]\n",
      " [0.00249521 0.9975048 ]\n",
      " [0.00218195 0.99781805]\n",
      " [0.00244924 0.9975508 ]\n",
      " [0.00208251 0.9979175 ]\n",
      " [0.00219777 0.9978022 ]\n",
      " [0.00195202 0.99804795]\n",
      " [0.00219528 0.9978047 ]\n",
      " [0.00203399 0.997966  ]\n",
      " [0.00201749 0.9979825 ]\n",
      " [0.00241812 0.9975819 ]\n",
      " [0.00408424 0.9959157 ]\n",
      " [0.17845534 0.82154465]\n",
      " [0.01595981 0.98404014]\n",
      " [0.99217695 0.00782302]\n",
      " [0.9476372  0.05236283]\n",
      " [0.07089933 0.9291007 ]\n",
      " [0.61960614 0.3803939 ]\n",
      " [0.19771262 0.8022874 ]\n",
      " [0.00460552 0.99539447]\n",
      " [0.9858813  0.01411864]\n",
      " [0.7388215  0.26117843]\n",
      " [0.08448015 0.91551983]\n",
      " [0.99781775 0.00218229]\n",
      " [0.8471498  0.15285024]\n",
      " [0.97077715 0.02922285]\n",
      " [0.9919531  0.00804695]\n",
      " [0.96330106 0.0366989 ]\n",
      " [0.99727243 0.00272755]\n",
      " [0.9965979  0.00340217]\n",
      " [0.99713326 0.00286677]\n",
      " [0.9932545  0.00674545]\n",
      " [0.81525177 0.18474823]\n",
      " [0.99707294 0.00292712]\n",
      " [0.9907452  0.00925479]\n",
      " [0.9976865  0.00231347]\n",
      " [0.00760523 0.99239475]\n",
      " [0.02270541 0.97729456]\n",
      " [0.99671775 0.0032823 ]\n",
      " [0.18139024 0.8186098 ]\n",
      " [0.12552775 0.8744723 ]\n",
      " [0.00395827 0.9960417 ]\n",
      " [0.00703664 0.9929633 ]\n",
      " [0.00575912 0.99424094]\n",
      " [0.89212626 0.10787375]\n",
      " [0.99857724 0.00142276]\n",
      " [0.99863124 0.00136871]\n",
      " [0.99851614 0.00148386]\n",
      " [0.99856055 0.00143946]\n",
      " [0.9986116  0.0013884 ]\n",
      " [0.9985799  0.00142009]\n",
      " [0.998433   0.00156698]\n",
      " [0.9983438  0.00165613]\n",
      " [0.9982938  0.0017062 ]\n",
      " [0.9986489  0.00135113]\n",
      " [0.9985657  0.00143426]\n",
      " [0.29959005 0.70040995]\n",
      " [0.00354391 0.9964561 ]\n",
      " [0.9812075  0.01879253]\n",
      " [0.00739977 0.99260026]\n",
      " [0.00280617 0.9971939 ]\n",
      " [0.0048889  0.9951111 ]\n",
      " [0.20564917 0.7943508 ]\n",
      " [0.00349782 0.99650216]\n",
      " [0.00379743 0.9962025 ]\n",
      " [0.00369448 0.9963055 ]\n",
      " [0.00388682 0.9961132 ]\n",
      " [0.01051328 0.9894867 ]\n",
      " [0.00393924 0.9960607 ]\n",
      " [0.00744831 0.9925517 ]\n",
      " [0.02818827 0.97181165]\n",
      " [0.02120791 0.97879213]\n",
      " [0.98715127 0.01284877]\n",
      " [0.00555508 0.9944449 ]\n",
      " [0.9982918  0.00170822]\n",
      " [0.99855256 0.00144742]\n",
      " [0.99849486 0.00150514]\n",
      " [0.997553   0.00244702]\n",
      " [0.9985349  0.00146505]\n",
      " [0.9980942  0.00190575]\n",
      " [0.99805766 0.00194233]\n",
      " [0.99850297 0.00149701]\n",
      " [0.99847543 0.00152461]\n",
      " [0.9985644  0.00143558]\n",
      " [0.99834394 0.00165604]\n",
      " [0.09929624 0.9007038 ]\n",
      " [0.99845684 0.00154313]\n",
      " [0.99860567 0.00139431]\n",
      " [0.9985602  0.00143986]\n",
      " [0.9981219  0.00187809]\n",
      " [0.9980719  0.00192809]\n",
      " [0.00224961 0.9977504 ]\n",
      " [0.00278189 0.99721813]\n",
      " [0.00266231 0.9973377 ]\n",
      " [0.00381583 0.9961842 ]\n",
      " [0.00327465 0.9967254 ]\n",
      " [0.00222586 0.9977741 ]\n",
      " [0.0175593  0.9824407 ]\n",
      " [0.0022907  0.9977093 ]\n",
      " [0.00277232 0.99722767]\n",
      " [0.00200442 0.9979956 ]\n",
      " [0.00236279 0.99763715]\n",
      " [0.00267164 0.99732834]\n",
      " [0.00273265 0.99726737]\n",
      " [0.00236523 0.99763477]\n",
      " [0.00256629 0.9974337 ]\n",
      " [0.00190917 0.9980908 ]\n",
      " [0.00300611 0.9969939 ]\n",
      " [0.00231073 0.99768925]\n",
      " [0.00153473 0.99846524]\n",
      " [0.00198437 0.99801564]\n",
      " [0.00249752 0.9975025 ]\n",
      " [0.00201237 0.9979876 ]\n",
      " [0.00347492 0.99652505]\n",
      " [0.00179549 0.9982045 ]\n",
      " [0.00159176 0.99840826]\n",
      " [0.00272151 0.9972785 ]\n",
      " [0.00389059 0.99610937]\n",
      " [0.00345642 0.9965436 ]\n",
      " [0.00159626 0.9984037 ]\n",
      " [0.00174787 0.99825215]\n",
      " [0.41401276 0.58598727]\n",
      " [0.00250157 0.99749845]\n",
      " [0.00451617 0.9954839 ]\n",
      " [0.0033224  0.99667764]\n",
      " [0.00316027 0.9968397 ]\n",
      " [0.5018958  0.49810424]\n",
      " [0.00358009 0.9964199 ]\n",
      " [0.00276772 0.99723226]\n",
      " [0.00393341 0.9960666 ]\n",
      " [0.00266557 0.9973344 ]\n",
      " [0.00357682 0.9964232 ]\n",
      " [0.00614935 0.99385065]\n",
      " [0.00362511 0.9963749 ]\n",
      " [0.00329761 0.9967024 ]\n",
      " [0.00290719 0.99709284]\n",
      " [0.00211213 0.9978879 ]\n",
      " [0.00311851 0.9968815 ]\n",
      " [0.00508566 0.99491435]\n",
      " [0.00299988 0.99700016]\n",
      " [0.00290915 0.9970908 ]\n",
      " [0.00341481 0.9965852 ]\n",
      " [0.00319346 0.9968065 ]\n",
      " [0.00398577 0.99601424]\n",
      " [0.00212672 0.9978733 ]\n",
      " [0.00265852 0.9973415 ]\n",
      " [0.00450238 0.99549764]\n",
      " [0.0021637  0.99783635]\n",
      " [0.00311838 0.9968816 ]\n",
      " [0.19639717 0.8036029 ]\n",
      " [0.00790992 0.99209005]\n",
      " [0.00297437 0.99702567]\n",
      " [0.00227223 0.9977278 ]\n",
      " [0.00238103 0.997619  ]\n",
      " [0.00310447 0.99689555]\n",
      " [0.00291213 0.99708784]\n",
      " [0.00234682 0.9976532 ]\n",
      " [0.00205914 0.99794084]\n",
      " [0.00164829 0.99835175]\n",
      " [0.9986784  0.0013216 ]\n",
      " [0.9986197  0.00138038]\n",
      " [0.99572253 0.00427747]\n",
      " [0.9979584  0.00204163]\n",
      " [0.9983296  0.00167043]\n",
      " [0.9978386  0.0021614 ]\n",
      " [0.99814224 0.00185781]\n",
      " [0.00278017 0.9972198 ]\n",
      " [0.00555652 0.9944435 ]\n",
      " [0.00574131 0.99425864]\n",
      " [0.00712637 0.9928736 ]\n",
      " [0.00916188 0.9908381 ]\n",
      " [0.0038298  0.9961702 ]\n",
      " [0.9968394  0.0031606 ]\n",
      " [0.99837786 0.00162217]\n",
      " [0.28984445 0.71015555]\n",
      " [0.9982361  0.0017639 ]\n",
      " [0.9113292  0.08867082]\n",
      " [0.815726   0.18427402]\n",
      " [0.9987151  0.00128487]\n",
      " [0.89302784 0.10697214]\n",
      " [0.00269799 0.997302  ]\n",
      " [0.98778796 0.012212  ]\n",
      " [0.9645021  0.03549791]\n",
      " [0.55291307 0.4470869 ]\n",
      " [0.86801416 0.13198581]\n",
      " [0.00261924 0.99738073]\n",
      " [0.00872593 0.991274  ]\n",
      " [0.9831438  0.01685615]\n",
      " [0.997505   0.002495  ]\n",
      " [0.9982022  0.00179783]\n",
      " [0.9985994  0.00140063]\n",
      " [0.99820006 0.00179995]\n",
      " [0.9982982  0.00170179]\n",
      " [0.99636716 0.00363288]\n",
      " [0.9982483  0.00175169]\n",
      " [0.9984588  0.00154123]\n",
      " [0.99820036 0.00179963]\n",
      " [0.9985277  0.00147229]\n",
      " [0.9983476  0.00165239]\n",
      " [0.9983848  0.00161521]\n",
      " [0.9984961  0.00150393]\n",
      " [0.39914685 0.6008532 ]\n",
      " [0.01065413 0.9893459 ]\n",
      " [0.00255677 0.99744326]\n",
      " [0.00190776 0.99809223]\n",
      " [0.00174175 0.99825823]\n",
      " [0.03093051 0.96906954]\n",
      " [0.0017182  0.9982818 ]\n",
      " [0.00184814 0.99815184]\n",
      " [0.00243176 0.99756825]\n",
      " [0.00162931 0.9983707 ]\n",
      " [0.00154767 0.99845237]\n",
      " [0.00169012 0.9983099 ]\n",
      " [0.00271739 0.9972826 ]\n",
      " [0.00202716 0.99797285]\n",
      " [0.00189728 0.99810266]\n",
      " [0.00170346 0.99829656]\n",
      " [0.00175003 0.99824995]]\n",
      "12/20/2021 21:41:02 - INFO - __main__ -   ***** Test results None *****\n",
      "100%|███████████████████████████████████████████| 61/61 [00:01<00:00, 42.12it/s]\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/ZeroShot/1' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/1/eval-eval/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train_en_2.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev_en_2.csv \\\n",
    "      --test_file Data/ZeroShot/eval_en_2.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 21:41:05 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 21:41:05 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/2/eval-eval/runs/Dec20_21-41-05_r18g08.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/2/eval-eval/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/2/eval-eval/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 21:41:05 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_ot_2.csv\n",
      "12/20/2021 21:41:05 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev_ot_2.csv\n",
      "12/20/2021 21:41:05 - INFO - __main__ -   load a local file for test: Data/ZeroShot/eval_ot_2.csv\n",
      "12/20/2021 21:41:06 - WARNING - datasets.builder -   Using custom data configuration default-b594c0df89ec05d2\n",
      "12/20/2021 21:41:06 - WARNING - datasets.builder -   Reusing dataset csv (/users/sitkonen/.cache/huggingface/datasets/csv/default-b594c0df89ec05d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 18.67it/s]\n",
      "[INFO|configuration_utils.py:586] 2021-12-20 21:41:06,459 >> loading configuration file models/ZeroShot/2/config.json\n",
      "[INFO|configuration_utils.py:625] 2021-12-20 21:41:06,459 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 21:41:06,467 >> Didn't find file models/ZeroShot/2/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:41:06,467 >> loading file models/ZeroShot/2/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:41:06,467 >> loading file models/ZeroShot/2/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:41:06,467 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:41:06,467 >> loading file models/ZeroShot/2/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 21:41:06,467 >> loading file models/ZeroShot/2/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1338] 2021-12-20 21:41:06,578 >> loading weights file models/ZeroShot/2/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1607] 2021-12-20 21:41:08,051 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[INFO|modeling_utils.py:1616] 2021-12-20 21:41:08,051 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/ZeroShot/2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "12/20/2021 21:41:08 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-b594c0df89ec05d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-f5e478bc919a0df5.arrow\n",
      "12/20/2021 21:41:08 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-b594c0df89ec05d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-968e3e931ce7959e.arrow\n",
      "12/20/2021 21:41:08 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /users/sitkonen/.cache/huggingface/datasets/csv/default-b594c0df89ec05d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-900d6abc66734618.arrow\n",
      "12/20/2021 21:41:12 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2021-12-20 21:41:12,017 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:41:12,019 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:41:12,019 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:41:12,019 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 46.17it/s]\n",
      "***** eval metrics *****\n",
      "  eval_accuracy           =      0.652\n",
      "  eval_f1                 =     0.5902\n",
      "  eval_loss               =     2.1115\n",
      "  eval_runtime            = 0:00:00.80\n",
      "  eval_samples            =        273\n",
      "  eval_samples_per_second =    340.409\n",
      "  eval_steps_per_second   =     43.642\n",
      "12/20/2021 21:41:12 - INFO - __main__ -   *** Test ***\n",
      "AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
      "  test_dataset.remove_columns_(\"label\")\n",
      "[INFO|trainer.py:541] 2021-12-20 21:41:12,866 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2021-12-20 21:41:12,868 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2245] 2021-12-20 21:41:12,868 >>   Num examples = 279\n",
      "[INFO|trainer.py:2248] 2021-12-20 21:41:12,868 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 44.99it/s][[ 0.088851    9.85703   ]\n",
      " [ 0.09686813  9.181072  ]\n",
      " [ 0.10364644  8.469546  ]\n",
      " [ 0.09781776  9.121981  ]\n",
      " [ 0.09691611  9.234986  ]\n",
      " [ 0.09767791  9.295756  ]\n",
      " [ 0.09902405  9.095046  ]\n",
      " [ 0.09523509  9.287799  ]\n",
      " [ 0.3866404   2.7441807 ]\n",
      " [16.013222    0.06169273]\n",
      " [ 0.1558812   5.9184656 ]\n",
      " [11.786088    0.07373758]\n",
      " [ 0.73161906  1.2962723 ]\n",
      " [ 0.24791919  3.5858786 ]\n",
      " [ 0.16451047  5.5952106 ]\n",
      " [ 0.13085127  6.6514907 ]\n",
      " [28.531548    0.03196837]\n",
      " [27.107452    0.03561869]\n",
      " [ 0.12244158  7.2485657 ]\n",
      " [25.498724    0.0359501 ]\n",
      " [ 0.14280783  6.498461  ]\n",
      " [ 1.79998     0.5891649 ]\n",
      " [ 0.16112423  5.4354815 ]\n",
      " [27.598259    0.03433438]\n",
      " [25.077858    0.03742473]\n",
      " [28.611197    0.03374056]\n",
      " [27.451338    0.03803958]\n",
      " [27.615253    0.03625053]\n",
      " [28.701849    0.0353503 ]\n",
      " [28.891539    0.03552737]\n",
      " [23.064615    0.04005203]\n",
      " [26.726467    0.03430425]\n",
      " [28.538387    0.03443811]\n",
      " [25.919853    0.03867893]\n",
      " [24.54621     0.03777959]\n",
      " [29.382254    0.03429462]\n",
      " [26.319338    0.04024617]\n",
      " [26.825262    0.03587852]\n",
      " [25.051003    0.03935609]\n",
      " [ 3.5877373   0.26358044]\n",
      " [ 0.14499052  6.457005  ]\n",
      " [ 0.11271292  7.866271  ]\n",
      " [26.514944    0.03594058]\n",
      " [23.6939      0.04262623]\n",
      " [26.318705    0.03879894]\n",
      " [27.707779    0.03538388]\n",
      " [22.052946    0.04676561]\n",
      " [29.155499    0.03427432]\n",
      " [20.743341    0.04616618]\n",
      " [23.129725    0.0421067 ]\n",
      " [27.540688    0.03384753]\n",
      " [27.087208    0.03648826]\n",
      " [ 0.10369796  8.74402   ]\n",
      " [ 0.09927577  9.052665  ]\n",
      " [ 0.09649825  9.449033  ]\n",
      " [ 0.09064717  9.6933565 ]\n",
      " [ 0.09181464  9.757943  ]\n",
      " [ 0.09388638  9.492313  ]\n",
      " [ 0.09226783  9.6258955 ]\n",
      " [ 0.08877773 10.06377   ]\n",
      " [ 0.09969757  9.178973  ]\n",
      " [ 0.08554695 10.358507  ]\n",
      " [ 0.08799299 10.498243  ]\n",
      " [ 0.09204407  9.483017  ]\n",
      " [ 0.09459659  9.603393  ]\n",
      " [ 0.08964135  9.846786  ]\n",
      " [ 0.08604229 10.539562  ]\n",
      " [ 0.10892821  8.038349  ]\n",
      " [26.525927    0.03584449]\n",
      " [27.085953    0.03630042]\n",
      " [26.601814    0.03757325]\n",
      " [25.931015    0.03728492]\n",
      " [28.455425    0.03479089]\n",
      " [28.662909    0.03553962]\n",
      " [26.251675    0.0380372 ]\n",
      " [26.31337     0.03902875]\n",
      " [27.060186    0.0370853 ]\n",
      " [27.974512    0.03566262]\n",
      " [23.15175     0.04019997]\n",
      " [28.0407      0.03472069]\n",
      " [28.128752    0.03718158]\n",
      " [28.82392     0.03587197]\n",
      " [27.52654     0.03692565]\n",
      " [27.293646    0.03556237]\n",
      " [27.665163    0.03436842]\n",
      " [28.7938      0.03706759]\n",
      " [27.514313    0.0358826 ]\n",
      " [24.68782     0.03956451]\n",
      " [26.531816    0.03610376]\n",
      " [27.552183    0.03838194]\n",
      " [27.605364    0.03673221]\n",
      " [26.506723    0.03972668]\n",
      " [24.723133    0.04406489]\n",
      " [26.46257     0.04173629]\n",
      " [23.301796    0.04562134]\n",
      " [ 0.10380357  8.508329  ]\n",
      " [25.58242     0.04193074]\n",
      " [23.804998    0.04293546]\n",
      " [23.417633    0.04404137]\n",
      " [24.424124    0.04328053]\n",
      " [25.78276     0.04208428]\n",
      " [25.854904    0.0406629 ]\n",
      " [25.137241    0.04065451]\n",
      " [26.718462    0.03923948]\n",
      " [27.49348     0.03718545]\n",
      " [27.856476    0.03629107]\n",
      " [27.956408    0.04027687]\n",
      " [26.595276    0.0382722 ]\n",
      " [27.976833    0.03746023]\n",
      " [ 0.09533834  9.390582  ]\n",
      " [27.231157    0.0359365 ]\n",
      " [26.124868    0.04088756]\n",
      " [25.875587    0.03929202]\n",
      " [23.522228    0.04328629]\n",
      " [25.700386    0.03649563]\n",
      " [24.330019    0.03874331]\n",
      " [23.984024    0.04216326]\n",
      " [25.193665    0.03798065]\n",
      " [21.702549    0.0463765 ]\n",
      " [26.266123    0.03644803]\n",
      " [22.43768     0.04569398]\n",
      " [19.113558    0.05281923]\n",
      " [25.653559    0.03700716]\n",
      " [25.552265    0.04065504]\n",
      " [22.822294    0.04725389]\n",
      " [ 0.1116779   7.794181  ]\n",
      " [ 0.11302379  7.9110627 ]\n",
      " [ 5.7803636   0.21872732]\n",
      " [ 0.11820739  7.518787  ]\n",
      " [19.211664    0.05404027]\n",
      " [16.595884    0.05902302]\n",
      " [ 0.10974483  8.038472  ]\n",
      " [ 0.11524455  7.761373  ]\n",
      " [ 0.11531473  7.6984544 ]\n",
      " [ 0.14434344  6.7368364 ]\n",
      " [ 0.13130488  6.8441877 ]\n",
      " [27.945665    0.03437108]\n",
      " [27.283571    0.0350599 ]\n",
      " [26.35547     0.0354426 ]\n",
      " [26.910812    0.03582854]\n",
      " [29.873549    0.03432312]\n",
      " [26.205837    0.03751712]\n",
      " [29.76213     0.0336053 ]\n",
      " [18.473316    0.06484678]\n",
      " [ 4.9121876   0.38627508]\n",
      " [21.918936    0.05513222]\n",
      " [ 0.37304813  3.3145661 ]\n",
      " [28.93145     0.03354136]\n",
      " [29.943672    0.03744393]\n",
      " [26.091719    0.03812386]\n",
      " [28.648657    0.03617394]\n",
      " [29.527634    0.03473694]\n",
      " [28.254679    0.03612769]\n",
      " [29.83686     0.03717921]\n",
      " [29.538845    0.03732255]\n",
      " [27.287685    0.04039785]\n",
      " [ 0.12253219  7.182175  ]\n",
      " [25.54654     0.04012407]\n",
      " [30.416723    0.0350999 ]\n",
      " [27.973356    0.03605102]\n",
      " [28.309896    0.03460154]\n",
      " [30.52047     0.03329868]\n",
      " [26.751108    0.04036077]\n",
      " [27.99673     0.03694559]\n",
      " [27.561878    0.0367013 ]\n",
      " [28.805582    0.03518007]\n",
      " [26.589787    0.03983877]\n",
      " [22.936417    0.04814674]\n",
      " [29.304304    0.03725088]\n",
      " [28.8262      0.03717176]\n",
      " [26.109978    0.0413135 ]\n",
      " [27.758223    0.04208282]\n",
      " [24.91332     0.04322995]\n",
      " [26.672752    0.03958547]\n",
      " [24.162413    0.04319464]\n",
      " [28.989717    0.03694019]\n",
      " [23.908417    0.04381166]\n",
      " [24.501955    0.04250888]\n",
      " [27.452084    0.03783185]\n",
      " [ 0.10975545  8.142406  ]\n",
      " [ 0.11387467  7.8773537 ]\n",
      " [14.301356    0.08638597]\n",
      " [20.371775    0.05053931]\n",
      " [28.177145    0.03820305]\n",
      " [28.400614    0.0353667 ]\n",
      " [29.979548    0.03489549]\n",
      " [29.168827    0.03601261]\n",
      " [28.071556    0.03670975]\n",
      " [29.191944    0.03772077]\n",
      " [26.997416    0.04144653]\n",
      " [27.888706    0.03682421]\n",
      " [29.508059    0.03488976]\n",
      " [25.285011    0.04006076]\n",
      " [27.838505    0.03824938]\n",
      " [30.427458    0.03628089]\n",
      " [22.896646    0.04486144]\n",
      " [27.193811    0.03604962]\n",
      " [30.05568     0.03613568]\n",
      " [28.23829     0.03483935]\n",
      " [28.364138    0.03538837]\n",
      " [24.002718    0.03965203]\n",
      " [16.923943    0.06578819]\n",
      " [14.738471    0.07723374]\n",
      " [16.063238    0.07094919]\n",
      " [ 0.12804611  7.323516  ]\n",
      " [19.451422    0.05693662]\n",
      " [24.79169     0.0428312 ]\n",
      " [26.966942    0.0378802 ]\n",
      " [ 0.09905934  8.999996  ]\n",
      " [ 5.1954246   0.28270897]\n",
      " [ 5.1032195   0.2950909 ]\n",
      " [14.817686    0.08128933]\n",
      " [24.343155    0.03996111]\n",
      " [23.23795     0.04264356]\n",
      " [23.373045    0.0436567 ]\n",
      " [17.833578    0.07115227]\n",
      " [16.693502    0.060674  ]\n",
      " [ 8.642351    0.18574497]\n",
      " [12.417865    0.10427792]\n",
      " [23.811823    0.04150631]\n",
      " [ 6.5905395   0.24343151]\n",
      " [11.667093    0.1296334 ]\n",
      " [ 0.24112315  4.6624613 ]\n",
      " [27.013704    0.03455873]\n",
      " [25.31788     0.03700897]\n",
      " [21.176529    0.04549937]\n",
      " [ 0.12163787  7.4900594 ]\n",
      " [29.26982     0.03503589]\n",
      " [25.25391     0.03710943]\n",
      " [27.773085    0.03504808]\n",
      " [26.208141    0.03678973]\n",
      " [25.404114    0.03981625]\n",
      " [27.324673    0.03591846]\n",
      " [28.713337    0.03412693]\n",
      " [26.769016    0.03718664]\n",
      " [27.008661    0.03557255]\n",
      " [ 0.12907119  6.829149  ]\n",
      " [ 0.12798378  7.079746  ]\n",
      " [22.830763    0.05401568]\n",
      " [29.88594     0.03771583]\n",
      " [25.508951    0.04647358]\n",
      " [25.979284    0.04372882]\n",
      " [27.714182    0.03694523]\n",
      " [27.678812    0.04091226]\n",
      " [14.60568     0.09254225]\n",
      " [28.658577    0.03853313]\n",
      " [26.172026    0.04049287]\n",
      " [28.161335    0.03863961]\n",
      " [27.58716     0.0386274 ]\n",
      " [22.916756    0.04444429]\n",
      " [22.792023    0.05263143]\n",
      " [15.948478    0.08896644]\n",
      " [21.355928    0.04996939]\n",
      " [13.656262    0.09633966]\n",
      " [27.811192    0.03538998]\n",
      " [27.916578    0.03276139]\n",
      " [27.053581    0.03512169]\n",
      " [26.147976    0.03646765]\n",
      " [26.887758    0.03621773]\n",
      " [26.603146    0.03661601]\n",
      " [26.039528    0.03498622]\n",
      " [28.430761    0.03494945]\n",
      " [26.750782    0.0356791 ]\n",
      " [27.848528    0.03588324]\n",
      " [29.489103    0.03440106]\n",
      " [28.83271     0.03568348]\n",
      " [29.429781    0.03413193]\n",
      " [27.36028     0.03648318]\n",
      " [27.960575    0.03665004]\n",
      " [29.260242    0.03445939]\n",
      " [29.11961     0.0356134 ]\n",
      " [29.998793    0.03721501]\n",
      " [14.071621    0.06386975]\n",
      " [27.203852    0.04084421]\n",
      " [27.77257     0.03446116]\n",
      " [28.585295    0.03519735]\n",
      " [29.457052    0.03428602]\n",
      " [31.562769    0.03453834]\n",
      " [29.21643     0.03380806]]\n",
      "[[0.00893345 0.9910666 ]\n",
      " [0.01044069 0.9895593 ]\n",
      " [0.0120896  0.98791045]\n",
      " [0.01060953 0.9893905 ]\n",
      " [0.01038546 0.98961455]\n",
      " [0.01039853 0.98960143]\n",
      " [0.01077043 0.9892296 ]\n",
      " [0.01014971 0.9898503 ]\n",
      " [0.12349489 0.87650514]\n",
      " [0.9961621  0.00383783]\n",
      " [0.02566222 0.97433776]\n",
      " [0.99378264 0.00621743]\n",
      " [0.3607782  0.6392217 ]\n",
      " [0.06466674 0.9353333 ]\n",
      " [0.02856223 0.9714378 ]\n",
      " [0.01929293 0.98070705]\n",
      " [0.99888074 0.0011192 ]\n",
      " [0.9986878  0.00131226]\n",
      " [0.01661124 0.9833887 ]\n",
      " [0.99859214 0.00140789]\n",
      " [0.02150309 0.9784969 ]\n",
      " [0.75339925 0.24660075]\n",
      " [0.02878963 0.97121036]\n",
      " [0.9987575  0.00124253]\n",
      " [0.9985099  0.00149012]\n",
      " [0.9988221  0.00117789]\n",
      " [0.99861616 0.00138379]\n",
      " [0.998689   0.00131098]\n",
      " [0.9987699  0.00123012]\n",
      " [0.9987718  0.00122817]\n",
      " [0.99826646 0.0017335 ]\n",
      " [0.99871814 0.00128189]\n",
      " [0.99879473 0.00120528]\n",
      " [0.99850994 0.00149003]\n",
      " [0.9984633  0.00153676]\n",
      " [0.9988342  0.00116583]\n",
      " [0.99847317 0.00152681]\n",
      " [0.99866426 0.0013357 ]\n",
      " [0.99843144 0.00156857]\n",
      " [0.93156093 0.06843902]\n",
      " [0.02196162 0.9780384 ]\n",
      " [0.01412622 0.98587376]\n",
      " [0.9986464  0.00135365]\n",
      " [0.99820423 0.00179581]\n",
      " [0.99852794 0.00147203]\n",
      " [0.99872464 0.00127541]\n",
      " [0.99788386 0.00211612]\n",
      " [0.9988258  0.00117419]\n",
      " [0.99777937 0.00222065]\n",
      " [0.99818283 0.00181715]\n",
      " [0.9987725  0.00122749]\n",
      " [0.9986548  0.00134525]\n",
      " [0.01172031 0.9882797 ]\n",
      " [0.01084751 0.9891525 ]\n",
      " [0.01010926 0.9898907 ]\n",
      " [0.00926483 0.99073523]\n",
      " [0.00932151 0.9906784 ]\n",
      " [0.00979391 0.99020606]\n",
      " [0.00949437 0.99050564]\n",
      " [0.00874438 0.99125564]\n",
      " [0.01074481 0.98925525]\n",
      " [0.00819097 0.99180907]\n",
      " [0.00831202 0.991688  ]\n",
      " [0.0096129  0.99038714]\n",
      " [0.00975425 0.9902457 ]\n",
      " [0.00902149 0.9909785 ]\n",
      " [0.00809764 0.99190235]\n",
      " [0.01336989 0.98663   ]\n",
      " [0.9986505  0.00134948]\n",
      " [0.9986616  0.0013384 ]\n",
      " [0.9985896  0.00141044]\n",
      " [0.99856424 0.00143579]\n",
      " [0.9987789  0.00122115]\n",
      " [0.9987616  0.00123838]\n",
      " [0.99855316 0.00144685]\n",
      " [0.998519   0.00148103]\n",
      " [0.9986314  0.0013686 ]\n",
      " [0.99872684 0.0012732 ]\n",
      " [0.9982667  0.00173336]\n",
      " [0.99876326 0.00123669]\n",
      " [0.9986799  0.00132009]\n",
      " [0.99875706 0.00124297]\n",
      " [0.9986603  0.00133966]\n",
      " [0.9986987  0.00130126]\n",
      " [0.9987592  0.00124076]\n",
      " [0.9987143  0.00128569]\n",
      " [0.9986975  0.00130244]\n",
      " [0.9984     0.00160003]\n",
      " [0.9986411  0.00135892]\n",
      " [0.9986089  0.00139113]\n",
      " [0.9986712  0.00132885]\n",
      " [0.9985035  0.0014965 ]\n",
      " [0.9982208  0.00177916]\n",
      " [0.9984253  0.0015747 ]\n",
      " [0.998046   0.00195402]\n",
      " [0.01205318 0.9879468 ]\n",
      " [0.9983636  0.00163636]\n",
      " [0.9981996  0.00180038]\n",
      " [0.9981229  0.00187716]\n",
      " [0.9982311  0.00176891]\n",
      " [0.9983704  0.0016296 ]\n",
      " [0.9984297  0.00157026]\n",
      " [0.9983853  0.00161469]\n",
      " [0.9985335  0.00146647]\n",
      " [0.9986493  0.00135069]\n",
      " [0.9986989  0.00130109]\n",
      " [0.9985613  0.00143863]\n",
      " [0.998563   0.00143699]\n",
      " [0.9986628  0.00133718]\n",
      " [0.01005051 0.9899495 ]\n",
      " [0.9986821  0.00131794]\n",
      " [0.99843735 0.00156264]\n",
      " [0.99848384 0.0015162 ]\n",
      " [0.99816316 0.00183685]\n",
      " [0.998582   0.00141803]\n",
      " [0.9984101  0.00158988]\n",
      " [0.99824506 0.00175489]\n",
      " [0.9984947  0.00150528]\n",
      " [0.9978676  0.00213236]\n",
      " [0.9986143  0.00138572]\n",
      " [0.99796766 0.00203235]\n",
      " [0.99724424 0.00275583]\n",
      " [0.99855953 0.0014405 ]\n",
      " [0.9984115  0.00158853]\n",
      " [0.99793375 0.00206624]\n",
      " [0.01412597 0.985874  ]\n",
      " [0.01408556 0.9859144 ]\n",
      " [0.96353996 0.03646008]\n",
      " [0.01547826 0.98452175]\n",
      " [0.99719495 0.002805  ]\n",
      " [0.99645615 0.00354388]\n",
      " [0.01346857 0.9865314 ]\n",
      " [0.01463122 0.9853688 ]\n",
      " [0.01475789 0.98524207]\n",
      " [0.02097655 0.97902346]\n",
      " [0.01882374 0.98117626]\n",
      " [0.9987716  0.00122841]\n",
      " [0.99871665 0.00128337]\n",
      " [0.99865705 0.00134298]\n",
      " [0.9986704  0.00132961]\n",
      " [0.9988524  0.00114763]\n",
      " [0.9985704  0.00142959]\n",
      " [0.99887216 0.00112786]\n",
      " [0.99650204 0.00349802]\n",
      " [0.9270967  0.07290324]\n",
      " [0.99749106 0.00250897]\n",
      " [0.10116246 0.89883757]\n",
      " [0.998842   0.001158  ]\n",
      " [0.9987511  0.00124892]\n",
      " [0.998541   0.00145902]\n",
      " [0.9987389  0.00126108]\n",
      " [0.99882495 0.00117504]\n",
      " [0.99872303 0.00127701]\n",
      " [0.99875546 0.00124453]\n",
      " [0.99873805 0.00126191]\n",
      " [0.99852175 0.00147825]\n",
      " [0.01677441 0.9832256 ]\n",
      " [0.9984318  0.00156816]\n",
      " [0.99884737 0.00115264]\n",
      " [0.9987129  0.0012871 ]\n",
      " [0.99877924 0.00122075]\n",
      " [0.9989102  0.00108984]\n",
      " [0.9984935  0.00150648]\n",
      " [0.9986821  0.0013179 ]\n",
      " [0.99867016 0.00132983]\n",
      " [0.99878025 0.0012198 ]\n",
      " [0.998504   0.00149603]\n",
      " [0.99790525 0.00209474]\n",
      " [0.9987305  0.00126956]\n",
      " [0.9987121  0.00128785]\n",
      " [0.99842024 0.00157979]\n",
      " [0.9984862  0.00151375]\n",
      " [0.99826777 0.00173221]\n",
      " [0.9985181  0.00148192]\n",
      " [0.99821556 0.00178449]\n",
      " [0.9987274  0.00127263]\n",
      " [0.99817085 0.00182913]\n",
      " [0.99826807 0.00173191]\n",
      " [0.9986238  0.00137621]\n",
      " [0.01330021 0.98669976]\n",
      " [0.01424996 0.9857501 ]\n",
      " [0.9939959  0.00600414]\n",
      " [0.9975253  0.00247471]\n",
      " [0.998646   0.00135398]\n",
      " [0.9987563  0.00124373]\n",
      " [0.9988374  0.00116262]\n",
      " [0.9987669  0.0012331 ]\n",
      " [0.998694   0.00130601]\n",
      " [0.9987095  0.0012905 ]\n",
      " [0.99846715 0.00153285]\n",
      " [0.99868137 0.00131866]\n",
      " [0.99881905 0.00118098]\n",
      " [0.99841815 0.00158186]\n",
      " [0.9986279  0.00137209]\n",
      " [0.99880904 0.00119095]\n",
      " [0.99804455 0.00195547]\n",
      " [0.9986761  0.0013239 ]\n",
      " [0.99879915 0.00120085]\n",
      " [0.99876773 0.00123224]\n",
      " [0.9987539  0.00124609]\n",
      " [0.99835074 0.00164926]\n",
      " [0.9961278  0.00387223]\n",
      " [0.99478704 0.00521296]\n",
      " [0.99560255 0.00439744]\n",
      " [0.0171838  0.9828162 ]\n",
      " [0.99708146 0.00291858]\n",
      " [0.99827534 0.00172466]\n",
      " [0.99859726 0.00140272]\n",
      " [0.01088677 0.9891133 ]\n",
      " [0.94839317 0.0516068 ]\n",
      " [0.9453364  0.05466357]\n",
      " [0.99454397 0.00545604]\n",
      " [0.9983611  0.00163888]\n",
      " [0.99816823 0.00183172]\n",
      " [0.9981356  0.00186434]\n",
      " [0.9960261  0.00397394]\n",
      " [0.99637854 0.00362143]\n",
      " [0.97895974 0.02104021]\n",
      " [0.9916725  0.00832748]\n",
      " [0.99825996 0.00174006]\n",
      " [0.9643792  0.0356208 ]\n",
      " [0.9890111  0.01098893]\n",
      " [0.04917284 0.9508272 ]\n",
      " [0.9987223  0.00127767]\n",
      " [0.9985404  0.00145964]\n",
      " [0.997856   0.00214397]\n",
      " [0.01598039 0.98401964]\n",
      " [0.99880445 0.00119557]\n",
      " [0.9985327  0.0014673 ]\n",
      " [0.99873966 0.00126035]\n",
      " [0.9985982  0.00140178]\n",
      " [0.99843514 0.00156486]\n",
      " [0.9986872  0.00131278]\n",
      " [0.9988129  0.00118713]\n",
      " [0.9986127  0.00138724]\n",
      " [0.99868464 0.00131535]\n",
      " [0.01854946 0.98145056]\n",
      " [0.01775646 0.98224354]\n",
      " [0.99763966 0.00236033]\n",
      " [0.9987396  0.0012604 ]\n",
      " [0.9981814  0.00181854]\n",
      " [0.9983196  0.00168039]\n",
      " [0.9986687  0.00133131]\n",
      " [0.99852407 0.00147593]\n",
      " [0.99370384 0.00629615]\n",
      " [0.9986573  0.00134275]\n",
      " [0.9984552  0.00154479]\n",
      " [0.9986298  0.0013702 ]\n",
      " [0.99860173 0.00139824]\n",
      " [0.99806434 0.00193563]\n",
      " [0.9976961  0.00230388]\n",
      " [0.99445254 0.00554742]\n",
      " [0.99766564 0.00233438]\n",
      " [0.99299484 0.0070052 ]\n",
      " [0.99872905 0.00127089]\n",
      " [0.9988279  0.00117217]\n",
      " [0.9987034  0.00129654]\n",
      " [0.9986072  0.00139272]\n",
      " [0.9986548  0.00134518]\n",
      " [0.9986255  0.00137449]\n",
      " [0.99865824 0.00134178]\n",
      " [0.9987722  0.00122777]\n",
      " [0.998668   0.00133198]\n",
      " [0.99871314 0.00128686]\n",
      " [0.9988348  0.00116521]\n",
      " [0.998764   0.00123607]\n",
      " [0.9988416  0.00115843]\n",
      " [0.9986683  0.00133166]\n",
      " [0.99869096 0.00130906]\n",
      " [0.9988237  0.0011763 ]\n",
      " [0.99877846 0.00122151]\n",
      " [0.998761   0.00123901]\n",
      " [0.9954816  0.0045184 ]\n",
      " [0.9985008  0.00149916]\n",
      " [0.9987607  0.0012393 ]\n",
      " [0.9987702  0.0012298 ]\n",
      " [0.9988374  0.00116258]\n",
      " [0.9989069  0.00109308]\n",
      " [0.9988442  0.00115582]]\n",
      "12/20/2021 21:41:13 - INFO - __main__ -   ***** Test results None *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 44.11it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/ZeroShot/2' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/2/eval-eval/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train_ot_2.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev_ot_2.csv \\\n",
    "      --test_file Data/ZeroShot/eval_ot_2.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk 'FNR==1 && NR!=1{next;}{print}' models/ZeroShot/1/eval-eval/test_results_None.txt models/ZeroShot/2/eval-eval/test_results_None.txt > models/ZeroShot/1/eval-eval/test_results_Comb2.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ez = {\n",
    "    'submission_format_file' : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/eval_submission_format.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/eval.csv'                   ,\n",
    "    'prediction_format_file' : 'models/ZeroShot/1/eval-eval/test_results_Comb2.txt'                        ,\n",
    "    }\n",
    "params_ez[ 'setting' ] = 'zero_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    " updated_data = insert_to_submission_file( **params_ez )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote outputs/zero_shot_eval_formated_comb.csv\n"
     ]
    }
   ],
   "source": [
    "write_csv( updated_data, 'outputs/zero_shot_eval_formated_comb.csv' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyWXLvHI4Cdt"
   },
   "source": [
    "**NOTE**: You can submit this file, but it only has results for the zero-shot setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/12/2022 14:28:57 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/12/2022 14:28:57 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/0/eval-test/runs/Jan12_14-28-56_r18g08.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/0/eval-test/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/0/eval-test/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "01/12/2022 14:28:57 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train.csv\n",
      "01/12/2022 14:28:57 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev.csv\n",
      "01/12/2022 14:28:57 - INFO - __main__ -   load a local file for test: Data/ZeroShot/test.csv\n",
      "01/12/2022 14:28:58 - WARNING - datasets.builder -   Using custom data configuration default-31a665eae2820d86\n",
      "Downloading and preparing dataset csv/default to /users/sitkonen/.cache/huggingface/datasets/csv/default-31a665eae2820d86/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n",
      "100%|███████████████████████████████████████████| 3/3 [00:00<00:00, 8490.49it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 26.06it/s]\n",
      "Dataset csv downloaded and prepared to /users/sitkonen/.cache/huggingface/datasets/csv/default-31a665eae2820d86/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 23.71it/s]\n",
      "[INFO|configuration_utils.py:586] 2022-01-12 14:29:01,815 >> loading configuration file models/ZeroShot/0/config.json\n",
      "[INFO|configuration_utils.py:625] 2022-01-12 14:29:01,816 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2022-01-12 14:29:01,855 >> Didn't find file models/ZeroShot/0/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:29:01,855 >> loading file models/ZeroShot/0/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:29:01,855 >> loading file models/ZeroShot/0/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:29:01,855 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:29:01,855 >> loading file models/ZeroShot/0/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:29:01,855 >> loading file models/ZeroShot/0/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1338] 2022-01-12 14:29:03,415 >> loading weights file models/ZeroShot/0/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1607] 2022-01-12 14:29:10,306 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[INFO|modeling_utils.py:1616] 2022-01-12 14:29:10,306 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/ZeroShot/0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.04ba/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.30ba/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  3.71ba/s]\n",
      "01/12/2022 14:30:08 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2022-01-12 14:30:08,253 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2022-01-12 14:30:08,396 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2022-01-12 14:30:08,396 >>   Num examples = 739\n",
      "[INFO|trainer.py:2248] 2022-01-12 14:30:08,396 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 93/93 [00:02<00:00, 38.88it/s]\n",
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.6955\n",
      "  eval_f1                 =     0.6939\n",
      "  eval_loss               =     2.1835\n",
      "  eval_runtime            = 0:00:09.95\n",
      "  eval_samples            =        739\n",
      "  eval_samples_per_second =     74.253\n",
      "  eval_steps_per_second   =      9.344\n",
      "01/12/2022 14:30:18 - INFO - __main__ -   *** Test ***\n",
      "AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
      "  test_dataset.remove_columns_(\"label\")\n",
      "[INFO|trainer.py:541] 2022-01-12 14:30:18,491 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
      "[INFO|trainer.py:2243] 2022-01-12 14:30:18,493 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2245] 2022-01-12 14:30:18,493 >>   Num examples = 2342\n",
      "[INFO|trainer.py:2248] 2022-01-12 14:30:18,493 >>   Batch size = 8\n",
      " 99%|████████████████████████████████████████▌| 290/293 [00:06<00:00, 46.17it/s][[1.8650847e-02 4.0781300e+01]\n",
      " [6.9537178e-02 1.3595468e+01]\n",
      " [2.3242608e-02 4.2393963e+01]\n",
      " ...\n",
      " [2.4097528e-02 4.4087547e+01]\n",
      " [7.9632080e+01 1.4027178e-02]\n",
      " [8.0358887e+01 1.3882777e-02]]\n",
      "[[4.5712915e-04 9.9954289e-01]\n",
      " [5.0887051e-03 9.9491131e-01]\n",
      " [5.4795237e-04 9.9945205e-01]\n",
      " ...\n",
      " [5.4628495e-04 9.9945372e-01]\n",
      " [9.9982387e-01 1.7611882e-04]\n",
      " [9.9982727e-01 1.7272985e-04]]\n",
      "01/12/2022 14:30:25 - INFO - __main__ -   ***** Test results None *****\n",
      "100%|█████████████████████████████████████████| 293/293 [00:06<00:00, 43.03it/s]\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/ZeroShot/0' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/0/eval-test/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
    "      --test_file Data/ZeroShot/test.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tparams = {\n",
    "    'submission_format_file' : 'SemEval_2022_Task2-idiomaticity/SubTaskA/TestData/test_submission_format.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/TestData/test.csv'                   ,\n",
    "    'prediction_format_file' : 'models/ZeroShot/0/eval-test/test_results_None.txt'                        ,\n",
    "    }\n",
    "tparams[ 'setting' ] = 'zero_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = insert_to_submission_file( **tparams )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote outputs/zero_shot_test_formated.csv\n"
     ]
    }
   ],
   "source": [
    "write_csv( updated_data, 'outputs/zero_shot_test_formated.csv' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use language-specific models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/12/2022 14:36:35 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/12/2022 14:36:35 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/1/eval-test/runs/Jan12_14-36-35_r18g08.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/1/eval-test/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/1/eval-test/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "01/12/2022 14:36:35 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_en_2.csv\n",
      "01/12/2022 14:36:35 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev_en_2.csv\n",
      "01/12/2022 14:36:35 - INFO - __main__ -   load a local file for test: Data/ZeroShot/test_en.csv\n",
      "01/12/2022 14:36:36 - WARNING - datasets.builder -   Using custom data configuration default-bdc7023bbf8eac6a\n",
      "Downloading and preparing dataset csv/default to /users/sitkonen/.cache/huggingface/datasets/csv/default-bdc7023bbf8eac6a/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n",
      "100%|██████████████████████████████████████████| 3/3 [00:00<00:00, 11214.72it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 37.55it/s]\n",
      "Dataset csv downloaded and prepared to /users/sitkonen/.cache/huggingface/datasets/csv/default-bdc7023bbf8eac6a/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  9.80it/s]\n",
      "[INFO|configuration_utils.py:586] 2022-01-12 14:36:39,643 >> loading configuration file models/ZeroShot/1/config.json\n",
      "[INFO|configuration_utils.py:625] 2022-01-12 14:36:39,644 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2022-01-12 14:36:39,847 >> Didn't find file models/ZeroShot/1/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:36:39,882 >> loading file models/ZeroShot/1/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:36:39,882 >> loading file models/ZeroShot/1/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:36:39,882 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:36:39,882 >> loading file models/ZeroShot/1/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:36:39,882 >> loading file models/ZeroShot/1/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1338] 2022-01-12 14:36:41,861 >> loading weights file models/ZeroShot/1/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1607] 2022-01-12 14:36:48,617 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[INFO|modeling_utils.py:1616] 2022-01-12 14:36:48,618 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/ZeroShot/1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00,  4.20ba/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 14.47ba/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.56ba/s]\n",
      "01/12/2022 14:37:46 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2022-01-12 14:37:46,153 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2022-01-12 14:37:46,295 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2022-01-12 14:37:46,295 >>   Num examples = 466\n",
      "[INFO|trainer.py:2248] 2022-01-12 14:37:46,295 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 59/59 [00:02<00:00, 26.98it/s]\n",
      "***** eval metrics *****\n",
      "  eval_accuracy           =     0.7682\n",
      "  eval_f1                 =     0.7605\n",
      "  eval_loss               =     1.0696\n",
      "  eval_runtime            = 0:00:17.27\n",
      "  eval_samples            =        466\n",
      "  eval_samples_per_second =     26.968\n",
      "  eval_steps_per_second   =      3.414\n",
      "01/12/2022 14:38:03 - INFO - __main__ -   *** Test ***\n",
      "AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
      "  test_dataset.remove_columns_(\"label\")\n",
      "[INFO|trainer.py:541] 2022-01-12 14:38:03,617 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence2, sentence1.\n",
      "[INFO|trainer.py:2243] 2022-01-12 14:38:03,619 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2245] 2022-01-12 14:38:03,619 >>   Num examples = 916\n",
      "[INFO|trainer.py:2248] 2022-01-12 14:38:03,619 >>   Batch size = 8\n",
      " 98%|████████████████████████████████████████▎| 113/115 [00:02<00:00, 46.11it/s][[ 0.07246548  7.0596085 ]\n",
      " [ 1.2768753   0.36446053]\n",
      " [ 1.2814913   0.3096759 ]\n",
      " ...\n",
      " [ 0.03375632 18.544134  ]\n",
      " [ 0.04097591 14.806348  ]\n",
      " [ 0.03981857 16.44165   ]]\n",
      "[[0.01016051 0.9898395 ]\n",
      " [0.77794886 0.22205117]\n",
      " [0.80537814 0.19462185]\n",
      " ...\n",
      " [0.00181702 0.998183  ]\n",
      " [0.00275982 0.9972402 ]\n",
      " [0.00241596 0.9975841 ]]\n",
      "01/12/2022 14:38:06 - INFO - __main__ -   ***** Test results None *****\n",
      "100%|█████████████████████████████████████████| 115/115 [00:02<00:00, 43.60it/s]\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/ZeroShot/1' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/1/eval-test/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train_en_2.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev_en_2.csv \\\n",
    "      --test_file Data/ZeroShot/test_en.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/12/2022 14:41:14 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/12/2022 14:41:14 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/ZeroShot/2/eval-test/runs/Jan12_14-41-14_r18g08.bullx,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=f1,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=9.0,\n",
      "output_dir=models/ZeroShot/2/eval-test/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/ZeroShot/2/eval-test/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "01/12/2022 14:41:14 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train_ot_2.csv\n",
      "01/12/2022 14:41:14 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev_ot_2.csv\n",
      "01/12/2022 14:41:14 - INFO - __main__ -   load a local file for test: Data/ZeroShot/test_ot.csv\n",
      "01/12/2022 14:41:16 - WARNING - datasets.builder -   Using custom data configuration default-cccbda6a1934f878\n",
      "Downloading and preparing dataset csv/default to /users/sitkonen/.cache/huggingface/datasets/csv/default-cccbda6a1934f878/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n",
      "100%|██████████████████████████████████████████| 3/3 [00:00<00:00, 12918.80it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 55.50it/s]\n",
      "Dataset csv downloaded and prepared to /users/sitkonen/.cache/huggingface/datasets/csv/default-cccbda6a1934f878/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 45.59it/s]\n",
      "[INFO|configuration_utils.py:586] 2022-01-12 14:41:17,097 >> loading configuration file models/ZeroShot/2/config.json\n",
      "[INFO|configuration_utils.py:625] 2022-01-12 14:41:17,098 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2022-01-12 14:41:17,219 >> Didn't find file models/ZeroShot/2/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:41:17,271 >> loading file models/ZeroShot/2/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:41:17,271 >> loading file models/ZeroShot/2/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:41:17,271 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:41:17,271 >> loading file models/ZeroShot/2/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2022-01-12 14:41:17,271 >> loading file models/ZeroShot/2/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1338] 2022-01-12 14:41:19,188 >> loading weights file models/ZeroShot/2/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1607] 2022-01-12 14:41:24,925 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[INFO|modeling_utils.py:1616] 2022-01-12 14:41:24,925 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at models/ZeroShot/2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  7.13ba/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.77ba/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  9.05ba/s]\n",
      "01/12/2022 14:42:11 - INFO - __main__ -   *** Evaluate ***\n",
      "[INFO|trainer.py:541] 2022-01-12 14:42:11,063 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, sentence2.\n",
      "[INFO|trainer.py:2243] 2022-01-12 14:42:11,416 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2245] 2022-01-12 14:42:11,417 >>   Num examples = 273\n",
      "[INFO|trainer.py:2248] 2022-01-12 14:42:11,417 >>   Batch size = 8\n",
      "100%|███████████████████████████████████████████| 35/35 [00:01<00:00, 19.89it/s]\n",
      "***** eval metrics *****\n",
      "  eval_accuracy           =      0.652\n",
      "  eval_f1                 =     0.5902\n",
      "  eval_loss               =     2.1115\n",
      "  eval_runtime            = 0:00:07.49\n",
      "  eval_samples            =        273\n",
      "  eval_samples_per_second =     36.419\n",
      "  eval_steps_per_second   =      4.669\n",
      "01/12/2022 14:42:19 - INFO - __main__ -   *** Test ***\n",
      "AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
      "  test_dataset.remove_columns_(\"label\")\n",
      "[INFO|trainer.py:541] 2022-01-12 14:42:19,040 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, sentence2.\n",
      "[INFO|trainer.py:2243] 2022-01-12 14:42:19,042 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2245] 2022-01-12 14:42:19,042 >>   Num examples = 1426\n",
      "[INFO|trainer.py:2248] 2022-01-12 14:42:19,042 >>   Batch size = 8\n",
      " 98%|████████████████████████████████████████▎| 176/179 [00:04<00:00, 45.49it/s][[21.81955     0.04332021]\n",
      " [25.696714    0.03693032]\n",
      " [20.187517    0.05232002]\n",
      " ...\n",
      " [18.81148     0.05453024]\n",
      " [21.843431    0.04479644]\n",
      " [26.284948    0.04053277]]\n",
      "[[0.99801856 0.00198145]\n",
      " [0.9985649  0.0014351 ]\n",
      " [0.99741495 0.002585  ]\n",
      " ...\n",
      " [0.99710953 0.0028904 ]\n",
      " [0.9979534  0.0020466 ]\n",
      " [0.9984603  0.00153968]]\n",
      "01/12/2022 14:42:23 - INFO - __main__ -   ***** Test results None *****\n",
      "100%|█████████████████████████████████████████| 179/179 [00:04<00:00, 39.91it/s]\n"
     ]
    }
   ],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/ZeroShot/2' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/ZeroShot/2/eval-test/ \\\n",
    "    \t--seed 0 \\\n",
    "    \t--train_file      Data/ZeroShot/train_ot_2.csv \\\n",
    "    \t--validation_file Data/ZeroShot/dev_ot_2.csv \\\n",
    "      --test_file Data/ZeroShot/test_ot.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk 'FNR==1 && NR!=1{next;}{print}' models/ZeroShot/1/eval-test/test_results_None.txt models/ZeroShot/2/eval-test/test_results_None.txt > models/ZeroShot/1/eval-test/test_results_Comb2.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2params = {\n",
    "    'submission_format_file' : 'SemEval_2022_Task2-idiomaticity/SubTaskA/TestData/test_submission_format.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/TestData/test.csv'                   ,\n",
    "    'prediction_format_file' : 'models/ZeroShot/1/eval-test/test_results_Comb2.txt'                        ,\n",
    "    }\n",
    "t2params[ 'setting' ] = 'zero_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = insert_to_submission_file( **t2params )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote outputs/zero_shot_test_formated_comb.csv\n"
     ]
    }
   ],
   "source": [
    "write_csv( updated_data, 'outputs/zero_shot_test_formated_comb.csv' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY7Irn_YvIni"
   },
   "source": [
    "# One Shot Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVYvUH3OvR9b"
   },
   "source": [
    "## Train One shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQO751yzvVJI",
    "outputId": "355f4d09-4507-4040-8874-20526e0fe4e7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'bert-base-multilingual-cased' \\\n",
    "    \t--do_train \\\n",
    "    \t--do_eval \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/OneShot/1/ \\\n",
    "    \t--seed 1 \\\n",
    "    \t--train_file      Data/OneShot/train.csv \\\n",
    "    \t--validation_file Data/OneShot/dev.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hW8stSsnIKWo",
    "outputId": "a797d11f-5b2f-4854-883f-fa1d592dafe1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0uO16BfcIur"
   },
   "outputs": [],
   "source": [
    "## Create save path\n",
    "#!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/OneShot/1/\n",
    "## Copy saved model.\n",
    "#!cp -r /content/models/OneShot/1/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/OneShot/1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dijAXZ7dD5V"
   },
   "source": [
    "## Evaluation On Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2903I4hKdJuE",
    "outputId": "76a28edb-007c-457e-b3a9-8530d8ef5d68",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/OneShot/1' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/OneShot/1/eval-dev/ \\\n",
    "    \t--seed 1 \\\n",
    "    \t--train_file      Data/OneShot/train.csv \\\n",
    "    \t--validation_file Data/OneShot/dev.csv \\\n",
    "      --test_file Data/OneShot/dev.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKjobV-x4R_8"
   },
   "source": [
    "### Use predictions to create the submission file (for dev data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZIEpIstdg_j"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'submission_format_file' : 'outputs/zero_shot_dev_formated.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
    "    'prediction_format_file' : 'models/OneShot/1/eval-dev/test_results_None.txt'                        ,\n",
    "    }\n",
    "params[ 'setting' ] = 'one_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrS0hvEDdspS",
    "outputId": "9d87a4b1-6d24-47ce-8277-b426ec562b43"
   },
   "outputs": [],
   "source": [
    " updated_data = insert_to_submission_file( **params )\n",
    " write_csv( updated_data, 'outputs/both_dev_formated.csv' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB2cBSmA4ZSR"
   },
   "source": [
    "### For the development data, we can run evaluation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "vTWEOw3Qd0Tz",
    "outputId": "4fff9308-e5e0-4a30-f0d2-ef4634363cb0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append( 'SemEval_2022_Task2-idiomaticity/SubTaskA/' ) \n",
    "from SubTask1Evaluator import evaluate_submission\n",
    "\n",
    "\n",
    "submission_file = 'outputs/both_dev_formated.csv'\n",
    "gold_file       = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
    "\n",
    "results = evaluate_submission( submission_file, gold_file )\n",
    "#%reload_ext google.colab.data_table\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data=results[1:], columns=results[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQhQptb1ePms"
   },
   "source": [
    "## Generate Eval Data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81G4ULAseSPB",
    "outputId": "9c1dcaec-c058-4f3b-c963-9cf040e854e1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
    "    \t--model_name_or_path 'models/OneShot/1' \\\n",
    "    \t--do_predict \\\n",
    "    \t--max_seq_length 128 \\\n",
    "    \t--per_device_train_batch_size 32 \\\n",
    "    \t--learning_rate 2e-5 \\\n",
    "    \t--num_train_epochs 9 \\\n",
    "    \t--evaluation_strategy \"epoch\" \\\n",
    "    \t--output_dir models/OneShot/1/eval-eval/ \\\n",
    "    \t--seed 1 \\\n",
    "    \t--train_file      Data/OneShot/train.csv \\\n",
    "    \t--validation_file Data/OneShot/dev.csv \\\n",
    "      --test_file Data/OneShot/eval.csv \\\n",
    "\t    --evaluation_strategy \"epoch\" \\\n",
    "\t    --save_strategy \"epoch\"  \\\n",
    "\t    --load_best_model_at_end \\\n",
    "\t    --metric_for_best_model \"f1\" \\\n",
    "\t    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnOf3yts4gcb"
   },
   "source": [
    "### Use predictions to create the submission file (for eval data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaG_XF6JJNuV"
   },
   "source": [
    "#### Create One Shot submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zk1EaW7IJa3A"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'submission_format_file' : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/eval_submission_format.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/eval.csv'                   ,\n",
    "    'prediction_format_file' : 'models/OneShot/1/eval-eval/test_results_None.txt'                         ,\n",
    "    }\n",
    "params[ 'setting' ] = 'one_shot'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IjSoShpJv6z",
    "outputId": "71d6fc47-8164-46b4-ccc2-44e171cbe30e"
   },
   "outputs": [],
   "source": [
    " updated_data = insert_to_submission_file( **params )\n",
    " write_csv( updated_data, 'outputs/one_shot_eval_formated.csv' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZlTBYSiJRP6"
   },
   "source": [
    "#### Combine Zero Shot and One Shot submission files.\n",
    "\n",
    "Do this by loading zero shot data as submission file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwpGn7d3edI1"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'submission_format_file' : 'outputs/zero_shot_eval_formated.csv' ,\n",
    "    'input_file'             : 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/eval.csv'                   ,\n",
    "    'prediction_format_file' : 'models/OneShot/1/eval-eval/test_results_None.txt'                        ,\n",
    "    }\n",
    "params[ 'setting' ] = 'one_shot'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "440OwBxyfJJs",
    "outputId": "99274dd4-42b0-41c5-d390-b511f5ee4c9c"
   },
   "outputs": [],
   "source": [
    " updated_data = insert_to_submission_file( **params )\n",
    " write_csv( updated_data, 'outputs/task2_subtaska.csv' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLz_mxylfc1e"
   },
   "source": [
    "# Download Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "R6vl3zemfeg6",
    "outputId": "b9519c6b-2fd9-49b6-c582-75dfbb9dfd8b"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('/content/outputs/task2_subtaska.csv') \n",
    "## Remeber to put this in a folder called \"submission\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuNKaVgbf2a2"
   },
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "cd78IDfLf3Xy",
    "outputId": "585f4392-9f86-4733-f06d-7b56382a0cea"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEYD3V3I5qEN"
   },
   "source": [
    "Notice the significant jump in F1 scores with the introduction of just one positive and one negative example. \n",
    "\n",
    "Note that your position on the leaderboard will be based on rows with index 2 and 5 (combined results for both languages). The rest of the results for information and ablation studies. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "do-TXGBemGgH"
   ],
   "name": "SemEval 2022 Task 2 : Subtask A [Baseline]",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
